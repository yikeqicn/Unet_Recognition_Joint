{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.44) detected. current: 2.0.2 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/yikeqicn/segnet-recognition-joint/8d3c210f650b41fa919270d5212b31de\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(api_key=\"YkPEmantOag1R1VOJmXz11hmt\", parse_args=False, project_name='SegNet_Recognition_Joint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import IRSPRT#RecgArtPrintNoIntsectHVBW\n",
    "import pytesseract as pyt\n",
    "from os.path import join, basename, dirname\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import editdistance\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split#, SequentialSampler #yike: add SequentialSampler\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "#from datasets import IRS #ArtPrintNoIntsectLBW,ArtPrintNoIntsectLBW_biameyd_siameyd,ArtPrintNoIntsectLBW_bpr_spr,ArtPrintNoIntsectLBW_biameyd_sprt\n",
    "############from Model_Unet_github import *\n",
    "from utils_seg import *\n",
    "import utils_recg\n",
    "\n",
    "############from recognition.Model import RecgModel, DecoderType\n",
    "#from recognition.utils import log_image\n",
    "\n",
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet\n",
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "from PIL import Image\n",
    "from math import ceil\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "from utils_seg import get_image_summary, log_images, _variable_with_weight_decay, _variable_on_cpu, _add_loss_summaries, \\\n",
    "    _activation_summary, print_hist_summery, get_hist, per_class_acc, writeImage\n",
    "\n",
    "# Recognition\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from os.path import join\n",
    "from Densenet4htr import Densenet4htr\n",
    "import utils_recg  # dangerous\n",
    "\n",
    "\n",
    "# model layers\n",
    "def weight_variable(shape, stddev=0.1, name=\"weight\"):\n",
    "    shape = np.array(shape)\n",
    "    # print(shape)\n",
    "    # print(stddev)\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def weight_variable_devonc(shape, stddev=0.1, name=\"weight_devonc\"):\n",
    "    shape = np.array(shape)\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev), name=name)\n",
    "\n",
    "\n",
    "def bias_variable(shape, name=\"bias\"):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, keep_prob_):\n",
    "    with tf.name_scope(\"conv2d\"):\n",
    "        conv_2d = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')  # 'VALID'\n",
    "        conv_2d_b = tf.nn.bias_add(conv_2d, b)\n",
    "        return tf.nn.dropout(conv_2d_b, keep_prob_)\n",
    "\n",
    "\n",
    "def deconv2d(x, W, stride):\n",
    "    with tf.name_scope(\"deconv2d\"):\n",
    "        x_shape = tf.shape(x)\n",
    "        output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3] // 2])\n",
    "        return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding='SAME',\n",
    "                                      name=\"conv2d_transpose\")  # 'VALID'\n",
    "\n",
    "\n",
    "def max_pool(x, n):\n",
    "    return tf.nn.max_pool(x, ksize=[1, n, n, 1], strides=[1, n, n, 1], padding='SAME')  # 'VALID'\n",
    "\n",
    "\n",
    "def crop_and_concat(x1, x2):\n",
    "    with tf.name_scope(\"crop_and_concat\"):\n",
    "        x1_shape = tf.shape(x1)\n",
    "        x2_shape = tf.shape(x2)\n",
    "        # offsets for the top left corner of the crop\n",
    "        offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
    "        size = [-1, x2_shape[1], x2_shape[2], -1]\n",
    "        x1_crop = tf.slice(x1, offsets, size)\n",
    "        return tf.concat([x1_crop, x2], 3)\n",
    "\n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    with tf.name_scope(\"pixel_wise_softmax\"):\n",
    "        max_axis = tf.reduce_max(output_map, axis=3, keepdims=True)\n",
    "        exponential_map = tf.exp(output_map - max_axis)\n",
    "        normalize = tf.reduce_sum(exponential_map, axis=3, keepdims=True)\n",
    "        return exponential_map / normalize\n",
    "\n",
    "\n",
    "def cross_entropy(y_, output_map):\n",
    "    return -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(output_map, 1e-10, 1.0)), name=\"cross_entropy\")\n",
    "\n",
    "\n",
    "# unet setting\n",
    "def create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2,\n",
    "                    summaries=True):\n",
    "    \"\"\"\n",
    "    Creates a new convolutional unet for the given parametrization.\n",
    "    :param x: input tensor, shape [?,nx,ny,channels]\n",
    "    :param keep_prob: dropout probability tensor\n",
    "    :param channels: number of channels in the input image\n",
    "    :param n_class: number of output labels\n",
    "    :param layers: number of layers in the net\n",
    "    :param features_root: number of features in the first layer\n",
    "    :param filter_size: size of the convolution filter\n",
    "    :param pool_size: size of the max pooling operation\n",
    "    :param summaries: Flag if summaries should be created\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\n",
    "        \"Layers {layers}, features {features}, filter size {filter_size}x{filter_size}, pool size: {pool_size}x{pool_size}\".format(\n",
    "            layers=layers,\n",
    "            features=features_root,\n",
    "            filter_size=filter_size,\n",
    "            pool_size=pool_size))\n",
    "\n",
    "    # Placeholder for the input image\n",
    "    with tf.name_scope(\"preprocessing\"):\n",
    "        nx = tf.shape(x)[1]\n",
    "        ny = tf.shape(x)[2]\n",
    "        # nx=32\n",
    "        # ny=128\n",
    "        # channels=1\n",
    "        x_image = tf.reshape(x, tf.stack([-1, nx, ny, channels]))\n",
    "        in_node = x_image\n",
    "        batch_size = tf.shape(x_image)[0]\n",
    "\n",
    "    weights = []\n",
    "    biases = []\n",
    "    convs = []\n",
    "    pools = OrderedDict()\n",
    "    deconv = OrderedDict()\n",
    "    dw_h_convs = OrderedDict()\n",
    "    up_h_convs = OrderedDict()\n",
    "\n",
    "    in_size = 1000  # ?????????????????????\n",
    "    size = in_size\n",
    "    # down layers\n",
    "    for layer in range(0, layers):\n",
    "        with tf.name_scope(\"down_conv_{}\".format(str(layer))):\n",
    "            features = 2 ** layer * features_root\n",
    "            stddev = np.sqrt(2 / (filter_size ** 2 * features))\n",
    "            if layer == 0:\n",
    "                w1 = weight_variable([filter_size, filter_size, channels, features], stddev, name=\"w1\")\n",
    "            else:\n",
    "                w1 = weight_variable([filter_size, filter_size, features // 2, features], stddev, name=\"w1\")\n",
    "\n",
    "            w2 = weight_variable([filter_size, filter_size, features, features], stddev, name=\"w2\")\n",
    "            b1 = bias_variable([features], name=\"b1\")\n",
    "            b2 = bias_variable([features], name=\"b2\")\n",
    "\n",
    "            conv1 = conv2d(in_node, w1, b1, keep_prob)\n",
    "            print(str(layer) + ' conv1: ' + str(conv1.get_shape()))\n",
    "            tmp_h_conv = tf.nn.relu(conv1)\n",
    "            conv2 = conv2d(tmp_h_conv, w2, b2, keep_prob)\n",
    "            print(str(layer) + ' conv2: ' + str(conv2.get_shape()))\n",
    "            dw_h_convs[layer] = tf.nn.relu(conv2)\n",
    "\n",
    "            weights.append((w1, w2))\n",
    "            biases.append((b1, b2))\n",
    "            convs.append((conv1, conv2))\n",
    "\n",
    "            size -= 2 * 2 * (filter_size // 2)  # valid conv\n",
    "            if layer < layers - 1:\n",
    "                pools[layer] = max_pool(dw_h_convs[layer], pool_size)\n",
    "                in_node = pools[layer]\n",
    "                size /= pool_size\n",
    "\n",
    "    in_node = dw_h_convs[layers - 1]\n",
    "\n",
    "    # up layers\n",
    "    for layer in range(layers - 2, -1, -1):\n",
    "        with tf.name_scope(\"up_conv_{}\".format(str(layer))):\n",
    "            features = 2 ** (layer + 1) * features_root\n",
    "            stddev = np.sqrt(2 / (filter_size ** 2 * features))\n",
    "\n",
    "            wd = weight_variable_devonc([pool_size, pool_size, features // 2, features], stddev, name=\"wd\")\n",
    "            bd = bias_variable([features // 2], name=\"bd\")\n",
    "            h_deconv = tf.nn.relu(deconv2d(in_node, wd, pool_size) + bd)\n",
    "            print(str(layer) + ' h_deconv: ' + str(h_deconv.get_shape()))\n",
    "            h_deconv_concat = crop_and_concat(dw_h_convs[layer], h_deconv)\n",
    "            print(str(layer) + ' h_deconv_concat: ' + str(h_deconv_concat.get_shape()))\n",
    "            deconv[layer] = h_deconv_concat\n",
    "\n",
    "            w1 = weight_variable([filter_size, filter_size, features, features // 2], stddev, name=\"w1\")\n",
    "            w2 = weight_variable([filter_size, filter_size, features // 2, features // 2], stddev, name=\"w2\")\n",
    "            b1 = bias_variable([features // 2], name=\"b1\")\n",
    "            b2 = bias_variable([features // 2], name=\"b2\")\n",
    "\n",
    "            conv1 = conv2d(h_deconv_concat, w1, b1, keep_prob)\n",
    "            h_conv = tf.nn.relu(conv1)\n",
    "            print(str(layer) + ' h_conv1_post_deconv: ' + str(h_conv.get_shape()))\n",
    "            conv2 = conv2d(h_conv, w2, b2, keep_prob)\n",
    "            in_node = tf.nn.relu(conv2)\n",
    "            up_h_convs[layer] = in_node\n",
    "            print(str(layer) + ' h_conv2_post_deconv: ' + str(in_node.get_shape()))\n",
    "\n",
    "            weights.append((w1, w2))\n",
    "            biases.append((b1, b2))\n",
    "            convs.append((conv1, conv2))\n",
    "\n",
    "            size *= pool_size\n",
    "            size -= 2 * 2 * (filter_size // 2)  # valid conv\n",
    "\n",
    "    # Output Map\n",
    "    with tf.name_scope(\"output_map\"):\n",
    "        weight = weight_variable([1, 1, features_root, n_class], stddev)\n",
    "        bias = bias_variable([n_class], name=\"bias\")\n",
    "        conv = conv2d(in_node, weight, bias, tf.constant(1.0))\n",
    "        print(str(layer) + ' outmap: ' + str(conv.get_shape()))\n",
    "\n",
    "        # output_map = tf.nn.relu(conv)\n",
    "        output_map = conv  # no activation, to be consistant with other models and leverage previous loss/prediction structures yike !!!!\n",
    "        up_h_convs[\"out\"] = output_map\n",
    "\n",
    "    if summaries:\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            for i, (c1, c2) in enumerate(convs):\n",
    "                tf.summary.image('summary_conv_%02d_01' % i, get_image_summary(c1))\n",
    "                tf.summary.image('summary_conv_%02d_02' % i, get_image_summary(c2))\n",
    "\n",
    "            for k in pools.keys():\n",
    "                tf.summary.image('summary_pool_%02d' % k, get_image_summary(pools[k]))\n",
    "\n",
    "            for k in deconv.keys():\n",
    "                tf.summary.image('summary_deconv_concat_%02d' % k, get_image_summary(deconv[k]))\n",
    "\n",
    "            for k in dw_h_convs.keys():\n",
    "                tf.summary.histogram(\"dw_convolution_%02d\" % k + '/activations', dw_h_convs[k])\n",
    "\n",
    "            for k in up_h_convs.keys():\n",
    "                tf.summary.histogram(\"up_convolution_%s\" % k + '/activations', up_h_convs[k])\n",
    "\n",
    "    variables = []\n",
    "    for w1, w2 in weights:\n",
    "        variables.append(w1)\n",
    "        variables.append(w2)\n",
    "\n",
    "    for b1, b2 in biases:\n",
    "        variables.append(b1)\n",
    "        variables.append(b2)\n",
    "\n",
    "    return output_map, variables, int(in_size - size)\n",
    "\n",
    "\n",
    "class DecoderType:\n",
    "    BestPath = 0\n",
    "    BeamSearch = 1\n",
    "    WordBeamSearch = 2\n",
    "\n",
    "\n",
    "class Model:\n",
    "    # model constants\n",
    "    # batchSize = 50 #qyk\n",
    "    # imgSize = (128, 32)\n",
    "    # imgSize = (192, 48) #qyk\n",
    "    maxTextLen = 32  # qyk?\n",
    "    MOVING_AVERAGE_DECAY = 0.9999  # The decay to use for the moving average.\n",
    "    NUM_EPOCHS_PER_DECAY = 350.0  # Epochs after which learning rate decays.\n",
    "    LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "\n",
    "    def __init__(self, args, charList, loss_beta, loss_weight, decoderType=DecoderType.BestPath, experiment=None,\n",
    "                 mustRestore_seg=False, mustRestore_recg=False, joint=False):  # !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        '''\n",
    "        loss_betaxsegloss+(1-loss_beta)xrecgloss\n",
    "        loss_weight: used in segnet training\n",
    "        joint: False -> train recognition only, True -> train segmentation with recognition frozen\n",
    "        '''\n",
    "        self.loss_beta = loss_beta  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        self.args = args\n",
    "        self.experiment = experiment\n",
    "        self.lrInit = args.lrInit\n",
    "        # self.mustRestore_recg= mustRestore_recg\n",
    "        ###################################\n",
    "        \"init segnet model parameters:\"\n",
    "        ###################################\n",
    "        self.mustRestore_seg = mustRestore_seg\n",
    "        ###model hyperparameters###\n",
    "        self.num_classes = args.num_class\n",
    "        # self.FilePaths = FilePaths\n",
    "        self.batch_size_seg = args.batch_size_seg  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        self.loss_weight = loss_weight\n",
    "\n",
    "        ###########################################################################\n",
    "        \"init recognition model parameters: add CNN, RNN and CTC and initialize TF\"\n",
    "        ###########################################################################\n",
    "        self.charList = charList\n",
    "        self.decoderType = decoderType\n",
    "        self.mustRestore_recg = mustRestore_recg\n",
    "        # self.FilePaths = FilePaths\n",
    "        self.batchsize_recg = args.batchsize_recg  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # self.lrInit = args.lrInit #!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # self.args = args #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        ############################################################################\n",
    "        \"\"\"Graph Set Up\"\"\"\n",
    "        ############################################################################\n",
    "        tf.reset_default_graph()  # yike reset default graph  #!!!!!!!!!!!!!!!!!!!!!还要吗？????????\n",
    "        with tf.name_scope('graph_segmentation'):\n",
    "            # self.loss_segmentation, output = YIKE_FUNCTION_HERE()\n",
    "\n",
    "            ###input### -- try to only set up graph once, combine train and test, by yike\n",
    "            # tf.reset_default_graph() # yike reset default graph\n",
    "            self.input_images_seg = tf.placeholder(tf.float32, shape=[None, self.args.image_h, self.args.image_w,\n",
    "                                                                      self.args.image_c])  # try my best to make runtime batch_size flexible #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            self.input_labels_seg = tf.placeholder(tf.int64, shape=[None, self.args.image_h, self.args.image_w,\n",
    "                                                                    1])  # !!!!!!!!!!!!!!!!!!!!!\n",
    "            self.phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "\n",
    "            ###graph### -- combine\n",
    "            self.logit_seg = self.setup_graph(self.input_images_seg,\n",
    "                                              self.phase_train)  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            self.loss_seg = self.cal_loss(self.logit_seg, self.input_labels_seg)*500 # make it to same level as recg loss\n",
    "            self.pred_seg = tf.argmax(self.logit_seg, axis=3)\n",
    "\n",
    "            input_images_2d_seg = tf.squeeze(self.input_images_seg, [3])  # to 2d images, channel=1\n",
    "            self.output_clean_seg = tf.to_float(self.pred_seg) * (255 - input_images_2d_seg) + input_images_2d_seg\n",
    "\n",
    "            print('clean output from seg: ' + str(self.output_clean_seg.get_shape()))\n",
    "\n",
    "        with tf.name_scope('graph_recognition'):\n",
    "            # assume the input has been resized to 32x128\n",
    "            if joint:\n",
    "                self.input_images_recg = tf.transpose(self.output_clean_seg, perm=(0, 2, 1))\n",
    "            else:\n",
    "                self.input_images_recg = tf.placeholder(tf.float32, shape=(None, args.image_w, args.image_h))\n",
    "            print('recg input: ' + str(self.input_images_recg.get_shape()))\n",
    "            # CNN\n",
    "            if args.nondensenet:\n",
    "                cnnOut4d = self.setupCNN(self.input_images_recg)\n",
    "            else:  # use densenet by default\n",
    "                cnnOut4d = self.setupCNNdensenet(self.input_images_recg, args)\n",
    "\n",
    "            # RNN\n",
    "            rnnOut3d = self.setupRNN(cnnOut4d)\n",
    "\n",
    "            # CTC\n",
    "            (self.ctcloss, self.decoder) = self.setupCTC(rnnOut3d)\n",
    "\n",
    "            # Explicit regularizers\n",
    "            self.loss_recg = self.ctcloss + args.wdec * self.setupWdec(args)\n",
    "\n",
    "        # combine losses\n",
    "        self.loss_total = (1 - loss_beta) * self.loss_recg + loss_beta * self.loss_seg\n",
    "        print(self.loss_total)\n",
    "        # optimizer for NN parameters\n",
    "        self.batchesTrained = args.batchesTrained  # only for recognition training\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])  # for recognition and segmentation\n",
    "        self.global_step = tf.Variable(0, trainable=False)  # for segmentation training\n",
    "\n",
    "        self.var_list_train_seg = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"graph_segmentation\") #TRAINABLE_\n",
    "        self.obj_list_savable_seg= tf.get_collection(tf.GraphKeys.VARIABLES, \"graph_segmentation\")\n",
    "        self.train_op_seg = self.train_op_seg_prepare(total_loss=self.loss_total, lr=self.learning_rate,\n",
    "                                                      global_step=self.global_step, var_list=self.var_list_train_seg)\n",
    "        # self.learning_rate self.loss_total\n",
    "        ## optimizer for recognition only\n",
    "\n",
    "        self.var_list_train_recg = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"graph_recognition\")#TRAINABLE_\n",
    "        self.obj_list_savable_recg= tf.get_collection(tf.GraphKeys.VARIABLES, \"graph_recognition\")\n",
    "        if args.optimizer == 'rmsprop':\n",
    "            self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss_recg,\n",
    "                                                                                    var_list=self.var_list_train_recg)\n",
    "        elif args.optimizer == 'adam':\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss_recg,\n",
    "                                                                                 var_list=self.var_list_train_recg)\n",
    "        elif args.optimizer == 'momentum':\n",
    "            self.optimizer = tf.train.MomentumOptimizer(self.learning_rate, .9).minimize(self.loss_recg,\n",
    "                                                                                         var_list=self.var_list_train_recg)\n",
    "\n",
    "        # self.global_step,var_list=self.var_list_train_seg)  # !!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # above: loss need to change to total loss\n",
    "        ###session and saver###\n",
    "        (self.sess, self.saver_seg, self.saver_recg) = self.initTF()  # tobe changed!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "    ############################################################\n",
    "    #####               Segnet Functions             ###########\n",
    "    ############################################################ Not Adjusted !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    ### 1. loss factory ###\n",
    "\n",
    "    def weighted_loss(self, logits, labels):  # num_classes, head=None):\n",
    "        \"\"\" median-frequency re-weighting \"\"\"\n",
    "        with tf.name_scope('loss'):\n",
    "            # print('w_llll')\n",
    "            logits = tf.reshape(logits, (-1, self.num_classes))\n",
    "            # print(logits.get_shape())\n",
    "            epsilon = tf.constant(value=1e-10)\n",
    "\n",
    "            logits = logits + epsilon\n",
    "\n",
    "            # consturct one-hot label array\n",
    "            label_flat = tf.reshape(labels, (-1, 1))\n",
    "            # print(label_flat.get_shape())\n",
    "\n",
    "            # should be [batch ,num_classes]\n",
    "            labels = tf.reshape(tf.one_hot(label_flat, depth=self.num_classes), (-1, self.num_classes))\n",
    "            # print(labels.get_shape())\n",
    "\n",
    "            softmax = tf.nn.softmax(logits)\n",
    "            # print(softmax.get_shape())\n",
    "            #        print(epsilon.get_shape())\n",
    "\n",
    "            #        print((labels * tf.log(softmax + epsilon)).get_shape())\n",
    "            #        print(head.shape)\n",
    "            #        print(tf.multiply(labels * tf.log(softmax + epsilon), head))\n",
    "\n",
    "            cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(softmax + epsilon), self.loss_weight),\n",
    "                                           axis=[1])\n",
    "            #        print(cross_entropy.get_shape()) # yike head -> self.loss_weight\n",
    "\n",
    "            cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "            #        print(cross_entropy_mean.get_shape())\n",
    "            tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "            loss = tf.add_n(tf.get_collection('losses'), name='total_loss_seg')\n",
    "            print('loss_seg: ' + str(loss.get_shape()))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def cal_loss(self, logits, labels):\n",
    "        labels = tf.cast(labels, tf.int32)\n",
    "        return self.weighted_loss(logits, labels)\n",
    "\n",
    "        # self.weighted_loss(logits, labels, num_classes=NUM_CLASSES, head=loss_weight)\n",
    "\n",
    "        ###2. train optimizer factory ##\n",
    "\n",
    "    def train_op_seg_prepare(self, total_loss, lr, global_step, var_list):\n",
    "        # all of them are tensor\n",
    "        # total_sample = 274 yike: ok to comment out?\n",
    "        # num_batches_per_epoch = 274/1 yike: ok to comment out?\n",
    "\n",
    "        loss_averages_op = _add_loss_summaries(total_loss)\n",
    "        # Compute gradients.\n",
    "        with tf.control_dependencies([loss_averages_op]):\n",
    "            # print('try...')\n",
    "            opt = tf.train.AdamOptimizer(lr)\n",
    "            print('toto_loss_shape: ' + str(total_loss))\n",
    "            opt.compute_gradients(total_loss, var_list=var_list)  # add list of variables\n",
    "            grads = opt.compute_gradients(total_loss, var_list=var_list)  # !!!!!!!\n",
    "            # print(grads)\n",
    "            apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "            # Add histograms for trainable variables.\n",
    "            #######for var in tf.trainable_variables():\n",
    "            ######tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "            # Add histograms for gradients.\n",
    "            #####for grad, var in grads:\n",
    "            #####if grad is not None:\n",
    "            #####tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "            # Track the moving averages of all trainable variables.\n",
    "            variable_averages = tf.train.ExponentialMovingAverage(Model.MOVING_AVERAGE_DECAY, global_step)\n",
    "            variables_averages_op = variable_averages.apply(var_list=var_list)  # tf.trainable_variables()\n",
    "\n",
    "            with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "                train_op_seg = tf.no_op(name='train_op_seg_prepare')\n",
    "\n",
    "        return train_op_seg\n",
    "\n",
    "        ###3. graph factory ###\n",
    "\n",
    "    def setup_graph(self, images, phase_train):\n",
    "        # previous inference() labels,inference, batch_size -- in order to get batch_size at running time\n",
    "        # rather than using fixed batch_size in graph set up, revise it in inference:\n",
    "        # batchsize=tf.shape(images)[0] # yike !!!\n",
    "        print('GGG')\n",
    "        input_shape = images.get_shape().as_list()\n",
    "        print(input_shape)\n",
    "\n",
    "        #       create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2,\n",
    "        #                    summaries=True)\n",
    "\n",
    "        logit, _, __ = create_conv_net(x=images, keep_prob=0.8, channels=input_shape[3], n_class=self.num_classes,\n",
    "                                       layers=3, features_root=32, filter_size=3)\n",
    "        print(logit.get_shape())\n",
    "        \"\"\"\n",
    "         Start Classify \n",
    "\n",
    "        # output predicted class number (6)\n",
    "        with tf.variable_scope('conv_classifier') as scope:\n",
    "          kernel = _variable_with_weight_decay('weights',\n",
    "                                            shape=[1, 1, 64, self.num_classes],\n",
    "                                            initializer=msra_initializer(1, 64),\n",
    "                                            wd=0.0005)\n",
    "          conv = tf.nn.conv2d(conv_decode1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "          print('cv')\n",
    "          print(conv.get_shape())\n",
    "          biases = _variable_on_cpu('biases', [self.num_classes], tf.constant_initializer(0.0))\n",
    "          print(biases.get_shape())\n",
    "          logit= tf.nn.bias_add(conv, biases, name=scope.name)\n",
    "          #conv_classifier = tf.nn.bias_add(conv, biases, name=scope.name)\n",
    "          #print(conv_classifier.get_shape())\n",
    "          #logit = conv_classifier\n",
    "          #print('LLL')\n",
    "          #print(labels)\n",
    "          #print(conv_classifier)\n",
    "\n",
    "          #loss = cal_loss(conv_classifier, labels)\n",
    "          print(logit.get_shape())\n",
    "          \"\"\"\n",
    "        return logit  # loss\n",
    "\n",
    "    ############################################################################\n",
    "    ###                 Recognition Functions                                ###\n",
    "    ############################################################################\n",
    "    def setupCNN(self, cnnIn3d):\n",
    "        \"vanilla cnn from original github repo\"\n",
    "        cnnIn4d = tf.expand_dims(input=cnnIn3d, axis=3)\n",
    "\n",
    "        # list of parameters for the layers\n",
    "        kernelVals = [5, 5, 3, 3, 3]\n",
    "        featureVals = [1, 32, 64, 128, 128, 256]\n",
    "        strideVals = poolVals = [(2, 2), (2, 2), (1, 2), (1, 2), (1, 2)]\n",
    "        numLayers = len(strideVals)\n",
    "\n",
    "        # create layers\n",
    "        pool = cnnIn4d  # input to first CNN layer\n",
    "        for i in range(numLayers):\n",
    "            kernel = tf.Variable(\n",
    "                tf.truncated_normal([kernelVals[i], kernelVals[i], featureVals[i], featureVals[i + 1]], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            relu = tf.nn.relu(conv)\n",
    "            pool = tf.nn.max_pool(relu, (1, poolVals[i][0], poolVals[i][1], 1),\n",
    "                                  (1, strideVals[i][0], strideVals[i][1], 1),\n",
    "                                  'VALID')\n",
    "\n",
    "        self.is_training = tf.placeholder(tf.bool, shape=[])  # dummy placeholder to prevent error, no effect\n",
    "        return pool\n",
    "\n",
    "    def setupCNNdensenet(self, cnnIn3d, args):\n",
    "        \"ADDED BY RONNY: densenet cnn\"\n",
    "        print('shape of cnn input: ' + str(cnnIn3d.get_shape().as_list()))\n",
    "        cnnIn4d = tf.expand_dims(input=cnnIn3d, axis=3)\n",
    "        net = Densenet4htr(cnnIn4d, **vars(args))\n",
    "        self.is_training = net.is_training\n",
    "        print('shape of cnn output: ' + str(net.output.get_shape().as_list()))\n",
    "        return net.output\n",
    "\n",
    "    def setupRNN(self, rnnIn4d):\n",
    "        \"create RNN layers and return output of these layers\"\n",
    "        rnnIn3d = tf.squeeze(rnnIn4d, axis=[2])\n",
    "\n",
    "        # basic cells which is used to build RNN\n",
    "        numHidden = self.args.rnndim\n",
    "        cells = [tf.contrib.rnn.LSTMCell(num_units=numHidden, state_is_tuple=True) for _ in range(2)]  # 2 layers\n",
    "\n",
    "        # stack basic cells\n",
    "        stacked = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        # bidirectional RNN\n",
    "        # BxTxF -> BxTx2H\n",
    "        ((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d,\n",
    "                                                        dtype=rnnIn3d.dtype, scope=\"graph_recognition/bidirectional_rnn\")\n",
    "\n",
    "        # BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n",
    "        concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
    "\n",
    "        # project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
    "        kernel = tf.Variable(tf.truncated_normal([1, 1, numHidden * 2, len(self.charList) + 1], stddev=0.1))\n",
    "        logits = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
    "        # with tf.variable_scope('logits'):\n",
    "        #   logits = tf.squeeze(tf.layers.conv2d(concat, len(self.charList)+1, 1, use_bias=True), axis=[2]) # FIXED BY RONNY\n",
    "        return logits\n",
    "\n",
    "    def setupCTC(self, ctcIn3d):\n",
    "        \"create CTC loss and decoder and return them\"\n",
    "        # BxTxC -> TxBxC\n",
    "        ctcIn3dTBC = tf.transpose(ctcIn3d, [1, 0, 2])\n",
    "        # ground truth text as sparse tensor\n",
    "        self.gtTexts = tf.SparseTensor(tf.placeholder(tf.int64, shape=[None, 2]),\n",
    "                                       tf.placeholder(tf.int32, [None]),\n",
    "                                       tf.placeholder(tf.int64, [2]))\n",
    "        # calc loss for batch\n",
    "        self.seqLen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "        loss = tf.nn.ctc_loss(labels=self.gtTexts, inputs=ctcIn3dTBC, sequence_length=self.seqLen,\n",
    "                              ctc_merge_repeated=True)  # , ignore_longer_outputs_than_inputs=True) #qyk\n",
    "\n",
    "        # decoder: either best path decoding or beam search decoding\n",
    "        if self.decoderType == DecoderType.BestPath:\n",
    "            decoder = tf.nn.ctc_greedy_decoder(inputs=ctcIn3dTBC, sequence_length=self.seqLen)\n",
    "        elif self.decoderType == DecoderType.BeamSearch:\n",
    "            decoder = tf.nn.ctc_beam_search_decoder(inputs=ctcIn3dTBC, sequence_length=self.seqLen, beam_width=50,\n",
    "                                                    merge_repeated=False)\n",
    "        elif self.decoderType == DecoderType.WordBeamSearch:\n",
    "            # import compiled word beam search operation (see https://github.com/githubharald/CTCWordBeamSearch)\n",
    "            word_beam_search_module = tf.load_op_library('TFWordBeamSearch.so')\n",
    "\n",
    "            # prepare information about language (dictionary, characters in dataset, characters forming words)\n",
    "            chars = str().join(self.charList)\n",
    "            wordChars = open('wordCharList.txt').read().splitlines()[0]\n",
    "            corpus = open(self.FilePaths.fnCorpus).read()\n",
    "\n",
    "            # decode using the \"Words\" mode of word beam search\n",
    "            decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(ctcIn3dTBC, dim=2), 50, 'Words', 0.0,\n",
    "                                                               corpus.encode('utf8'), chars.encode('utf8'),\n",
    "                                                               wordChars.encode('utf8'))\n",
    "\n",
    "        # return a CTC operation to compute the loss and a CTC operation to decode the RNN output\n",
    "        return (tf.reduce_mean(loss), decoder)\n",
    "\n",
    "    def setupWdec(self, args):\n",
    "        \"\"\"L2 weight decay loss.\"\"\"\n",
    "        costs = []\n",
    "        for var in tf.trainable_variables():  # all weights count toward weight decay except batchnorm and biases\n",
    "            if var.op.name.find(r'BatchNorm') == -1 & var.op.name.find(r'bias:0') == -1:\n",
    "                costs.append(tf.nn.l2_loss(var))\n",
    "        return tf.add_n(costs)\n",
    "\n",
    "    def toSparse(self, texts):\n",
    "        \"put ground truth texts into sparse tensor for ctc_loss\"\n",
    "        indices = []\n",
    "        values = []\n",
    "        shape = [len(texts), 0]  # last entry must be max(labelList[i])\n",
    "\n",
    "        # go over all texts\n",
    "        for (batchElement, text) in enumerate(texts):\n",
    "            # convert to string of label (i.e. class-ids)\n",
    "            labelStr = [self.charList.index(c) for c in text]\n",
    "            # sparse tensor must have size of max. label-string\n",
    "            if len(labelStr) > shape[1]:\n",
    "                shape[1] = len(labelStr)\n",
    "            # put each label into sparse tensor\n",
    "            for (i, label) in enumerate(labelStr):\n",
    "                indices.append([batchElement, i])\n",
    "                values.append(label)\n",
    "\n",
    "        return (indices, values, shape)\n",
    "\n",
    "    def decoderOutputToText(self, ctcOutput):\n",
    "        \"extract texts from output of CTC decoder\"\n",
    "        bt_size = ctcOutput[1].shape[0]  # yike !!!!!!\n",
    "        # contains string of labels for each batch element\n",
    "        encodedLabelStrs = [[] for i in range(bt_size)]  # yike self.batchsize !!!!!!!\n",
    "\n",
    "        # word beam search: label strings terminated by blank\n",
    "        if self.decoderType == DecoderType.WordBeamSearch:\n",
    "            blank = len(self.charList)\n",
    "            for b in range(bt_size):  # yike self.batchsize !!!!!!!\n",
    "                for label in ctcOutput[b]:\n",
    "                    if label == blank:\n",
    "                        break\n",
    "                    encodedLabelStrs[b].append(label)\n",
    "\n",
    "        # TF decoders: label strings are contained in sparse tensor\n",
    "        else:\n",
    "            # ctc returns tuple, first element is SparseTensor\n",
    "            decoded = ctcOutput[0][0]\n",
    "\n",
    "            # go over all indices and save mapping: batch -> values\n",
    "            idxDict = {b: [] for b in range(bt_size)}  # yike self.batchsize !!!!!\n",
    "            for (idx, idx2d) in enumerate(decoded.indices):\n",
    "                label = decoded.values[idx]\n",
    "                batchElement = idx2d[0]  # index according to [b,t]\n",
    "                encodedLabelStrs[batchElement].append(label)\n",
    "\n",
    "        # map labels to chars for all batch elements\n",
    "        return [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]\n",
    "\n",
    "    #########################################################\n",
    "    ####             Initialize TF (Both)                ####\n",
    "    #########################################################\n",
    "\n",
    "    def initTF(self):\n",
    "        \"initialize TF\"\n",
    "        print('Python: ' + sys.version)\n",
    "        print('Tensorflow: ' + tf.__version__)\n",
    "\n",
    "        sess = tf.Session(\n",
    "            config=tf.ConfigProto(allow_soft_placement=True, gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "\n",
    "        #####################################\n",
    "        ##        SegNet Initiation        ##\n",
    "        #####################################\n",
    "\n",
    "        saver_seg = tf.train.Saver(var_list=self.obj_list_savable_seg, max_to_keep=1)  # saver saves model to file\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Ran global_variables_initializer first')\n",
    "        # Restore from saved model in current checkpoint directory\n",
    "        latestSnapshot_seg = tf.train.latest_checkpoint(self.args.ckptpath_seg)  # is there a saved model?\n",
    "        if self.mustRestore_seg and not latestSnapshot_seg:  # if model must be restored (for inference), there must be a snapshot\n",
    "            raise Exception('No saved model found in: ' + self.args.ckptpath_seg)\n",
    "\n",
    "        if latestSnapshot_seg:  # load saved model if available\n",
    "            saver_seg.restore(sess, latestSnapshot_seg)\n",
    "            print('Init with stored values from ' + latestSnapshot_seg)\n",
    "        else:\n",
    "            # sess.run(tf.global_variables_initializer())\n",
    "            # print('Ran global_variables_initializer')\n",
    "            sess.run(tf.initializers.variables(var_list=self.var_list_train_seg, name='init_seg'))\n",
    "            print('Ran initializers.variables on segnet trainable variables')\n",
    "\n",
    "        '''\n",
    "            # initialize params from other model (transfer learning)\n",
    "        if self.args.transfer:\n",
    "            utils.maybe_download(source_url=self.args.urlTransferFrom,\n",
    "                                 filename=join(self.args.ckptpath_seg, 'transferFrom'),\n",
    "                                 target_directory=None,\n",
    "                                 filetype='folder',\n",
    "                                 force=True)\n",
    "            saverTransfer = tf.train.Saver(\n",
    "                tf.trainable_variables()[:-1])  # load all variables except from logit (classification) layer\n",
    "            saverTransfer.restore(sess, glob(join(self.args.ckptpath_seg, 'transferFrom', 'model*'))[0].split('.')[0])\n",
    "            print('Loaded variable values (except logit layer) from ' + self.args.urlTransferFrom)\n",
    "        '''\n",
    "        #############################################\n",
    "        ###         Recognition Initialization    ###\n",
    "        #############################################\n",
    "        saver_recg = tf.train.Saver(var_list=self.obj_list_savable_recg, max_to_keep=1)\n",
    "\n",
    "        latestSnapshot_recg = tf.train.latest_checkpoint(self.args.ckptpath_recg)  # is there a saved model?\n",
    "        if self.mustRestore_recg and not latestSnapshot_recg:  # if model must be restored (for inference), there must be a snapshot\n",
    "            raise Exception('No saved model found in: ' + self.args.ckptpath_recg)\n",
    "\n",
    "        if latestSnapshot_recg:  # load saved model if available\n",
    "            saver_recg.restore(sess, latestSnapshot_recg)\n",
    "            print('Init with stored values from ' + latestSnapshot_recg)\n",
    "        else:\n",
    "            sess.run(tf.initializers.variables(var_list=self.var_list_train_recg, name='init_recg'))\n",
    "            print('Ran initializers.variables on recognition trainable variables')\n",
    "        # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # initialize params from other model (transfer learning)\n",
    "        \"\"\"\n",
    "        if self.args.transfer:\n",
    "            utils.maybe_download(source_url=self.args.urlTransferFrom,\n",
    "                                 filename=join(self.args.ckptpath_recg, 'transferFrom'),\n",
    "                                 target_directory=None,\n",
    "                                 filetype='folder',\n",
    "                                 force=True)\n",
    "            saverTransfer = tf.train.Saver(\n",
    "                tf.trainable_variables()[:-1])  # load all variables except from logit (classification) layer\n",
    "            saverTransfer.restore(sess, glob(join(self.args.ckptpath_recg, 'transferFrom', 'model*'))[0].split('.')[0])\n",
    "            print('Loaded variable values (except logit layer) from ' + self.args.urlTransferFrom)\n",
    "        \"\"\"\n",
    "\n",
    "        return (sess, saver_seg, saver_recg)\n",
    "    #######################################################\n",
    "    #####         Training, Inference and Save        #####\n",
    "    #######################################################\n",
    "\n",
    "    #######################SegNet##########################\n",
    "    def saveSeg(self, epoch):\n",
    "       \"save model to file\"\n",
    "       self.saver_seg.save(self.sess, join(self.args.ckptpath_seg, 'model'), global_step=epoch)\n",
    "    def trainBatchSeg(self, images, labels, labels_recg): # added labels_recg!!!!!!!!!!!!!!!!\n",
    "        \"feed a batch into the NN to train it\"\n",
    "\n",
    "        # sparse = self.toSparse(labels)\n",
    "        # lrnrate = self.lrInit if self.batchesTrained < self.args.lrDrop1 else (\n",
    "        # self.lrInit*1e-1 if self.batchesTrained < self.args.lrDrop2 else self.lrInit*1e-2)  # decay learning rate\n",
    "        bt_size=len(images)\n",
    "        train_step = self.global_step.eval(session=self.sess)\n",
    "        sparse = self.toSparse(labels_recg) # added !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        \"\"\" fix lr \"\"\"  ## To Ronny, change the schedule?\n",
    "        # lr = self.lrInit\n",
    "        lr = self.lrInit if train_step < self.args.lrDrop1 else (\n",
    "            self.lrInit * 1e-1 if train_step < self.args.lrDrop2 else self.lrInit * 1e-2)  # yike\n",
    "        (_, lossValTotal,lossValSeg) = self.sess.run([self.train_op_seg, self.loss_total,self.loss_seg],\n",
    "                                     {self.input_images_seg: images,\n",
    "                                      #self.input_images_recg: images, # added !!!!!!!!!!!!!!!\n",
    "                                      self.input_labels_seg: labels,\n",
    "                                      self.gtTexts:sparse, # added !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                                      self.seqLen: [Model.maxTextLen]*bt_size, #* self.batchsize_seg, #added!!!!!!!!!!!!!!!!!!!!!!\n",
    "                                      self.learning_rate: lr,\n",
    "                                      self.phase_train: True,\n",
    "                                      self.is_training: False})\n",
    "        # self.batchesTrained += 1\n",
    "        return lossValTotal,lossValSeg\n",
    "\n",
    "    def inferBatchSeg(self, imgs):  # modify to compatible to torch. previous def inferBatch(self, batch)\n",
    "        \"feed a batch into the NN to recngnize the texts\"\n",
    "\n",
    "        bt_size = len(imgs)  # yike !!!!!!!!\n",
    "\n",
    "        pred = self.sess.run(self.pred_seg, feed_dict=\n",
    "        {self.input_images_seg: imgs,  # check in, comment out in formal run\n",
    "         # self.input_labels: labels,\n",
    "         self.phase_train: False,\n",
    "         self.is_training: False})  # yike self.batchsize!!!!!!!!!\n",
    "        return pred\n",
    "    def imageCleanSeg(self, imgs):\n",
    "        bt_size = len(imgs)\n",
    "        cleaneds=self.sess.run(self.output_clean_seg, feed_dict={self.input_images_seg: imgs, self.phase_train: False, self.is_training:False})\n",
    "        return cleaneds\n",
    "    def trainSeg(self, loader, validateloader=None, testloader=None):\n",
    "        \"train NN\"\n",
    "        epoch = 0  # number of training epochs since start\n",
    "        best_accuracy = 0.0\n",
    "        step = 0\n",
    "        while True:\n",
    "            epoch += 1;\n",
    "            print('Epoch:', epoch, ' Training...')\n",
    "            # train\n",
    "            counter = 0\n",
    "            # step = 0\n",
    "            for idx, (images, labels, labels_recg) in enumerate(loader):\n",
    "                images = images.numpy()\n",
    "                labels = labels.numpy()\n",
    "                #labels_recg=labels_recg.numpy()\n",
    "                loss_value_total,loss_value_seg = self.trainBatchSeg(images, labels, labels_recg)\n",
    "                assert not np.isnan(loss_value_total), 'Model diverged with loss = NaN'\n",
    "                step += 1\n",
    "\n",
    "                if idx % 100 == 0:\n",
    "                    print('TRAIN: Batch:', idx / len(loader), 'Loss_Total:', loss_value_total)\n",
    "                    print('TRAIN: Batch:', idx / len(loader), 'Loss_Seg:', loss_value_seg)\n",
    "                    self.experiment.log_metric('train/loss_total', loss_value_total, step)\n",
    "                    self.experiment.log_metric('train/loss_seg', loss_value_seg, step)#!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                    \n",
    "                    logits = self.sess.run(self.logit_seg,\n",
    "                                           feed_dict={self.input_images_seg: images,  # check in, comment out in formal run\n",
    "                                                      # self.input_labels: labels,\n",
    "                                                      # self.learning_rate: lr,\n",
    "                                                      self.phase_train: False,\n",
    "                                                      self.is_training:False})\n",
    "                    train_acc, train_acc_classes = per_class_acc(logits, labels)  # check in, comment out in formal run\n",
    "\n",
    "            # train log:\n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metric('train/acc', train_acc, step)\n",
    "                self.experiment.log_metric('train/cap_0', train_acc_classes[0], step)\n",
    "                self.experiment.log_metric('train/cap_1', train_acc_classes[1], step)\n",
    "\n",
    "            # validate:\n",
    "            if validateloader != None:\n",
    "                avg_batch_loss_seg,avg_batch_loss_total, acc_total, cap_0, cap_1 = self.validateSeg(validateloader, epoch)\n",
    "            else:\n",
    "                avg_batch_loss_seg,avg_batch_loss_total, acc_total, cap_0, cap_1 = self.validateSeg(loader, epoch)\n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metric('valid/acc', acc_total, step)\n",
    "                self.experiment.log_metric('valid/cap_0', cap_0, step)\n",
    "                self.experiment.log_metric('valid/cap_1', cap_1, step)\n",
    "                self.experiment.log_metric('valid/loss_seg', avg_batch_loss_seg, step)\n",
    "                self.experiment.log_metric('valid/loss_total', avg_batch_loss_total, step)\n",
    "                \n",
    "            # test:\n",
    "            if testloader != None:\n",
    "                acc_total, cap_0, cap_1 = self.validateSeg(testloader, epoch, is_testing=True)\n",
    "                if self.experiment is not None:\n",
    "                    self.experiment.log_metric('test/acc', acc_total, step)\n",
    "                    self.experiment.log_metric('test/cap_0', cap_0, step)\n",
    "                    self.experiment.log_metric('test/cap_1', cap_1, step)\n",
    "\n",
    "            # log best metrics\n",
    "            if acc_total > best_accuracy:  # if best validation accuracy so far, save model parameters\n",
    "                print('Character error rate improved, save model')\n",
    "                best_accuracy = acc_total\n",
    "                noImprovementSince = 0\n",
    "                self.saveSeg(epoch)\n",
    "                open(join(self.args.ckptpath_seg, 'accuracy.txt'), 'w').write(\n",
    "                    'Validation accuracy, class 0, class 1 capture rates of saved model: %f%%, %f%% and %f%% ' % (\n",
    "                    acc_total * 100.0, cap_0 * 100.0, cap_1 * 100.0))\n",
    "                if self.experiment is not None:\n",
    "                    self.experiment.log_metric('best/acc', acc_total, step)\n",
    "                    self.experiment.log_metric('best/cap_0', cap_0, step)\n",
    "                    self.experiment.log_metric('best/cap_1', cap_1, step)\n",
    "            else:\n",
    "                print('Character error rate not improved')\n",
    "                noImprovementSince += 1\n",
    "\n",
    "            # stop training\n",
    "            if epoch >= self.args.max_epoch: print('Done with training at epoch', epoch,'sigoptObservation=' + str(best_accuracy)); break\n",
    "\n",
    "    def validateSeg(self, loader, epoch, is_testing=False):\n",
    "        \"validate NN\"\n",
    "        if not is_testing:\n",
    "            print('Validating NN')\n",
    "        else:\n",
    "            print('Testing NN')\n",
    "        total_val_loss_seg = 0.0\n",
    "        total_val_loss_total= 0.0\n",
    "        # num_batches=len(loader)\n",
    "        hist = np.zeros((self.num_classes, self.num_classes))\n",
    "\n",
    "        image_upload_count = 0\n",
    "        for idx, (images, labels, labels_recg) in enumerate(loader):\n",
    "            \n",
    "            images = images.numpy()\n",
    "            labels = labels.numpy()\n",
    "            bt_size=len(images)            \n",
    "            sparse=self.toSparse(labels_recg) #added!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            #labels_recg=labels_recg.numpy() #added!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            #sparse=self.toSparse()\n",
    "            val_loss_total, val_loss_seg, val_logit = self.sess.run([self.loss_total,self.loss_seg, self.logit_seg], feed_dict=\n",
    "            {self.input_images_seg: images,  # check in, comment out in formal run\n",
    "             self.input_labels_seg: labels,\n",
    "             self.gtTexts:sparse,\n",
    "             self.seqLen: [Model.maxTextLen] * bt_size,#self.batchsize_recg, #changed!!!!!!!!!!!!!!!!!!!\n",
    "             self.phase_train: False,\n",
    "             self.is_training:False})  # self.loss,val_loss,\n",
    "\n",
    "            total_val_loss_seg += val_loss_seg\n",
    "            total_val_loss_total += val_loss_total#!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            \n",
    "            hist += get_hist(val_logit, labels)\n",
    "            # val_loss=total_val_loss / len(validateloader)*batch_size\n",
    "\n",
    "            if epoch == self.args.max_epoch and image_upload_count < 1000 and self.experiment is not None:  # decide how many images to upload\n",
    "                pred = val_logit.argmax(3)\n",
    "                images = np.squeeze(images, axis=3)\n",
    "                image_upload_count = log_images(images, pred, image_upload_count, self.experiment,\n",
    "                                                self.args.ckptpath_seg)\n",
    "\n",
    "        avg_batch_loss_seg = total_val_loss_seg / idx\n",
    "        avg_batch_loss_total = total_val_loss_total / idx\n",
    "        \n",
    "        cls_sample_nums = hist.sum(1).astype(float)\n",
    "        capture_array = np.diag(hist)\n",
    "        acc_total = capture_array.sum() / hist.sum()\n",
    "        capture_rate_ls = []\n",
    "        for cls in range(self.num_classes):\n",
    "            if cls_sample_nums[cls] == 0:\n",
    "                capture_rate = 0.0\n",
    "            else:\n",
    "                capture_rate = capture_array[cls] / cls_sample_nums[cls]\n",
    "            capture_rate_ls.append(capture_rate)\n",
    "        # iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "        # mean_iu=np.nanmean(iu)\n",
    "        print('VALID: Total accuracy: %f%%. Class 0 capture: %f%%. Class 1 capture: %f%%' % (\n",
    "            acc_total * 100.0, capture_rate_ls[0] * 100.0, capture_rate_ls[1] * 100.0))\n",
    "        return avg_batch_loss_seg,avg_batch_loss_total, acc_total, capture_rate_ls[0], capture_rate_ls[1]\n",
    "\n",
    "            ##################Recognition##########################\n",
    "\n",
    "    def trainBatchRecg(self, images, labels): #!!!!!!!!!!!!!!!!\n",
    "\n",
    "        \"feed a batch into the NN to train it\"\n",
    "        sparse = self.toSparse(labels)\n",
    "        bt_size=len(images)#!!!!!!!!!!!!!!!!!!!!\n",
    "        lrnrate = self.lrInit if self.batchesTrained < self.args.lrDrop1 else (self.lrInit * 1e-1 if self.batchesTrained < self.args.lrDrop2 else self.lrInit * 1e-2)  # decay learning rate\n",
    "        (_, lossVal) = self.sess.run([self.optimizer, self.loss_recg],\n",
    "                                    {self.input_images_recg: images,\n",
    "                                     self.gtTexts: sparse,\n",
    "                                     self.seqLen: [Model.maxTextLen]*bt_size,# * self.batchsize_recg,\n",
    "                                     self.learning_rate: lrnrate,\n",
    "                                     self.is_training: True})\n",
    "        self.batchesTrained += 1\n",
    "        return lossVal\n",
    "\n",
    "    def inferBatchRecg(self, imgs):  # modify to compatible to torch. previous def inferBatch(self, batch)\n",
    "        \"feed a batch into the NN to recngnize the texts\"\n",
    "        '''if batch to infer less than args.batchsize, error'''\n",
    "\n",
    "        bt_size = len(imgs)  # yike !!!!!!!!\n",
    "\n",
    "        decoded = self.sess.run(self.decoder,\n",
    "                                {self.input_images_recg: imgs, self.seqLen: [Model.maxTextLen] * bt_size,\n",
    "                                 self.is_training: False})  # yike self.batchsize!!!!!!!!!\n",
    "        return self.decoderOutputToText(decoded)  # previous batch.imgs\n",
    "\n",
    "    def saveRecg(self, epoch):\n",
    "        \"save model to file\"\n",
    "        self.saver_recg.save(self.sess, join(self.args.ckptpath_recg, 'model'), global_step=epoch)\n",
    "\n",
    "    def trainRecg(self, loader, validateloader=None, testloader=None):  # model\n",
    "\n",
    "        \"train NN\"\n",
    "        epoch = 0  # number of training epochs since start\n",
    "        bestCharErrorRate = bestWordErrorRate = float('inf')  # best valdiation character error rate\n",
    "\n",
    "        while True:\n",
    "            epoch += 1;\n",
    "            print('Epoch:', epoch, ' Training...')\n",
    "\n",
    "            # train\n",
    "            counter = 0\n",
    "            step = 0\n",
    "\n",
    "            for idx, (images, labels) in enumerate(loader):\n",
    "\n",
    "                # convert torchtensor to numpy\n",
    "                images = images.numpy()\n",
    "\n",
    "                # train batch\n",
    "                # try:\n",
    "                loss = self.trainBatchRecg(images, labels)\n",
    "                # except:\n",
    "                #  print(labels)\n",
    "                step += 1\n",
    "\n",
    "                # save training status\n",
    "                if np.mod(idx, 110) == 0:\n",
    "                    print('TRAIN: Batch:', idx / len(loader), 'Loss:', loss)\n",
    "                    if self.experiment is not None:\n",
    "                        self.experiment.log_metric('train/loss', loss, step)\n",
    "\n",
    "                # log images\n",
    "                if epoch == 1 and counter < 5:\n",
    "                    text = labels[counter]\n",
    "                    utils_recg.log_image(self.experiment, images[counter], text, 'train', self.args.ckptpath_recg, counter, epoch)\n",
    "                    counter += 1\n",
    "                # for debug\n",
    "                # if idx >2:\n",
    "                #  break\n",
    "\n",
    "            # validate\n",
    "            if validateloader != None:\n",
    "                charErrorRate, wordAccuracy = self.validateRecg(validateloader, epoch)  # yike !!!!!!!!!!!!\n",
    "            else:  # yike !!!!!!!!!!!!!\n",
    "                charErrorRate, wordAccuracy = self.validateRecg(loader, epoch)\n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metric('valid/cer', charErrorRate, step)\n",
    "                self.experiment.log_metric('valid/wer', 1 - wordAccuracy, step)\n",
    "\n",
    "            # test\n",
    "            if testloader != None:\n",
    "                charErrorRate, wordAccuracy = self.validateRecg(testloader, epoch, is_testing=True)\n",
    "                if self.experiment is not None:\n",
    "                    self.experiment.log_metric('test/cer', charErrorRate, step)\n",
    "                    self.experiment.log_metric('test/wer', 1 - wordAccuracy, step)\n",
    "\n",
    "            # log best metrics\n",
    "            if charErrorRate < bestCharErrorRate:  # if best validation accuracy so far, save model parameters\n",
    "                print('Character error rate improved, save model')\n",
    "                bestCharErrorRate = charErrorRate\n",
    "                noImprovementSince = 0\n",
    "                self.saveRecg(epoch)\n",
    "                open(join(args.ckptpath_recg, 'accuracy.txt'), 'w').write(\n",
    "                    'Validation character error rate of saved model: %f%%' % (charErrorRate * 100.0))\n",
    "            else:\n",
    "                print('Character error rate not improved')\n",
    "                noImprovementSince += 1\n",
    "            if 1 - wordAccuracy < bestWordErrorRate:\n",
    "                bestWordErrorRate = 1 - wordAccuracy\n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metric('best/cer', bestCharErrorRate, step)\n",
    "                self.experiment.log_metric('best/wer', bestWordErrorRate, step)\n",
    "\n",
    "            # stop training\n",
    "            if epoch >= args.epochEnd: print('Done with training at epoch', epoch,\n",
    "                                         'sigoptObservation=' + str(bestCharErrorRate)); break\n",
    "\n",
    "    def validateRecg(self, loader, epoch, is_testing=False):\n",
    "        \"validate NN\"\n",
    "        if not is_testing: print('Validating NN')\n",
    "        else: print('Testing NN')\n",
    "        #loader.validationSet() # comment out by yike. see row 141\n",
    "        numCharErr, numCharTotal, numWordOK, numWordTotal = 0, 0, 0, 0\n",
    "        plt.figure(figsize=(6,2))\n",
    "        counter = 0\n",
    "        '''\n",
    "        yike: convert to troch dataloader, test\n",
    "        '''\n",
    "        for idx, (images, labels) in enumerate(loader):\n",
    "            if np.mod(idx,10)==0:\n",
    "                print(str(idx*50*8))\n",
    "            images=images.numpy()\n",
    "            recognized=self.inferBatchRecg(images)\n",
    "\n",
    "            for i in range(len(recognized)):\n",
    "                numWordOK += 1 if labels[i] == recognized[i] else 0 #batch.gtTexts[i]\n",
    "                numWordTotal += 1\n",
    "                dist = editdistance.eval(recognized[i], labels[i])# batch.gtTexts[i])\n",
    "                numCharErr += dist\n",
    "                numCharTotal += len(labels[i]) #batch.gtTexts[i]\n",
    "\n",
    "                if is_testing and epoch==self.args.epochEnd and self.experiment is not None: #batch.gtTexts[i]\n",
    "                    text = ' '.join(['[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' + labels[i] + '\"', '->', '\"' + recognized[i] + '\"'])\n",
    "                    utils_recg.log_image(self.experiment, images[i], text, 'test-'+('ok' if dist==0 else 'err'), self.args.ckptpath_recg, counter, epoch)\n",
    "                    counter += 1 # previous batch.imgs[i]\n",
    "\n",
    "            if epoch==1 and counter<5 and not is_testing and self.experiment is not None: # log images\n",
    "                text = ' '.join(['[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' + labels[i] + '\"', '->', '\"' + recognized[i] + '\"'])\n",
    "                utils_recg.log_image(self.experiment, images[i], text, 'valid', args.ckptpath_recg, counter, epoch) #batch.gtTexts[i]\n",
    "                counter += 1 #batch.imgs[i]\n",
    "\n",
    "\n",
    "        # print validation result\n",
    "        charErrorRate = numCharErr / numCharTotal\n",
    "        wordAccuracy = numWordOK / numWordTotal\n",
    "        print('VALID: Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate * 100.0, wordAccuracy * 100.0))\n",
    "        return charErrorRate, wordAccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=Model(args, charList=\"\", loss_beta=0.6,loss_weight=[.5,.5], decoderType=DecoderType.BestPath,experiment=None,mustRestore_seg=False,mustRestore_recg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-urlTranferFrom'], dest='urlTranferFrom', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help=' archived model url ', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#General Settings\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# system basics\n",
    "#parser.add_argument(\"-name\", default='segnet_unet_hvbw_all_combine_100_epoches', type=str, help=\"name of the log\") #debug model_intersect # segnet_no_intersect_1conv_64_channels_30epoch_unet_github\n",
    "parser.add_argument(\"-name_seg\", default='debug_seg_what_ever', type=str, help=\"name of the log\") #debug model_intersect # segnet_no_intersect_1conv_64_channels_30epoch_unet_github\n",
    "#segnet_binary_100epoch_unet_github\n",
    "parser.add_argument(\"-gpu\", default='1', type=str, help=\"gpu numbers\")\n",
    "\n",
    "parser.add_argument(\"-train\", default=True, help=\"train the NN\", action=\"store_true\")\n",
    "parser.add_argument(\"-validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"-transfer\",default=False, help=\"test the NN\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"-test\",default=False, help=\"test the NN\", action=\"store_true\")\n",
    "\n",
    "# image and logistic parameters \n",
    "parser.add_argument(\"-image_h\", default=32, type=int, help='image height') #('image_h', \"360\", \"\"\" image height \"\"\") 32\n",
    "parser.add_argument(\"-image_w\", default=128, type=int, help='image width')#('image_w', \"480\", \"\"\" image width \"\"\")128\n",
    "#parser.add_argument(\"-image_h\", default=360, type=int, help='image height') \n",
    "#parser.add_argument(\"-image_w\", default=480, type=int, help='image width')\n",
    "\n",
    "parser.add_argument(\"-image_c\", default=1, type=int, help='image channel')#('image_c', \"3\", \"\"\" image channel (RGB) \"\"\")\n",
    "parser.add_argument(\"-num_class\", default=2, type=int, help='total class number')\n",
    "\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batch_size_seg\", default=10, type=int, help='batch_size')\n",
    "parser.add_argument(\"-lrInit\", default=1e-3, type=int, help='initial lr')\n",
    "parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time') # not sure\n",
    "parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time') # not sure\n",
    "parser.add_argument('-max_epoch',default=100, type=int,help='max epoch numbers')\n",
    "\n",
    "\n",
    "\n",
    "# file paths\n",
    "parser.add_argument('-ckpt_root', default=\"/root/ckpt\", type=str,help= \"dir to store ckpt\") # log_dir !!!!!\n",
    "parser.add_argument('-data_root', default=\"/root/datasets\", type=str, help=\" root to any data folder \")\n",
    "parser.add_argument('-urlTranferFrom', default=\"\", type=str, help=\" archived model url \")\n",
    "\n",
    "\n",
    "#args = parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognition Model\n",
    "# basic operations\n",
    "parser.add_argument(\"-name_recg\", default=\"recg_new_five_datasets\", type=str, help=\"name of the log\") #'dense_128_32_noartifact_beamsearch_5_datasets'\n",
    "#parser.add_argument(\"-gpu\", default='-1', type=str, help=\"gpu numbers\")\n",
    "#parser.add_argument(\"-train\", help=\"train the NN\", action=\"store_true\")\n",
    "#parser.add_argument(\"-validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "#parser.add_argument(\"-transfer\", action=\"store_true\")\n",
    "#actually not effective:\n",
    "parser.add_argument(\"-batchesTrained\", default=0, type=int, help='number of batches already trained (for lr schedule)') \n",
    "# beam search\n",
    "parser.add_argument(\"-beamsearch\", help=\"use beam search instead of best path decoding\",default=True, action=\"store_true\")\n",
    "parser.add_argument(\"-wordbeamsearch\", help=\"use word beam search instead of best path decoding\", action=\"store_true\")\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batchsize_recg\", default=10, type=int, help='batch size') # actually not effective in infrerence\n",
    "#parser.add_argument(\"-lrInit\", default=1e-2, type=float, help='initial learning rate') # actually not effective\n",
    "parser.add_argument(\"-optimizer\", default='rmsprop', help=\"adam, rmsprop, momentum\") # actually not effective\n",
    "parser.add_argument(\"-wdec\", default=1e-4, type=float, help='weight decay') # acctually not effective\n",
    "#parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time')\n",
    "#parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time')\n",
    "parser.add_argument(\"-epochEnd\", default=40, type=int, help='end after this many epochs')\n",
    "# trainset hyperparam\n",
    "#parser.add_argument(\"-noncustom\", help=\"noncustom (original) augmentation technique\", action=\"store_true\")\n",
    "#parser.add_argument(\"-noartifact\", help=\"dont insert artifcats\", action=\"store_true\")\n",
    "#parser.add_argument(\"-iam\", help='use iam dataset', action='store_true')\n",
    "# densenet hyperparam\n",
    "parser.add_argument(\"-nondensenet\", help=\"use noncustom (original) vanilla cnn\", action=\"store_true\")\n",
    "parser.add_argument(\"-growth_rate\", default=12, type=int, help='growth rate (k)')\n",
    "parser.add_argument(\"-layers_per_block\", default=18, type=int, help='number of layers per block')\n",
    "parser.add_argument(\"-total_blocks\", default=5, type=int, help='nuber of densenet blocks')\n",
    "parser.add_argument(\"-keep_prob\", default=1, type=float, help='keep probability in dropout')\n",
    "parser.add_argument(\"-reduction\", default=0.4, type=float, help='reduction factor in 1x1 conv in transition layers')\n",
    "parser.add_argument(\"-bc_mode\", default=True, type=bool, help=\"bottleneck and compresssion mode\")\n",
    "# rnn,  hyperparams\n",
    "parser.add_argument(\"-rnndim\", default=256, type=int, help='rnn dimenstionality') #256\n",
    "parser.add_argument(\"-rnnsteps\", default=32, type=int, help='number of desired time steps (image slices) to feed rnn')\n",
    "# img size\n",
    "parser.add_argument(\"-imgsize\", default=[128,32], type=int, nargs='+') #qyk default 128,32 // use segnet definition\n",
    "# testset crop\n",
    "#parser.add_argument(\"-crop_r1\", default=3, type=int)\n",
    "#parser.add_argument(\"-crop_r2\", default=28, type=int)\n",
    "#parser.add_argument(\"-crop_c1\", default=10, type=int)\n",
    "#parser.add_argument(\"-crop_c2\", default=115, type=int)\n",
    "# filepaths\n",
    "parser.add_argument(\"-dataroot\", default='/root/datasets', type=str)\n",
    "#######parser.add_argument(\"-ckptroot\", default='/root/ckpt', type=str)##############\n",
    "#parser.add_argument(\"-urlTransferFrom\", default=None, type=str)\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "### SegNet\n",
    "home = os.environ['HOME']\n",
    "#name = args.name\n",
    "#ckptroot = join(home, 'ckpt')\n",
    "#args.ckptpath = join(ckptroot, name)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "####args = parser.parse_known_args()[0]\n",
    "\n",
    "name_seg = args.name_seg\n",
    "name_recg=args.name_recg\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "ckptroot = args.ckpt_root\n",
    "args.ckptpath_seg = join(ckptroot, name_seg)\n",
    "args.ckptpath_recg = join(ckptroot, name_recg)\n",
    "if args.name_seg=='debug_seg_': shutil.rmtree(args.ckptpath_seg, ignore_errors=True)\n",
    "if args.name_recg=='debug_recg_': shutil.rmtree(args.ckptpath_recg, ignore_errors=True)\n",
    "\n",
    "os.makedirs(args.ckptpath_seg, exist_ok=True)\n",
    "os.makedirs(args.ckptpath_recg, exist_ok=True)\n",
    "\n",
    "#recg_name=args.recg_name\n",
    "#args.regckptpath=join(ckptroot,recg_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_name('recg_new_five_datasets')\n",
    "experiment.log_parameters(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_recg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/datasets/iam_handwriting already exists, skipping download\n",
      "/root/datasets/htr_assets already exists, skipping download\n",
      "/root/datasets/img_print_single already exists, skipping download\n",
      "/root/datasets/irs_handwriting already exists, skipping download\n",
      "/root/datasets/text_recognition already exists, skipping download\n",
      "screened :815531\n",
      "1262239\n",
      "22720.3\n",
      "2524.48\n",
      "GGG\n",
      "[None, 32, 128, 1]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:52: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:52: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py:3042: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py:3042: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1: (?, ?, ?, 32)\n",
      "0 conv2: (?, ?, ?, 32)\n",
      "1 conv1: (?, ?, ?, 64)\n",
      "1 conv2: (?, ?, ?, 64)\n",
      "2 conv1: (?, ?, ?, 128)\n",
      "2 conv2: (?, ?, ?, 128)\n",
      "1 h_deconv: (?, ?, ?, 64)\n",
      "1 h_deconv_concat: (?, ?, ?, ?)\n",
      "1 h_conv1_post_deconv: (?, ?, ?, 64)\n",
      "1 h_conv2_post_deconv: (?, ?, ?, 64)\n",
      "0 h_deconv: (?, ?, ?, 32)\n",
      "0 h_deconv_concat: (?, ?, ?, ?)\n",
      "0 h_conv1_post_deconv: (?, ?, ?, 32)\n",
      "0 h_conv2_post_deconv: (?, ?, ?, 32)\n",
      "0 outmap: (?, ?, ?, 2)\n",
      "(?, ?, ?, 2)\n",
      "loss_seg: ()\n",
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:313: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:313: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean output from seg: (?, 32, 128)\n",
      "recg input: (?, 128, 32)\n",
      "shape of cnn input: [None, 128, 32]\n",
      "Build Densenet4htr model with 5 blocks, 9 bottleneck layers and 9 composite layers each.\n",
      "Depth: 96\n",
      "Reduction at transition layers: 0.4\n",
      "densenet feature extractor graph built in (sec): 6.749483346939087\n",
      "Total training params: 1.0M\n",
      "shape of cnn output: [None, 32, 1, 178]\n",
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:542: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:542: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:545: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:545: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:550: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6809828a6d02>:550: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n",
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toto_loss_shape: Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3197: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3197: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "Ran global_variables_initializer first\n",
      "Ran initializers.variables on segnet trainable variables\n",
      "Ran initializers.variables on recognition trainable variables\n",
      "Epoch: 1  Training...\n",
      "TRAIN: Batch: 0.0 Loss: 131.06061\n",
      "TRAIN: Batch: 0.0009683013353755689 Loss: 23.748524\n",
      "TRAIN: Batch: 0.0019366026707511377 Loss: 21.244017\n",
      "TRAIN: Batch: 0.0029049040061267066 Loss: 18.977917\n",
      "TRAIN: Batch: 0.0038732053415022755 Loss: 20.952007\n",
      "TRAIN: Batch: 0.004841506676877844 Loss: 17.280458\n",
      "TRAIN: Batch: 0.005809808012253413 Loss: 15.293234\n",
      "TRAIN: Batch: 0.006778109347628982 Loss: 19.338072\n",
      "TRAIN: Batch: 0.007746410683004551 Loss: 12.631161\n",
      "TRAIN: Batch: 0.00871471201838012 Loss: 22.246756\n",
      "TRAIN: Batch: 0.009683013353755689 Loss: 18.207626\n",
      "TRAIN: Batch: 0.010651314689131258 Loss: 14.101362\n",
      "TRAIN: Batch: 0.011619616024506826 Loss: 13.481483\n",
      "TRAIN: Batch: 0.012587917359882395 Loss: 19.422735\n",
      "TRAIN: Batch: 0.013556218695257964 Loss: 17.194805\n",
      "TRAIN: Batch: 0.014524520030633533 Loss: 19.27061\n",
      "TRAIN: Batch: 0.015492821366009102 Loss: 27.459654\n",
      "TRAIN: Batch: 0.01646112270138467 Loss: 15.214338\n",
      "TRAIN: Batch: 0.01742942403676024 Loss: 15.731065\n",
      "TRAIN: Batch: 0.01839772537213581 Loss: 19.23659\n",
      "TRAIN: Batch: 0.019366026707511377 Loss: 13.877042\n",
      "TRAIN: Batch: 0.020334328042886946 Loss: 16.08931\n",
      "TRAIN: Batch: 0.021302629378262515 Loss: 16.88416\n",
      "TRAIN: Batch: 0.022270930713638084 Loss: 12.831049\n",
      "TRAIN: Batch: 0.023239232049013653 Loss: 19.68292\n",
      "TRAIN: Batch: 0.02420753338438922 Loss: 15.897421\n",
      "TRAIN: Batch: 0.02517583471976479 Loss: 12.227677\n",
      "TRAIN: Batch: 0.02614413605514036 Loss: 16.048178\n",
      "TRAIN: Batch: 0.02711243739051593 Loss: 10.778533\n",
      "TRAIN: Batch: 0.028080738725891497 Loss: 17.190153\n",
      "TRAIN: Batch: 0.029049040061267066 Loss: 17.597214\n",
      "TRAIN: Batch: 0.030017341396642635 Loss: 22.104465\n",
      "TRAIN: Batch: 0.030985642732018204 Loss: 17.097794\n",
      "TRAIN: Batch: 0.031953944067393776 Loss: 14.967201\n",
      "TRAIN: Batch: 0.03292224540276934 Loss: 19.005894\n",
      "TRAIN: Batch: 0.033890546738144914 Loss: 17.037046\n",
      "TRAIN: Batch: 0.03485884807352048 Loss: 17.285265\n",
      "TRAIN: Batch: 0.03582714940889605 Loss: 24.98428\n",
      "TRAIN: Batch: 0.03679545074427162 Loss: 11.507413\n",
      "TRAIN: Batch: 0.03776375207964719 Loss: 9.457549\n",
      "TRAIN: Batch: 0.038732053415022755 Loss: 18.92378\n",
      "TRAIN: Batch: 0.03970035475039833 Loss: 14.239678\n",
      "TRAIN: Batch: 0.04066865608577389 Loss: 14.356531\n",
      "TRAIN: Batch: 0.041636957421149465 Loss: 14.2896185\n",
      "TRAIN: Batch: 0.04260525875652503 Loss: 14.454133\n",
      "TRAIN: Batch: 0.0435735600919006 Loss: 13.075394\n",
      "TRAIN: Batch: 0.04454186142727617 Loss: 12.6528015\n",
      "TRAIN: Batch: 0.04551016276265174 Loss: 14.13787\n",
      "TRAIN: Batch: 0.046478464098027306 Loss: 14.489038\n",
      "TRAIN: Batch: 0.04744676543340288 Loss: 19.415646\n",
      "TRAIN: Batch: 0.04841506676877844 Loss: 10.14282\n",
      "TRAIN: Batch: 0.049383368104154016 Loss: 21.571444\n",
      "TRAIN: Batch: 0.05035166943952958 Loss: 12.517799\n",
      "TRAIN: Batch: 0.05131997077490515 Loss: 16.383287\n",
      "TRAIN: Batch: 0.05228827211028072 Loss: 17.506771\n",
      "TRAIN: Batch: 0.05325657344565629 Loss: 16.12232\n",
      "TRAIN: Batch: 0.05422487478103186 Loss: 14.527342\n",
      "TRAIN: Batch: 0.05519317611640743 Loss: 16.096409\n",
      "TRAIN: Batch: 0.056161477451782994 Loss: 16.31522\n",
      "TRAIN: Batch: 0.05712977878715857 Loss: 15.942958\n",
      "TRAIN: Batch: 0.05809808012253413 Loss: 9.053571\n",
      "TRAIN: Batch: 0.059066381457909704 Loss: 14.1022835\n",
      "TRAIN: Batch: 0.06003468279328527 Loss: 11.818032\n",
      "TRAIN: Batch: 0.06100298412866084 Loss: 13.424999\n",
      "TRAIN: Batch: 0.06197128546403641 Loss: 25.214174\n",
      "TRAIN: Batch: 0.06293958679941197 Loss: 16.1615\n",
      "TRAIN: Batch: 0.06390788813478755 Loss: 12.454906\n",
      "TRAIN: Batch: 0.06487618947016312 Loss: 19.464415\n",
      "TRAIN: Batch: 0.06584449080553868 Loss: 15.6258955\n",
      "TRAIN: Batch: 0.06681279214091425 Loss: 10.887303\n",
      "TRAIN: Batch: 0.06778109347628983 Loss: 19.782846\n",
      "TRAIN: Batch: 0.06874939481166539 Loss: 13.674308\n",
      "TRAIN: Batch: 0.06971769614704096 Loss: 11.990424\n",
      "TRAIN: Batch: 0.07068599748241652 Loss: 14.988047\n",
      "TRAIN: Batch: 0.0716542988177921 Loss: 14.40313\n",
      "TRAIN: Batch: 0.07262260015316767 Loss: 13.35592\n",
      "TRAIN: Batch: 0.07359090148854323 Loss: 17.49851\n",
      "TRAIN: Batch: 0.0745592028239188 Loss: 13.936877\n",
      "TRAIN: Batch: 0.07552750415929438 Loss: 19.21745\n",
      "TRAIN: Batch: 0.07649580549466994 Loss: 22.196642\n",
      "TRAIN: Batch: 0.07746410683004551 Loss: 20.572788\n",
      "TRAIN: Batch: 0.07843240816542107 Loss: 16.916265\n",
      "TRAIN: Batch: 0.07940070950079665 Loss: 21.165388\n",
      "TRAIN: Batch: 0.08036901083617222 Loss: 12.053056\n",
      "TRAIN: Batch: 0.08133731217154778 Loss: 22.189484\n",
      "TRAIN: Batch: 0.08230561350692335 Loss: 19.865582\n",
      "TRAIN: Batch: 0.08327391484229893 Loss: 11.029629\n",
      "TRAIN: Batch: 0.0842422161776745 Loss: 17.226206\n",
      "TRAIN: Batch: 0.08521051751305006 Loss: 12.111401\n",
      "TRAIN: Batch: 0.08617881884842563 Loss: 18.423775\n",
      "TRAIN: Batch: 0.0871471201838012 Loss: 12.633284\n",
      "TRAIN: Batch: 0.08811542151917677 Loss: 14.197346\n",
      "TRAIN: Batch: 0.08908372285455234 Loss: 20.976162\n",
      "TRAIN: Batch: 0.0900520241899279 Loss: 16.093159\n",
      "TRAIN: Batch: 0.09102032552530348 Loss: 13.668855\n",
      "TRAIN: Batch: 0.09198862686067905 Loss: 16.383423\n",
      "TRAIN: Batch: 0.09295692819605461 Loss: 13.1415615\n",
      "TRAIN: Batch: 0.09392522953143018 Loss: 9.358849\n",
      "TRAIN: Batch: 0.09489353086680576 Loss: 17.338024\n",
      "TRAIN: Batch: 0.09586183220218132 Loss: 11.68188\n",
      "TRAIN: Batch: 0.09683013353755689 Loss: 15.839275\n",
      "TRAIN: Batch: 0.09779843487293245 Loss: 12.488278\n",
      "TRAIN: Batch: 0.09876673620830803 Loss: 14.146387\n",
      "TRAIN: Batch: 0.0997350375436836 Loss: 17.295937\n",
      "TRAIN: Batch: 0.10070333887905916 Loss: 16.476963\n",
      "TRAIN: Batch: 0.10167164021443473 Loss: 14.636311\n",
      "TRAIN: Batch: 0.1026399415498103 Loss: 23.347675\n",
      "TRAIN: Batch: 0.10360824288518587 Loss: 17.715002\n",
      "TRAIN: Batch: 0.10457654422056144 Loss: 10.714191\n",
      "TRAIN: Batch: 0.105544845555937 Loss: 17.73406\n",
      "TRAIN: Batch: 0.10651314689131258 Loss: 11.544135\n",
      "TRAIN: Batch: 0.10748144822668815 Loss: 12.04287\n",
      "TRAIN: Batch: 0.10844974956206371 Loss: 15.348693\n",
      "TRAIN: Batch: 0.10941805089743928 Loss: 13.820356\n",
      "TRAIN: Batch: 0.11038635223281486 Loss: 19.2217\n",
      "TRAIN: Batch: 0.11135465356819042 Loss: 20.022636\n",
      "TRAIN: Batch: 0.11232295490356599 Loss: 14.338263\n",
      "TRAIN: Batch: 0.11329125623894155 Loss: 15.806656\n",
      "TRAIN: Batch: 0.11425955757431713 Loss: 23.125957\n",
      "TRAIN: Batch: 0.1152278589096927 Loss: 10.645598\n",
      "TRAIN: Batch: 0.11619616024506826 Loss: 13.374788\n",
      "TRAIN: Batch: 0.11716446158044383 Loss: 9.009109\n",
      "TRAIN: Batch: 0.11813276291581941 Loss: 15.199741\n",
      "TRAIN: Batch: 0.11910106425119497 Loss: 10.991459\n",
      "TRAIN: Batch: 0.12006936558657054 Loss: 12.365145\n",
      "TRAIN: Batch: 0.1210376669219461 Loss: 13.642362\n",
      "TRAIN: Batch: 0.12200596825732168 Loss: 11.915842\n",
      "TRAIN: Batch: 0.12297426959269725 Loss: 13.4897785\n",
      "TRAIN: Batch: 0.12394257092807281 Loss: 11.862284\n",
      "TRAIN: Batch: 0.12491087226344838 Loss: 19.254753\n",
      "TRAIN: Batch: 0.12587917359882395 Loss: 10.095443\n",
      "TRAIN: Batch: 0.1268474749341995 Loss: 12.66621\n",
      "TRAIN: Batch: 0.1278157762695751 Loss: 13.109759\n",
      "TRAIN: Batch: 0.12878407760495067 Loss: 10.852221\n",
      "TRAIN: Batch: 0.12975237894032624 Loss: 18.843493\n",
      "TRAIN: Batch: 0.1307206802757018 Loss: 13.974956\n",
      "TRAIN: Batch: 0.13168898161107737 Loss: 11.442323\n",
      "TRAIN: Batch: 0.13265728294645293 Loss: 16.92969\n",
      "TRAIN: Batch: 0.1336255842818285 Loss: 14.517393\n",
      "TRAIN: Batch: 0.13459388561720406 Loss: 11.752909\n",
      "TRAIN: Batch: 0.13556218695257966 Loss: 15.202692\n",
      "TRAIN: Batch: 0.13653048828795522 Loss: 12.774096\n",
      "TRAIN: Batch: 0.13749878962333079 Loss: 13.763764\n",
      "TRAIN: Batch: 0.13846709095870635 Loss: 19.23505\n",
      "TRAIN: Batch: 0.13943539229408192 Loss: 8.722691\n",
      "TRAIN: Batch: 0.14040369362945748 Loss: 11.456754\n",
      "TRAIN: Batch: 0.14137199496483305 Loss: 8.9279\n",
      "TRAIN: Batch: 0.1423402963002086 Loss: 14.925594\n",
      "TRAIN: Batch: 0.1433085976355842 Loss: 13.629144\n",
      "TRAIN: Batch: 0.14427689897095977 Loss: 12.88524\n",
      "TRAIN: Batch: 0.14524520030633534 Loss: 11.615802\n",
      "TRAIN: Batch: 0.1462135016417109 Loss: 18.24578\n",
      "TRAIN: Batch: 0.14718180297708647 Loss: 13.135833\n",
      "TRAIN: Batch: 0.14815010431246203 Loss: 20.29772\n",
      "TRAIN: Batch: 0.1491184056478376 Loss: 9.826102\n",
      "TRAIN: Batch: 0.15008670698321316 Loss: 14.85682\n",
      "TRAIN: Batch: 0.15105500831858876 Loss: 16.763517\n",
      "TRAIN: Batch: 0.15202330965396432 Loss: 13.489951\n",
      "TRAIN: Batch: 0.1529916109893399 Loss: 8.789729\n",
      "TRAIN: Batch: 0.15395991232471545 Loss: 16.030855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.15492821366009102 Loss: 18.957766\n",
      "TRAIN: Batch: 0.15589651499546658 Loss: 10.88976\n",
      "TRAIN: Batch: 0.15686481633084215 Loss: 9.998733\n",
      "TRAIN: Batch: 0.15783311766621771 Loss: 11.886268\n",
      "TRAIN: Batch: 0.1588014190015933 Loss: 13.362761\n",
      "TRAIN: Batch: 0.15976972033696887 Loss: 10.974422\n",
      "TRAIN: Batch: 0.16073802167234444 Loss: 16.08273\n",
      "TRAIN: Batch: 0.16170632300772 Loss: 15.557267\n",
      "TRAIN: Batch: 0.16267462434309557 Loss: 20.684603\n",
      "TRAIN: Batch: 0.16364292567847114 Loss: 15.214645\n",
      "TRAIN: Batch: 0.1646112270138467 Loss: 12.822224\n",
      "TRAIN: Batch: 0.16557952834922227 Loss: 12.172162\n",
      "TRAIN: Batch: 0.16654782968459786 Loss: 11.032542\n",
      "TRAIN: Batch: 0.16751613101997342 Loss: 15.556934\n",
      "TRAIN: Batch: 0.168484432355349 Loss: 12.486335\n",
      "TRAIN: Batch: 0.16945273369072456 Loss: 15.495084\n",
      "TRAIN: Batch: 0.17042103502610012 Loss: 8.740005\n",
      "TRAIN: Batch: 0.17138933636147569 Loss: 18.491262\n",
      "TRAIN: Batch: 0.17235763769685125 Loss: 17.408215\n",
      "TRAIN: Batch: 0.17332593903222682 Loss: 20.601917\n",
      "TRAIN: Batch: 0.1742942403676024 Loss: 12.00774\n",
      "TRAIN: Batch: 0.17526254170297798 Loss: 17.805986\n",
      "TRAIN: Batch: 0.17623084303835354 Loss: 14.214983\n",
      "TRAIN: Batch: 0.1771991443737291 Loss: 10.887966\n",
      "TRAIN: Batch: 0.17816744570910467 Loss: 11.496817\n",
      "TRAIN: Batch: 0.17913574704448024 Loss: 18.021776\n",
      "TRAIN: Batch: 0.1801040483798558 Loss: 10.068835\n",
      "TRAIN: Batch: 0.18107234971523137 Loss: 12.94322\n",
      "TRAIN: Batch: 0.18204065105060696 Loss: 21.45793\n",
      "TRAIN: Batch: 0.18300895238598253 Loss: 11.709844\n",
      "TRAIN: Batch: 0.1839772537213581 Loss: 12.995866\n",
      "TRAIN: Batch: 0.18494555505673366 Loss: 11.382183\n",
      "TRAIN: Batch: 0.18591385639210922 Loss: 9.824255\n",
      "TRAIN: Batch: 0.1868821577274848 Loss: 8.955417\n",
      "TRAIN: Batch: 0.18785045906286035 Loss: 12.940161\n",
      "TRAIN: Batch: 0.18881876039823592 Loss: 13.871406\n",
      "TRAIN: Batch: 0.1897870617336115 Loss: 10.703943\n",
      "TRAIN: Batch: 0.19075536306898708 Loss: 10.063152\n",
      "TRAIN: Batch: 0.19172366440436264 Loss: 11.9461975\n",
      "TRAIN: Batch: 0.1926919657397382 Loss: 14.226671\n",
      "TRAIN: Batch: 0.19366026707511377 Loss: 11.450528\n",
      "TRAIN: Batch: 0.19462856841048934 Loss: 10.219579\n",
      "TRAIN: Batch: 0.1955968697458649 Loss: 20.645212\n",
      "TRAIN: Batch: 0.19656517108124047 Loss: 11.025315\n",
      "TRAIN: Batch: 0.19753347241661606 Loss: 16.500626\n",
      "TRAIN: Batch: 0.19850177375199163 Loss: 14.435144\n",
      "TRAIN: Batch: 0.1994700750873672 Loss: 10.750433\n",
      "TRAIN: Batch: 0.20043837642274276 Loss: 15.811267\n",
      "TRAIN: Batch: 0.20140667775811832 Loss: 10.178289\n",
      "TRAIN: Batch: 0.2023749790934939 Loss: 10.025109\n",
      "TRAIN: Batch: 0.20334328042886946 Loss: 10.714846\n",
      "TRAIN: Batch: 0.20431158176424502 Loss: 14.477307\n",
      "TRAIN: Batch: 0.2052798830996206 Loss: 14.833113\n",
      "TRAIN: Batch: 0.20624818443499618 Loss: 17.059004\n",
      "TRAIN: Batch: 0.20721648577037174 Loss: 10.797664\n",
      "TRAIN: Batch: 0.2081847871057473 Loss: 13.587467\n",
      "TRAIN: Batch: 0.20915308844112288 Loss: 10.414334\n",
      "TRAIN: Batch: 0.21012138977649844 Loss: 13.326107\n",
      "TRAIN: Batch: 0.211089691111874 Loss: 16.56518\n",
      "TRAIN: Batch: 0.21205799244724957 Loss: 18.398195\n",
      "TRAIN: Batch: 0.21302629378262516 Loss: 14.150446\n",
      "TRAIN: Batch: 0.21399459511800073 Loss: 12.20968\n",
      "TRAIN: Batch: 0.2149628964533763 Loss: 13.632166\n",
      "TRAIN: Batch: 0.21593119778875186 Loss: 13.240561\n",
      "TRAIN: Batch: 0.21689949912412743 Loss: 16.860006\n",
      "TRAIN: Batch: 0.217867800459503 Loss: 7.4467382\n",
      "TRAIN: Batch: 0.21883610179487856 Loss: 8.837245\n",
      "TRAIN: Batch: 0.21980440313025412 Loss: 11.924096\n",
      "TRAIN: Batch: 0.22077270446562972 Loss: 13.051809\n",
      "TRAIN: Batch: 0.22174100580100528 Loss: 11.214441\n",
      "TRAIN: Batch: 0.22270930713638085 Loss: 9.973613\n",
      "TRAIN: Batch: 0.2236776084717564 Loss: 11.203814\n",
      "TRAIN: Batch: 0.22464590980713198 Loss: 4.477394\n",
      "TRAIN: Batch: 0.22561421114250754 Loss: 14.7128935\n",
      "TRAIN: Batch: 0.2265825124778831 Loss: 9.629555\n",
      "TRAIN: Batch: 0.22755081381325867 Loss: 13.198933\n",
      "TRAIN: Batch: 0.22851911514863427 Loss: 13.672896\n",
      "TRAIN: Batch: 0.22948741648400983 Loss: 8.1312895\n",
      "TRAIN: Batch: 0.2304557178193854 Loss: 9.022595\n",
      "TRAIN: Batch: 0.23142401915476096 Loss: 12.881071\n",
      "TRAIN: Batch: 0.23239232049013653 Loss: 8.818061\n",
      "TRAIN: Batch: 0.2333606218255121 Loss: 12.700739\n",
      "TRAIN: Batch: 0.23432892316088766 Loss: 13.339524\n",
      "TRAIN: Batch: 0.23529722449626322 Loss: 11.299847\n",
      "TRAIN: Batch: 0.23626552583163882 Loss: 9.496784\n",
      "TRAIN: Batch: 0.23723382716701438 Loss: 9.75337\n",
      "TRAIN: Batch: 0.23820212850238995 Loss: 8.417024\n",
      "TRAIN: Batch: 0.2391704298377655 Loss: 9.250233\n",
      "TRAIN: Batch: 0.24013873117314108 Loss: 10.981044\n",
      "TRAIN: Batch: 0.24110703250851664 Loss: 10.872892\n",
      "TRAIN: Batch: 0.2420753338438922 Loss: 9.827532\n",
      "TRAIN: Batch: 0.24304363517926778 Loss: 11.199198\n",
      "TRAIN: Batch: 0.24401193651464337 Loss: 10.23067\n",
      "TRAIN: Batch: 0.24498023785001893 Loss: 13.266089\n",
      "TRAIN: Batch: 0.2459485391853945 Loss: 12.6024475\n",
      "TRAIN: Batch: 0.24691684052077006 Loss: 9.406131\n",
      "TRAIN: Batch: 0.24788514185614563 Loss: 14.811557\n",
      "TRAIN: Batch: 0.2488534431915212 Loss: 10.187535\n",
      "TRAIN: Batch: 0.24982174452689676 Loss: 9.086175\n",
      "TRAIN: Batch: 0.2507900458622723 Loss: 10.961723\n",
      "TRAIN: Batch: 0.2517583471976479 Loss: 8.351245\n",
      "TRAIN: Batch: 0.25272664853302346 Loss: 11.509628\n",
      "TRAIN: Batch: 0.253694949868399 Loss: 14.08304\n",
      "TRAIN: Batch: 0.2546632512037746 Loss: 11.710405\n",
      "TRAIN: Batch: 0.2556315525391502 Loss: 12.34723\n",
      "TRAIN: Batch: 0.2565998538745258 Loss: 10.781967\n",
      "TRAIN: Batch: 0.25756815520990134 Loss: 18.047821\n",
      "TRAIN: Batch: 0.2585364565452769 Loss: 15.130273\n",
      "TRAIN: Batch: 0.25950475788065247 Loss: 7.7587647\n",
      "TRAIN: Batch: 0.26047305921602804 Loss: 11.686527\n",
      "TRAIN: Batch: 0.2614413605514036 Loss: 9.451647\n",
      "TRAIN: Batch: 0.26240966188677917 Loss: 14.320541\n",
      "TRAIN: Batch: 0.26337796322215473 Loss: 10.625159\n",
      "TRAIN: Batch: 0.2643462645575303 Loss: 9.092152\n",
      "TRAIN: Batch: 0.26531456589290586 Loss: 12.7805\n",
      "TRAIN: Batch: 0.26628286722828143 Loss: 8.605877\n",
      "TRAIN: Batch: 0.267251168563657 Loss: 12.352854\n",
      "TRAIN: Batch: 0.26821946989903256 Loss: 8.203042\n",
      "TRAIN: Batch: 0.2691877712344081 Loss: 7.99635\n",
      "TRAIN: Batch: 0.2701560725697837 Loss: 8.42003\n",
      "TRAIN: Batch: 0.2711243739051593 Loss: 8.459131\n",
      "TRAIN: Batch: 0.2720926752405349 Loss: 6.8115015\n",
      "TRAIN: Batch: 0.27306097657591044 Loss: 10.108516\n",
      "TRAIN: Batch: 0.274029277911286 Loss: 8.876202\n",
      "TRAIN: Batch: 0.27499757924666157 Loss: 7.2368984\n",
      "TRAIN: Batch: 0.27596588058203714 Loss: 10.117792\n",
      "TRAIN: Batch: 0.2769341819174127 Loss: 14.659167\n",
      "TRAIN: Batch: 0.27790248325278827 Loss: 11.696277\n",
      "TRAIN: Batch: 0.27887078458816383 Loss: 9.466739\n",
      "TRAIN: Batch: 0.2798390859235394 Loss: 7.357417\n",
      "TRAIN: Batch: 0.28080738725891496 Loss: 10.4012985\n",
      "TRAIN: Batch: 0.28177568859429053 Loss: 12.873163\n",
      "TRAIN: Batch: 0.2827439899296661 Loss: 9.2774\n",
      "TRAIN: Batch: 0.28371229126504166 Loss: 11.304639\n",
      "TRAIN: Batch: 0.2846805926004172 Loss: 10.13024\n",
      "TRAIN: Batch: 0.2856488939357928 Loss: 8.588139\n",
      "TRAIN: Batch: 0.2866171952711684 Loss: 9.845427\n",
      "TRAIN: Batch: 0.287585496606544 Loss: 7.745884\n",
      "TRAIN: Batch: 0.28855379794191954 Loss: 14.946119\n",
      "TRAIN: Batch: 0.2895220992772951 Loss: 12.351811\n",
      "TRAIN: Batch: 0.2904904006126707 Loss: 8.176084\n",
      "TRAIN: Batch: 0.29145870194804624 Loss: 8.270275\n",
      "TRAIN: Batch: 0.2924270032834218 Loss: 11.645548\n",
      "TRAIN: Batch: 0.29339530461879737 Loss: 8.76315\n",
      "TRAIN: Batch: 0.29436360595417294 Loss: 9.732469\n",
      "TRAIN: Batch: 0.2953319072895485 Loss: 10.796199\n",
      "TRAIN: Batch: 0.29630020862492407 Loss: 8.151933\n",
      "TRAIN: Batch: 0.29726850996029963 Loss: 10.465914\n",
      "TRAIN: Batch: 0.2982368112956752 Loss: 11.518964\n",
      "TRAIN: Batch: 0.29920511263105076 Loss: 12.353701\n",
      "TRAIN: Batch: 0.30017341396642633 Loss: 11.2265835\n",
      "TRAIN: Batch: 0.3011417153018019 Loss: 12.315623\n",
      "TRAIN: Batch: 0.3021100166371775 Loss: 11.769226\n",
      "TRAIN: Batch: 0.3030783179725531 Loss: 15.860729\n",
      "TRAIN: Batch: 0.30404661930792864 Loss: 11.8088045\n",
      "TRAIN: Batch: 0.3050149206433042 Loss: 9.789874\n",
      "TRAIN: Batch: 0.3059832219786798 Loss: 15.495387\n",
      "TRAIN: Batch: 0.30695152331405534 Loss: 9.451673\n",
      "TRAIN: Batch: 0.3079198246494309 Loss: 13.208348\n",
      "TRAIN: Batch: 0.30888812598480647 Loss: 8.664778\n",
      "TRAIN: Batch: 0.30985642732018204 Loss: 12.541927\n",
      "TRAIN: Batch: 0.3108247286555576 Loss: 8.846965\n",
      "TRAIN: Batch: 0.31179302999093317 Loss: 9.021354\n",
      "TRAIN: Batch: 0.31276133132630873 Loss: 7.087309\n",
      "TRAIN: Batch: 0.3137296326616843 Loss: 12.986992\n",
      "TRAIN: Batch: 0.31469793399705986 Loss: 9.031941\n",
      "TRAIN: Batch: 0.31566623533243543 Loss: 11.621006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.316634536667811 Loss: 6.5771728\n",
      "TRAIN: Batch: 0.3176028380031866 Loss: 10.20325\n",
      "TRAIN: Batch: 0.3185711393385622 Loss: 13.7014675\n",
      "TRAIN: Batch: 0.31953944067393775 Loss: 8.252477\n",
      "TRAIN: Batch: 0.3205077420093133 Loss: 7.467317\n",
      "TRAIN: Batch: 0.3214760433446889 Loss: 10.4637375\n",
      "TRAIN: Batch: 0.32244434468006444 Loss: 10.568926\n",
      "TRAIN: Batch: 0.32341264601544 Loss: 10.151724\n",
      "TRAIN: Batch: 0.3243809473508156 Loss: 9.045135\n",
      "TRAIN: Batch: 0.32534924868619114 Loss: 16.89053\n",
      "TRAIN: Batch: 0.3263175500215667 Loss: 6.5533757\n",
      "TRAIN: Batch: 0.32728585135694227 Loss: 14.284755\n",
      "TRAIN: Batch: 0.32825415269231784 Loss: 10.4045105\n",
      "TRAIN: Batch: 0.3292224540276934 Loss: 12.492059\n",
      "TRAIN: Batch: 0.33019075536306897 Loss: 6.8892736\n",
      "TRAIN: Batch: 0.33115905669844453 Loss: 8.707531\n",
      "TRAIN: Batch: 0.33212735803382015 Loss: 7.479154\n",
      "TRAIN: Batch: 0.3330956593691957 Loss: 7.8472548\n",
      "TRAIN: Batch: 0.3340639607045713 Loss: 5.7731295\n",
      "TRAIN: Batch: 0.33503226203994685 Loss: 8.649587\n",
      "TRAIN: Batch: 0.3360005633753224 Loss: 11.415331\n",
      "TRAIN: Batch: 0.336968864710698 Loss: 13.7240095\n",
      "TRAIN: Batch: 0.33793716604607354 Loss: 9.303445\n",
      "TRAIN: Batch: 0.3389054673814491 Loss: 6.710083\n",
      "TRAIN: Batch: 0.3398737687168247 Loss: 7.878663\n",
      "TRAIN: Batch: 0.34084207005220024 Loss: 9.370996\n",
      "TRAIN: Batch: 0.3418103713875758 Loss: 17.662834\n",
      "TRAIN: Batch: 0.34277867272295137 Loss: 8.611974\n",
      "TRAIN: Batch: 0.34374697405832694 Loss: 5.671735\n",
      "TRAIN: Batch: 0.3447152753937025 Loss: 4.7884197\n",
      "TRAIN: Batch: 0.34568357672907807 Loss: 9.811408\n",
      "TRAIN: Batch: 0.34665187806445363 Loss: 6.6135144\n",
      "TRAIN: Batch: 0.34762017939982925 Loss: 8.478789\n",
      "TRAIN: Batch: 0.3485884807352048 Loss: 6.001605\n",
      "TRAIN: Batch: 0.3495567820705804 Loss: 9.238593\n",
      "TRAIN: Batch: 0.35052508340595595 Loss: 4.1179686\n",
      "TRAIN: Batch: 0.3514933847413315 Loss: 5.9127336\n",
      "TRAIN: Batch: 0.3524616860767071 Loss: 5.2877817\n",
      "TRAIN: Batch: 0.35342998741208265 Loss: 6.736929\n",
      "TRAIN: Batch: 0.3543982887474582 Loss: 6.8257775\n",
      "TRAIN: Batch: 0.3553665900828338 Loss: 5.246939\n",
      "TRAIN: Batch: 0.35633489141820934 Loss: 5.0693407\n",
      "TRAIN: Batch: 0.3573031927535849 Loss: 4.995858\n",
      "TRAIN: Batch: 0.3582714940889605 Loss: 5.521106\n",
      "TRAIN: Batch: 0.35923979542433604 Loss: 6.7573156\n",
      "TRAIN: Batch: 0.3602080967597116 Loss: 8.182459\n",
      "TRAIN: Batch: 0.36117639809508717 Loss: 5.526097\n",
      "TRAIN: Batch: 0.36214469943046274 Loss: 12.519822\n",
      "TRAIN: Batch: 0.36311300076583836 Loss: 6.0004535\n",
      "TRAIN: Batch: 0.3640813021012139 Loss: 11.146733\n",
      "TRAIN: Batch: 0.3650496034365895 Loss: 5.0727305\n",
      "TRAIN: Batch: 0.36601790477196505 Loss: 9.25463\n",
      "TRAIN: Batch: 0.3669862061073406 Loss: 4.3189054\n",
      "TRAIN: Batch: 0.3679545074427162 Loss: 7.218788\n",
      "TRAIN: Batch: 0.36892280877809175 Loss: 5.2620745\n",
      "TRAIN: Batch: 0.3698911101134673 Loss: 16.791162\n",
      "TRAIN: Batch: 0.3708594114488429 Loss: 6.272488\n",
      "TRAIN: Batch: 0.37182771278421844 Loss: 4.556259\n",
      "TRAIN: Batch: 0.372796014119594 Loss: 10.186493\n",
      "TRAIN: Batch: 0.3737643154549696 Loss: 10.311435\n",
      "TRAIN: Batch: 0.37473261679034514 Loss: 6.233222\n",
      "TRAIN: Batch: 0.3757009181257207 Loss: 10.282516\n",
      "TRAIN: Batch: 0.37666921946109627 Loss: 11.477959\n",
      "TRAIN: Batch: 0.37763752079647184 Loss: 6.614519\n",
      "TRAIN: Batch: 0.37860582213184746 Loss: 5.2951274\n",
      "TRAIN: Batch: 0.379574123467223 Loss: 6.439054\n",
      "TRAIN: Batch: 0.3805424248025986 Loss: 9.011351\n",
      "TRAIN: Batch: 0.38151072613797415 Loss: 8.494806\n",
      "TRAIN: Batch: 0.3824790274733497 Loss: 10.1565075\n",
      "TRAIN: Batch: 0.3834473288087253 Loss: 5.0821176\n",
      "TRAIN: Batch: 0.38441563014410085 Loss: 6.943342\n",
      "TRAIN: Batch: 0.3853839314794764 Loss: 4.777132\n",
      "TRAIN: Batch: 0.386352232814852 Loss: 7.373871\n",
      "TRAIN: Batch: 0.38732053415022755 Loss: 6.005272\n",
      "TRAIN: Batch: 0.3882888354856031 Loss: 7.0026298\n",
      "TRAIN: Batch: 0.3892571368209787 Loss: 6.467332\n",
      "TRAIN: Batch: 0.39022543815635424 Loss: 7.6547503\n",
      "TRAIN: Batch: 0.3911937394917298 Loss: 9.74253\n",
      "TRAIN: Batch: 0.3921620408271054 Loss: 9.676543\n",
      "TRAIN: Batch: 0.39313034216248094 Loss: 8.810017\n",
      "TRAIN: Batch: 0.39409864349785656 Loss: 7.644042\n",
      "TRAIN: Batch: 0.3950669448332321 Loss: 6.070099\n",
      "TRAIN: Batch: 0.3960352461686077 Loss: 8.787388\n",
      "TRAIN: Batch: 0.39700354750398326 Loss: 5.4383483\n",
      "TRAIN: Batch: 0.3979718488393588 Loss: 11.423916\n",
      "TRAIN: Batch: 0.3989401501747344 Loss: 5.251733\n",
      "TRAIN: Batch: 0.39990845151010995 Loss: 4.24804\n",
      "TRAIN: Batch: 0.4008767528454855 Loss: 12.0883465\n",
      "TRAIN: Batch: 0.4018450541808611 Loss: 4.405157\n",
      "TRAIN: Batch: 0.40281335551623665 Loss: 4.943831\n",
      "TRAIN: Batch: 0.4037816568516122 Loss: 6.0134387\n",
      "TRAIN: Batch: 0.4047499581869878 Loss: 8.625579\n",
      "TRAIN: Batch: 0.40571825952236334 Loss: 7.3099146\n",
      "TRAIN: Batch: 0.4066865608577389 Loss: 11.566629\n",
      "TRAIN: Batch: 0.4076548621931145 Loss: 7.9872804\n",
      "TRAIN: Batch: 0.40862316352849004 Loss: 6.2724276\n",
      "TRAIN: Batch: 0.40959146486386566 Loss: 5.405381\n",
      "TRAIN: Batch: 0.4105597661992412 Loss: 6.862607\n",
      "TRAIN: Batch: 0.4115280675346168 Loss: 9.672023\n",
      "TRAIN: Batch: 0.41249636886999236 Loss: 9.200542\n",
      "TRAIN: Batch: 0.4134646702053679 Loss: 5.851629\n",
      "TRAIN: Batch: 0.4144329715407435 Loss: 3.9966302\n",
      "TRAIN: Batch: 0.41540127287611905 Loss: 5.0399013\n",
      "TRAIN: Batch: 0.4163695742114946 Loss: 5.125628\n",
      "TRAIN: Batch: 0.4173378755468702 Loss: 10.8810215\n",
      "TRAIN: Batch: 0.41830617688224575 Loss: 8.66487\n",
      "TRAIN: Batch: 0.4192744782176213 Loss: 5.214499\n",
      "TRAIN: Batch: 0.4202427795529969 Loss: 5.819381\n",
      "TRAIN: Batch: 0.42121108088837245 Loss: 6.5262246\n",
      "TRAIN: Batch: 0.422179382223748 Loss: 4.557343\n",
      "TRAIN: Batch: 0.4231476835591236 Loss: 7.4936805\n",
      "TRAIN: Batch: 0.42411598489449914 Loss: 5.0379915\n",
      "TRAIN: Batch: 0.42508428622987476 Loss: 9.238607\n",
      "TRAIN: Batch: 0.42605258756525033 Loss: 11.9279785\n",
      "TRAIN: Batch: 0.4270208889006259 Loss: 9.722314\n",
      "TRAIN: Batch: 0.42798919023600146 Loss: 4.307314\n",
      "TRAIN: Batch: 0.428957491571377 Loss: 4.5689745\n",
      "TRAIN: Batch: 0.4299257929067526 Loss: 6.744501\n",
      "TRAIN: Batch: 0.43089409424212816 Loss: 6.2933927\n",
      "TRAIN: Batch: 0.4318623955775037 Loss: 4.0103703\n",
      "TRAIN: Batch: 0.4328306969128793 Loss: 4.9677773\n",
      "TRAIN: Batch: 0.43379899824825485 Loss: 4.711392\n",
      "TRAIN: Batch: 0.4347672995836304 Loss: 6.187509\n",
      "TRAIN: Batch: 0.435735600919006 Loss: 6.120774\n",
      "TRAIN: Batch: 0.43670390225438155 Loss: 6.007829\n",
      "TRAIN: Batch: 0.4376722035897571 Loss: 10.416903\n",
      "TRAIN: Batch: 0.4386405049251327 Loss: 3.8597875\n",
      "TRAIN: Batch: 0.43960880626050824 Loss: 5.290368\n",
      "TRAIN: Batch: 0.44057710759588387 Loss: 5.7586102\n",
      "TRAIN: Batch: 0.44154540893125943 Loss: 5.15113\n",
      "TRAIN: Batch: 0.442513710266635 Loss: 3.3141892\n",
      "TRAIN: Batch: 0.44348201160201056 Loss: 3.3622918\n",
      "TRAIN: Batch: 0.4444503129373861 Loss: 2.3517447\n",
      "TRAIN: Batch: 0.4454186142727617 Loss: 3.5072305\n",
      "TRAIN: Batch: 0.44638691560813726 Loss: 3.3783112\n",
      "TRAIN: Batch: 0.4473552169435128 Loss: 4.083055\n",
      "TRAIN: Batch: 0.4483235182788884 Loss: 5.069642\n",
      "TRAIN: Batch: 0.44929181961426395 Loss: 4.7882795\n",
      "TRAIN: Batch: 0.4502601209496395 Loss: 4.317109\n",
      "TRAIN: Batch: 0.4512284222850151 Loss: 2.517762\n",
      "TRAIN: Batch: 0.45219672362039065 Loss: 3.419651\n",
      "TRAIN: Batch: 0.4531650249557662 Loss: 3.8185658\n",
      "TRAIN: Batch: 0.4541333262911418 Loss: 8.212334\n",
      "TRAIN: Batch: 0.45510162762651735 Loss: 9.984263\n",
      "TRAIN: Batch: 0.45606992896189297 Loss: 6.708992\n",
      "TRAIN: Batch: 0.45703823029726853 Loss: 7.8040924\n",
      "TRAIN: Batch: 0.4580065316326441 Loss: 4.806764\n",
      "TRAIN: Batch: 0.45897483296801966 Loss: 4.9277477\n",
      "TRAIN: Batch: 0.45994313430339523 Loss: 12.951263\n",
      "TRAIN: Batch: 0.4609114356387708 Loss: 5.752199\n",
      "TRAIN: Batch: 0.46187973697414636 Loss: 7.804921\n",
      "TRAIN: Batch: 0.4628480383095219 Loss: 4.8780007\n",
      "TRAIN: Batch: 0.4638163396448975 Loss: 5.164155\n",
      "TRAIN: Batch: 0.46478464098027306 Loss: 2.9290528\n",
      "TRAIN: Batch: 0.4657529423156486 Loss: 6.147097\n",
      "TRAIN: Batch: 0.4667212436510242 Loss: 4.223694\n",
      "TRAIN: Batch: 0.46768954498639975 Loss: 4.1825\n",
      "TRAIN: Batch: 0.4686578463217753 Loss: 4.3089933\n",
      "TRAIN: Batch: 0.4696261476571509 Loss: 6.1234384\n",
      "TRAIN: Batch: 0.47059444899252645 Loss: 8.506577\n",
      "TRAIN: Batch: 0.47156275032790207 Loss: 4.5293474\n",
      "TRAIN: Batch: 0.47253105166327763 Loss: 1.215773\n",
      "TRAIN: Batch: 0.4734993529986532 Loss: 9.73857\n",
      "TRAIN: Batch: 0.47446765433402877 Loss: 3.4900396\n",
      "TRAIN: Batch: 0.47543595566940433 Loss: 15.963023\n",
      "TRAIN: Batch: 0.4764042570047799 Loss: 5.7648435\n",
      "TRAIN: Batch: 0.47737255834015546 Loss: 3.9006255\n",
      "TRAIN: Batch: 0.478340859675531 Loss: 5.604866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.4793091610109066 Loss: 5.136889\n",
      "TRAIN: Batch: 0.48027746234628216 Loss: 2.6909783\n",
      "TRAIN: Batch: 0.4812457636816577 Loss: 6.863636\n",
      "TRAIN: Batch: 0.4822140650170333 Loss: 3.3367286\n",
      "TRAIN: Batch: 0.48318236635240885 Loss: 6.140968\n",
      "TRAIN: Batch: 0.4841506676877844 Loss: 5.456624\n",
      "TRAIN: Batch: 0.48511896902316 Loss: 4.6587377\n",
      "TRAIN: Batch: 0.48608727035853555 Loss: 5.624387\n",
      "TRAIN: Batch: 0.48705557169391117 Loss: 3.1637344\n",
      "TRAIN: Batch: 0.48802387302928674 Loss: 4.45544\n",
      "TRAIN: Batch: 0.4889921743646623 Loss: 3.7839546\n",
      "TRAIN: Batch: 0.48996047570003787 Loss: 8.670853\n",
      "TRAIN: Batch: 0.49092877703541343 Loss: 1.9701364\n",
      "TRAIN: Batch: 0.491897078370789 Loss: 3.040503\n",
      "TRAIN: Batch: 0.49286537970616456 Loss: 3.2671256\n",
      "TRAIN: Batch: 0.49383368104154013 Loss: 3.1279988\n",
      "TRAIN: Batch: 0.4948019823769157 Loss: 6.3699727\n",
      "TRAIN: Batch: 0.49577028371229126 Loss: 3.182983\n",
      "TRAIN: Batch: 0.4967385850476668 Loss: 5.663402\n",
      "TRAIN: Batch: 0.4977068863830424 Loss: 3.8834858\n",
      "TRAIN: Batch: 0.49867518771841796 Loss: 5.7863164\n",
      "TRAIN: Batch: 0.4996434890537935 Loss: 7.4437385\n",
      "TRAIN: Batch: 0.5006117903891691 Loss: 4.759711\n",
      "TRAIN: Batch: 0.5015800917245447 Loss: 5.4290156\n",
      "TRAIN: Batch: 0.5025483930599203 Loss: 4.1225343\n",
      "TRAIN: Batch: 0.5035166943952958 Loss: 3.200508\n",
      "TRAIN: Batch: 0.5044849957306714 Loss: 7.4704747\n",
      "TRAIN: Batch: 0.5054532970660469 Loss: 2.6782792\n",
      "TRAIN: Batch: 0.5064215984014225 Loss: 4.607209\n",
      "TRAIN: Batch: 0.507389899736798 Loss: 4.35788\n",
      "TRAIN: Batch: 0.5083582010721737 Loss: 11.162888\n",
      "TRAIN: Batch: 0.5093265024075492 Loss: 11.748129\n",
      "TRAIN: Batch: 0.5102948037429248 Loss: 9.734872\n",
      "TRAIN: Batch: 0.5112631050783004 Loss: 7.6391\n",
      "TRAIN: Batch: 0.5122314064136759 Loss: 4.2064037\n",
      "TRAIN: Batch: 0.5131997077490515 Loss: 3.649863\n",
      "TRAIN: Batch: 0.5141680090844271 Loss: 3.0836945\n",
      "TRAIN: Batch: 0.5151363104198027 Loss: 5.085001\n",
      "TRAIN: Batch: 0.5161046117551782 Loss: 4.141209\n",
      "TRAIN: Batch: 0.5170729130905538 Loss: 7.569785\n",
      "TRAIN: Batch: 0.5180412144259293 Loss: 3.3304653\n",
      "TRAIN: Batch: 0.5190095157613049 Loss: 5.7225723\n",
      "TRAIN: Batch: 0.5199778170966805 Loss: 4.1238527\n",
      "TRAIN: Batch: 0.5209461184320561 Loss: 3.3874772\n",
      "TRAIN: Batch: 0.5219144197674316 Loss: 4.314874\n",
      "TRAIN: Batch: 0.5228827211028072 Loss: 4.189871\n",
      "TRAIN: Batch: 0.5238510224381827 Loss: 5.434147\n",
      "TRAIN: Batch: 0.5248193237735583 Loss: 10.030144\n",
      "TRAIN: Batch: 0.525787625108934 Loss: 6.803127\n",
      "TRAIN: Batch: 0.5267559264443095 Loss: 2.6129441\n",
      "TRAIN: Batch: 0.5277242277796851 Loss: 4.786927\n",
      "TRAIN: Batch: 0.5286925291150606 Loss: 8.056516\n",
      "TRAIN: Batch: 0.5296608304504362 Loss: 3.9590962\n",
      "TRAIN: Batch: 0.5306291317858117 Loss: 16.849405\n",
      "TRAIN: Batch: 0.5315974331211873 Loss: 13.941052\n",
      "TRAIN: Batch: 0.5325657344565629 Loss: 4.0286593\n",
      "TRAIN: Batch: 0.5335340357919385 Loss: 2.3350182\n",
      "TRAIN: Batch: 0.534502337127314 Loss: 3.2729805\n",
      "TRAIN: Batch: 0.5354706384626896 Loss: 8.433739\n",
      "TRAIN: Batch: 0.5364389397980651 Loss: 6.6695676\n",
      "TRAIN: Batch: 0.5374072411334407 Loss: 3.9660144\n",
      "TRAIN: Batch: 0.5383755424688162 Loss: 2.4605212\n",
      "TRAIN: Batch: 0.5393438438041919 Loss: 7.679036\n",
      "TRAIN: Batch: 0.5403121451395674 Loss: 4.5351963\n",
      "TRAIN: Batch: 0.541280446474943 Loss: 4.827878\n",
      "TRAIN: Batch: 0.5422487478103186 Loss: 3.3843725\n",
      "TRAIN: Batch: 0.5432170491456941 Loss: 4.126576\n",
      "TRAIN: Batch: 0.5441853504810698 Loss: 4.155329\n",
      "TRAIN: Batch: 0.5451536518164453 Loss: 3.7485168\n",
      "TRAIN: Batch: 0.5461219531518209 Loss: 3.0014672\n",
      "TRAIN: Batch: 0.5470902544871964 Loss: 8.545671\n",
      "TRAIN: Batch: 0.548058555822572 Loss: 3.266365\n",
      "TRAIN: Batch: 0.5490268571579475 Loss: 7.7077684\n",
      "TRAIN: Batch: 0.5499951584933231 Loss: 2.0970807\n",
      "TRAIN: Batch: 0.5509634598286987 Loss: 4.3325896\n",
      "TRAIN: Batch: 0.5519317611640743 Loss: 4.22148\n",
      "TRAIN: Batch: 0.5529000624994498 Loss: 6.3959103\n",
      "TRAIN: Batch: 0.5538683638348254 Loss: 5.900439\n",
      "TRAIN: Batch: 0.5548366651702009 Loss: 3.6310835\n",
      "TRAIN: Batch: 0.5558049665055765 Loss: 3.092567\n",
      "TRAIN: Batch: 0.5567732678409522 Loss: 4.413779\n",
      "TRAIN: Batch: 0.5577415691763277 Loss: 3.7641022\n",
      "TRAIN: Batch: 0.5587098705117033 Loss: 7.553306\n",
      "TRAIN: Batch: 0.5596781718470788 Loss: 4.0286746\n",
      "TRAIN: Batch: 0.5606464731824544 Loss: 8.282678\n",
      "TRAIN: Batch: 0.5616147745178299 Loss: 3.2265844\n",
      "TRAIN: Batch: 0.5625830758532055 Loss: 7.29621\n",
      "TRAIN: Batch: 0.5635513771885811 Loss: 1.8154056\n",
      "TRAIN: Batch: 0.5645196785239567 Loss: 3.807552\n",
      "TRAIN: Batch: 0.5654879798593322 Loss: 4.026055\n",
      "TRAIN: Batch: 0.5664562811947078 Loss: 3.8403466\n",
      "TRAIN: Batch: 0.5674245825300833 Loss: 3.3382008\n",
      "TRAIN: Batch: 0.5683928838654589 Loss: 3.9437404\n",
      "TRAIN: Batch: 0.5693611852008345 Loss: 2.108829\n",
      "TRAIN: Batch: 0.5703294865362101 Loss: 9.706141\n",
      "TRAIN: Batch: 0.5712977878715856 Loss: 3.6860993\n",
      "TRAIN: Batch: 0.5722660892069612 Loss: 2.2690828\n",
      "TRAIN: Batch: 0.5732343905423368 Loss: 4.3669844\n",
      "TRAIN: Batch: 0.5742026918777123 Loss: 3.8977356\n",
      "TRAIN: Batch: 0.575170993213088 Loss: 1.7970158\n",
      "TRAIN: Batch: 0.5761392945484635 Loss: 4.1877766\n",
      "TRAIN: Batch: 0.5771075958838391 Loss: 10.437982\n",
      "TRAIN: Batch: 0.5780758972192146 Loss: 3.1582632\n",
      "TRAIN: Batch: 0.5790441985545902 Loss: 3.5864978\n",
      "TRAIN: Batch: 0.5800124998899657 Loss: 1.8772273\n",
      "TRAIN: Batch: 0.5809808012253413 Loss: 6.2211924\n",
      "TRAIN: Batch: 0.5819491025607169 Loss: 2.7422113\n",
      "TRAIN: Batch: 0.5829174038960925 Loss: 5.159154\n",
      "TRAIN: Batch: 0.583885705231468 Loss: 10.499345\n",
      "TRAIN: Batch: 0.5848540065668436 Loss: 7.935295\n",
      "TRAIN: Batch: 0.5858223079022191 Loss: 3.4179692\n",
      "TRAIN: Batch: 0.5867906092375947 Loss: 10.465909\n",
      "TRAIN: Batch: 0.5877589105729704 Loss: 3.271701\n",
      "TRAIN: Batch: 0.5887272119083459 Loss: 4.629466\n",
      "TRAIN: Batch: 0.5896955132437215 Loss: 2.4399297\n",
      "TRAIN: Batch: 0.590663814579097 Loss: 1.677075\n",
      "TRAIN: Batch: 0.5916321159144726 Loss: 6.954653\n",
      "TRAIN: Batch: 0.5926004172498481 Loss: 8.180403\n",
      "TRAIN: Batch: 0.5935687185852238 Loss: 4.4324384\n",
      "TRAIN: Batch: 0.5945370199205993 Loss: 6.7812886\n",
      "TRAIN: Batch: 0.5955053212559749 Loss: 4.2498116\n",
      "TRAIN: Batch: 0.5964736225913504 Loss: 7.781993\n",
      "TRAIN: Batch: 0.597441923926726 Loss: 7.1159277\n",
      "TRAIN: Batch: 0.5984102252621015 Loss: 4.5794992\n",
      "TRAIN: Batch: 0.5993785265974771 Loss: 3.172808\n",
      "TRAIN: Batch: 0.6003468279328527 Loss: 5.340694\n",
      "TRAIN: Batch: 0.6013151292682283 Loss: 3.9471745\n",
      "TRAIN: Batch: 0.6022834306036038 Loss: 5.6796756\n",
      "TRAIN: Batch: 0.6032517319389794 Loss: 8.867246\n",
      "TRAIN: Batch: 0.604220033274355 Loss: 4.8960066\n",
      "TRAIN: Batch: 0.6051883346097305 Loss: 2.7257044\n",
      "TRAIN: Batch: 0.6061566359451062 Loss: 2.665595\n",
      "TRAIN: Batch: 0.6071249372804817 Loss: 5.61282\n",
      "TRAIN: Batch: 0.6080932386158573 Loss: 5.0341783\n",
      "TRAIN: Batch: 0.6090615399512328 Loss: 6.715068\n",
      "TRAIN: Batch: 0.6100298412866084 Loss: 2.1302814\n",
      "TRAIN: Batch: 0.6109981426219839 Loss: 6.019631\n",
      "TRAIN: Batch: 0.6119664439573596 Loss: 1.68294\n",
      "TRAIN: Batch: 0.6129347452927351 Loss: 7.041386\n",
      "TRAIN: Batch: 0.6139030466281107 Loss: 5.860607\n",
      "TRAIN: Batch: 0.6148713479634862 Loss: 5.4577303\n",
      "TRAIN: Batch: 0.6158396492988618 Loss: 2.8073878\n",
      "TRAIN: Batch: 0.6168079506342373 Loss: 3.8175712\n",
      "TRAIN: Batch: 0.6177762519696129 Loss: 3.843745\n",
      "TRAIN: Batch: 0.6187445533049886 Loss: 6.039768\n",
      "TRAIN: Batch: 0.6197128546403641 Loss: 5.9944925\n",
      "TRAIN: Batch: 0.6206811559757397 Loss: 2.0483816\n",
      "TRAIN: Batch: 0.6216494573111152 Loss: 4.828405\n",
      "TRAIN: Batch: 0.6226177586464908 Loss: 6.266923\n",
      "TRAIN: Batch: 0.6235860599818663 Loss: 7.0823073\n",
      "TRAIN: Batch: 0.624554361317242 Loss: 4.108884\n",
      "TRAIN: Batch: 0.6255226626526175 Loss: 3.553194\n",
      "TRAIN: Batch: 0.6264909639879931 Loss: 4.057563\n",
      "TRAIN: Batch: 0.6274592653233686 Loss: 6.6672883\n",
      "TRAIN: Batch: 0.6284275666587442 Loss: 3.3666918\n",
      "TRAIN: Batch: 0.6293958679941197 Loss: 2.750269\n",
      "TRAIN: Batch: 0.6303641693294953 Loss: 6.0250926\n",
      "TRAIN: Batch: 0.6313324706648709 Loss: 5.194761\n",
      "TRAIN: Batch: 0.6323007720002465 Loss: 3.3699534\n",
      "TRAIN: Batch: 0.633269073335622 Loss: 7.618151\n",
      "TRAIN: Batch: 0.6342373746709976 Loss: 5.168609\n",
      "TRAIN: Batch: 0.6352056760063732 Loss: 2.1699266\n",
      "TRAIN: Batch: 0.6361739773417487 Loss: 7.7311006\n",
      "TRAIN: Batch: 0.6371422786771244 Loss: 2.3791776\n",
      "TRAIN: Batch: 0.6381105800124999 Loss: 8.396403\n",
      "TRAIN: Batch: 0.6390788813478755 Loss: 3.561825\n",
      "TRAIN: Batch: 0.640047182683251 Loss: 4.5602303\n",
      "TRAIN: Batch: 0.6410154840186266 Loss: 3.9055374\n",
      "TRAIN: Batch: 0.6419837853540021 Loss: 6.8731184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.6429520866893778 Loss: 3.8177996\n",
      "TRAIN: Batch: 0.6439203880247533 Loss: 6.759048\n",
      "TRAIN: Batch: 0.6448886893601289 Loss: 3.5861278\n",
      "TRAIN: Batch: 0.6458569906955044 Loss: 6.903816\n",
      "TRAIN: Batch: 0.64682529203088 Loss: 5.7333994\n",
      "TRAIN: Batch: 0.6477935933662555 Loss: 3.8667982\n",
      "TRAIN: Batch: 0.6487618947016311 Loss: 2.020539\n",
      "TRAIN: Batch: 0.6497301960370068 Loss: 2.6296902\n",
      "TRAIN: Batch: 0.6506984973723823 Loss: 3.5185084\n",
      "TRAIN: Batch: 0.6516667987077579 Loss: 4.2178016\n",
      "TRAIN: Batch: 0.6526351000431334 Loss: 4.4442344\n",
      "TRAIN: Batch: 0.653603401378509 Loss: 6.875615\n",
      "TRAIN: Batch: 0.6545717027138845 Loss: 4.93185\n",
      "TRAIN: Batch: 0.6555400040492602 Loss: 8.395308\n",
      "TRAIN: Batch: 0.6565083053846357 Loss: 1.7829854\n",
      "TRAIN: Batch: 0.6574766067200113 Loss: 3.8914852\n",
      "TRAIN: Batch: 0.6584449080553868 Loss: 4.0883846\n",
      "TRAIN: Batch: 0.6594132093907624 Loss: 4.668467\n",
      "TRAIN: Batch: 0.6603815107261379 Loss: 5.6238117\n",
      "TRAIN: Batch: 0.6613498120615136 Loss: 2.0676184\n",
      "TRAIN: Batch: 0.6623181133968891 Loss: 2.1412709\n",
      "TRAIN: Batch: 0.6632864147322647 Loss: 4.7193484\n",
      "TRAIN: Batch: 0.6642547160676403 Loss: 2.2427163\n",
      "TRAIN: Batch: 0.6652230174030158 Loss: 4.131474\n",
      "TRAIN: Batch: 0.6661913187383914 Loss: 3.2016447\n",
      "TRAIN: Batch: 0.667159620073767 Loss: 8.465457\n",
      "TRAIN: Batch: 0.6681279214091426 Loss: 1.8638946\n",
      "TRAIN: Batch: 0.6690962227445181 Loss: 2.8059833\n",
      "TRAIN: Batch: 0.6700645240798937 Loss: 3.7270484\n",
      "TRAIN: Batch: 0.6710328254152692 Loss: 3.2312088\n",
      "TRAIN: Batch: 0.6720011267506448 Loss: 1.444812\n",
      "TRAIN: Batch: 0.6729694280860203 Loss: 3.8142245\n",
      "TRAIN: Batch: 0.673937729421396 Loss: 6.7812157\n",
      "TRAIN: Batch: 0.6749060307567715 Loss: 2.833853\n",
      "TRAIN: Batch: 0.6758743320921471 Loss: 3.860598\n",
      "TRAIN: Batch: 0.6768426334275226 Loss: 2.610414\n",
      "TRAIN: Batch: 0.6778109347628982 Loss: 3.0941298\n",
      "TRAIN: Batch: 0.6787792360982737 Loss: 1.6850863\n",
      "TRAIN: Batch: 0.6797475374336494 Loss: 1.7773192\n",
      "TRAIN: Batch: 0.680715838769025 Loss: 1.7053248\n",
      "TRAIN: Batch: 0.6816841401044005 Loss: 1.8944218\n",
      "TRAIN: Batch: 0.6826524414397761 Loss: 2.3041096\n",
      "TRAIN: Batch: 0.6836207427751516 Loss: 7.2134213\n",
      "TRAIN: Batch: 0.6845890441105272 Loss: 2.4062746\n",
      "TRAIN: Batch: 0.6855573454459027 Loss: 2.6198938\n",
      "TRAIN: Batch: 0.6865256467812784 Loss: 2.8238487\n",
      "TRAIN: Batch: 0.6874939481166539 Loss: 3.5940664\n",
      "TRAIN: Batch: 0.6884622494520295 Loss: 2.8669908\n",
      "TRAIN: Batch: 0.689430550787405 Loss: 3.5924566\n",
      "TRAIN: Batch: 0.6903988521227806 Loss: 13.060707\n",
      "TRAIN: Batch: 0.6913671534581561 Loss: 7.8133383\n",
      "TRAIN: Batch: 0.6923354547935318 Loss: 2.2288938\n",
      "TRAIN: Batch: 0.6933037561289073 Loss: 2.125946\n",
      "TRAIN: Batch: 0.6942720574642829 Loss: 2.7474182\n",
      "TRAIN: Batch: 0.6952403587996585 Loss: 1.667886\n",
      "TRAIN: Batch: 0.696208660135034 Loss: 3.8070776\n",
      "TRAIN: Batch: 0.6971769614704096 Loss: 1.9123905\n",
      "TRAIN: Batch: 0.6981452628057851 Loss: 1.8946077\n",
      "TRAIN: Batch: 0.6991135641411608 Loss: 2.955464\n",
      "TRAIN: Batch: 0.7000818654765363 Loss: 1.5226706\n",
      "TRAIN: Batch: 0.7010501668119119 Loss: 2.89602\n",
      "TRAIN: Batch: 0.7020184681472874 Loss: 4.19701\n",
      "TRAIN: Batch: 0.702986769482663 Loss: 2.9433434\n",
      "TRAIN: Batch: 0.7039550708180385 Loss: 2.170262\n",
      "TRAIN: Batch: 0.7049233721534142 Loss: 3.210173\n",
      "TRAIN: Batch: 0.7058916734887897 Loss: 6.705654\n",
      "TRAIN: Batch: 0.7068599748241653 Loss: 2.6570976\n",
      "TRAIN: Batch: 0.7078282761595408 Loss: 4.7317066\n",
      "TRAIN: Batch: 0.7087965774949164 Loss: 4.4481606\n",
      "TRAIN: Batch: 0.7097648788302919 Loss: 3.018084\n",
      "TRAIN: Batch: 0.7107331801656676 Loss: 1.9032447\n",
      "TRAIN: Batch: 0.7117014815010432 Loss: 6.209806\n",
      "TRAIN: Batch: 0.7126697828364187 Loss: 3.6813765\n",
      "TRAIN: Batch: 0.7136380841717943 Loss: 4.6848297\n",
      "TRAIN: Batch: 0.7146063855071698 Loss: 3.0763254\n",
      "TRAIN: Batch: 0.7155746868425454 Loss: 2.5804179\n",
      "TRAIN: Batch: 0.716542988177921 Loss: 1.7747389\n",
      "TRAIN: Batch: 0.7175112895132966 Loss: 3.770408\n",
      "TRAIN: Batch: 0.7184795908486721 Loss: 6.765953\n",
      "TRAIN: Batch: 0.7194478921840477 Loss: 2.5821779\n",
      "TRAIN: Batch: 0.7204161935194232 Loss: 4.8585978\n",
      "TRAIN: Batch: 0.7213844948547988 Loss: 6.0031223\n",
      "TRAIN: Batch: 0.7223527961901743 Loss: 5.228586\n",
      "TRAIN: Batch: 0.72332109752555 Loss: 1.6550084\n",
      "TRAIN: Batch: 0.7242893988609255 Loss: 3.3801847\n",
      "TRAIN: Batch: 0.7252577001963011 Loss: 3.7155902\n",
      "TRAIN: Batch: 0.7262260015316767 Loss: 5.3047566\n",
      "TRAIN: Batch: 0.7271943028670522 Loss: 1.8848776\n",
      "TRAIN: Batch: 0.7281626042024278 Loss: 1.3945458\n",
      "TRAIN: Batch: 0.7291309055378034 Loss: 4.6446333\n",
      "TRAIN: Batch: 0.730099206873179 Loss: 7.3658266\n",
      "TRAIN: Batch: 0.7310675082085545 Loss: 4.062152\n",
      "TRAIN: Batch: 0.7320358095439301 Loss: 4.6592526\n",
      "TRAIN: Batch: 0.7330041108793056 Loss: 2.3617203\n",
      "TRAIN: Batch: 0.7339724122146812 Loss: 4.0655284\n",
      "TRAIN: Batch: 0.7349407135500567 Loss: 4.0664525\n",
      "TRAIN: Batch: 0.7359090148854324 Loss: 3.6340811\n",
      "TRAIN: Batch: 0.7368773162208079 Loss: 3.8513854\n",
      "TRAIN: Batch: 0.7378456175561835 Loss: 3.2209277\n",
      "TRAIN: Batch: 0.738813918891559 Loss: 1.8607314\n",
      "TRAIN: Batch: 0.7397822202269346 Loss: 4.602792\n",
      "TRAIN: Batch: 0.7407505215623101 Loss: 6.3092394\n",
      "TRAIN: Batch: 0.7417188228976858 Loss: 5.906773\n",
      "TRAIN: Batch: 0.7426871242330614 Loss: 5.925563\n",
      "TRAIN: Batch: 0.7436554255684369 Loss: 3.5053344\n",
      "TRAIN: Batch: 0.7446237269038125 Loss: 3.6548288\n",
      "TRAIN: Batch: 0.745592028239188 Loss: 3.5237987\n",
      "TRAIN: Batch: 0.7465603295745636 Loss: 3.4988825\n",
      "TRAIN: Batch: 0.7475286309099392 Loss: 1.1416771\n",
      "TRAIN: Batch: 0.7484969322453148 Loss: 4.964242\n",
      "TRAIN: Batch: 0.7494652335806903 Loss: 2.8996673\n",
      "TRAIN: Batch: 0.7504335349160659 Loss: 2.3317087\n",
      "TRAIN: Batch: 0.7514018362514414 Loss: 3.4488888\n",
      "TRAIN: Batch: 0.752370137586817 Loss: 3.1883428\n",
      "TRAIN: Batch: 0.7533384389221925 Loss: 1.0830774\n",
      "TRAIN: Batch: 0.7543067402575682 Loss: 3.145644\n",
      "TRAIN: Batch: 0.7552750415929437 Loss: 4.769691\n",
      "TRAIN: Batch: 0.7562433429283193 Loss: 3.0795045\n",
      "TRAIN: Batch: 0.7572116442636949 Loss: 3.5540183\n",
      "TRAIN: Batch: 0.7581799455990704 Loss: 1.1693234\n",
      "TRAIN: Batch: 0.759148246934446 Loss: 3.0818965\n",
      "TRAIN: Batch: 0.7601165482698216 Loss: 5.4032984\n",
      "TRAIN: Batch: 0.7610848496051972 Loss: 2.0840816\n",
      "TRAIN: Batch: 0.7620531509405727 Loss: 3.15074\n",
      "TRAIN: Batch: 0.7630214522759483 Loss: 6.2616143\n",
      "TRAIN: Batch: 0.7639897536113238 Loss: 3.3896704\n",
      "TRAIN: Batch: 0.7649580549466994 Loss: 1.6377226\n",
      "TRAIN: Batch: 0.765926356282075 Loss: 1.5781615\n",
      "TRAIN: Batch: 0.7668946576174506 Loss: 5.1441145\n",
      "TRAIN: Batch: 0.7678629589528261 Loss: 3.1609917\n",
      "TRAIN: Batch: 0.7688312602882017 Loss: 4.759027\n",
      "TRAIN: Batch: 0.7697995616235772 Loss: 4.735128\n",
      "TRAIN: Batch: 0.7707678629589528 Loss: 7.0565014\n",
      "TRAIN: Batch: 0.7717361642943283 Loss: 1.7301636\n",
      "TRAIN: Batch: 0.772704465629704 Loss: 2.2812946\n",
      "TRAIN: Batch: 0.7736727669650796 Loss: 4.1195397\n",
      "TRAIN: Batch: 0.7746410683004551 Loss: 4.7727213\n",
      "TRAIN: Batch: 0.7756093696358307 Loss: 5.1919427\n",
      "TRAIN: Batch: 0.7765776709712062 Loss: 5.643033\n",
      "TRAIN: Batch: 0.7775459723065818 Loss: 2.4750361\n",
      "TRAIN: Batch: 0.7785142736419574 Loss: 7.8896537\n",
      "TRAIN: Batch: 0.779482574977333 Loss: 2.2508633\n",
      "TRAIN: Batch: 0.7804508763127085 Loss: 4.14937\n",
      "TRAIN: Batch: 0.7814191776480841 Loss: 4.3058224\n",
      "TRAIN: Batch: 0.7823874789834596 Loss: 3.4948082\n",
      "TRAIN: Batch: 0.7833557803188352 Loss: 7.706482\n",
      "TRAIN: Batch: 0.7843240816542107 Loss: 4.3482594\n",
      "TRAIN: Batch: 0.7852923829895864 Loss: 3.3484669\n",
      "TRAIN: Batch: 0.7862606843249619 Loss: 1.6018537\n",
      "TRAIN: Batch: 0.7872289856603375 Loss: 2.703746\n",
      "TRAIN: Batch: 0.7881972869957131 Loss: 6.8892727\n",
      "TRAIN: Batch: 0.7891655883310886 Loss: 4.197348\n",
      "TRAIN: Batch: 0.7901338896664643 Loss: 1.8229587\n",
      "TRAIN: Batch: 0.7911021910018398 Loss: 5.0166793\n",
      "TRAIN: Batch: 0.7920704923372154 Loss: 3.3695104\n",
      "TRAIN: Batch: 0.7930387936725909 Loss: 4.1583033\n",
      "TRAIN: Batch: 0.7940070950079665 Loss: 2.8565102\n",
      "TRAIN: Batch: 0.794975396343342 Loss: 4.484128\n",
      "TRAIN: Batch: 0.7959436976787176 Loss: 6.208813\n",
      "TRAIN: Batch: 0.7969119990140932 Loss: 6.872699\n",
      "TRAIN: Batch: 0.7978803003494688 Loss: 6.1559973\n",
      "TRAIN: Batch: 0.7988486016848443 Loss: 1.7730445\n",
      "TRAIN: Batch: 0.7998169030202199 Loss: 6.5172553\n",
      "TRAIN: Batch: 0.8007852043555954 Loss: 6.0228095\n",
      "TRAIN: Batch: 0.801753505690971 Loss: 1.7216296\n",
      "TRAIN: Batch: 0.8027218070263465 Loss: 4.85032\n",
      "TRAIN: Batch: 0.8036901083617222 Loss: 6.5579987\n",
      "TRAIN: Batch: 0.8046584096970978 Loss: 1.3656119\n",
      "TRAIN: Batch: 0.8056267110324733 Loss: 1.9960796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.8065950123678489 Loss: 3.0869536\n",
      "TRAIN: Batch: 0.8075633137032244 Loss: 3.992953\n",
      "TRAIN: Batch: 0.8085316150386 Loss: 4.3401012\n",
      "TRAIN: Batch: 0.8094999163739756 Loss: 5.656549\n",
      "TRAIN: Batch: 0.8104682177093512 Loss: 1.6772228\n",
      "TRAIN: Batch: 0.8114365190447267 Loss: 3.980864\n",
      "TRAIN: Batch: 0.8124048203801023 Loss: 5.39812\n",
      "TRAIN: Batch: 0.8133731217154778 Loss: 5.806828\n",
      "TRAIN: Batch: 0.8143414230508534 Loss: 2.6357431\n",
      "TRAIN: Batch: 0.815309724386229 Loss: 2.650655\n",
      "TRAIN: Batch: 0.8162780257216046 Loss: 3.4787593\n",
      "TRAIN: Batch: 0.8172463270569801 Loss: 5.091568\n",
      "TRAIN: Batch: 0.8182146283923557 Loss: 2.5853224\n",
      "TRAIN: Batch: 0.8191829297277313 Loss: 3.4315958\n",
      "TRAIN: Batch: 0.8201512310631068 Loss: 6.26151\n",
      "TRAIN: Batch: 0.8211195323984825 Loss: 2.5418086\n",
      "TRAIN: Batch: 0.822087833733858 Loss: 2.06443\n",
      "TRAIN: Batch: 0.8230561350692336 Loss: 5.692156\n",
      "TRAIN: Batch: 0.8240244364046091 Loss: 1.643204\n",
      "TRAIN: Batch: 0.8249927377399847 Loss: 2.2458346\n",
      "TRAIN: Batch: 0.8259610390753602 Loss: 2.3441105\n",
      "TRAIN: Batch: 0.8269293404107358 Loss: 1.5206707\n",
      "TRAIN: Batch: 0.8278976417461114 Loss: 2.3362916\n",
      "TRAIN: Batch: 0.828865943081487 Loss: 1.1461332\n",
      "TRAIN: Batch: 0.8298342444168625 Loss: 3.0935187\n",
      "TRAIN: Batch: 0.8308025457522381 Loss: 2.6849537\n",
      "TRAIN: Batch: 0.8317708470876136 Loss: 3.30536\n",
      "TRAIN: Batch: 0.8327391484229892 Loss: 2.7916703\n",
      "TRAIN: Batch: 0.8337074497583647 Loss: 1.8995517\n",
      "TRAIN: Batch: 0.8346757510937404 Loss: 3.5743103\n",
      "TRAIN: Batch: 0.835644052429116 Loss: 2.1360383\n",
      "TRAIN: Batch: 0.8366123537644915 Loss: 4.0280695\n",
      "TRAIN: Batch: 0.8375806550998671 Loss: 3.852449\n",
      "TRAIN: Batch: 0.8385489564352426 Loss: 4.1886296\n",
      "TRAIN: Batch: 0.8395172577706183 Loss: 1.5662396\n",
      "TRAIN: Batch: 0.8404855591059938 Loss: 2.8455312\n",
      "TRAIN: Batch: 0.8414538604413694 Loss: 1.6133492\n",
      "TRAIN: Batch: 0.8424221617767449 Loss: 7.0801544\n",
      "TRAIN: Batch: 0.8433904631121205 Loss: 1.6043527\n",
      "TRAIN: Batch: 0.844358764447496 Loss: 4.5060554\n",
      "TRAIN: Batch: 0.8453270657828716 Loss: 1.3062897\n",
      "TRAIN: Batch: 0.8462953671182472 Loss: 5.221471\n",
      "TRAIN: Batch: 0.8472636684536228 Loss: 3.4088259\n",
      "TRAIN: Batch: 0.8482319697889983 Loss: 4.72493\n",
      "TRAIN: Batch: 0.8492002711243739 Loss: 6.492601\n",
      "TRAIN: Batch: 0.8501685724597495 Loss: 3.2509422\n",
      "TRAIN: Batch: 0.851136873795125 Loss: 3.2938945\n",
      "TRAIN: Batch: 0.8521051751305007 Loss: 3.4076715\n",
      "TRAIN: Batch: 0.8530734764658762 Loss: 3.0747313\n",
      "TRAIN: Batch: 0.8540417778012518 Loss: 1.4598393\n",
      "TRAIN: Batch: 0.8550100791366273 Loss: 3.2201667\n",
      "TRAIN: Batch: 0.8559783804720029 Loss: 11.642537\n",
      "TRAIN: Batch: 0.8569466818073784 Loss: 2.4461958\n",
      "TRAIN: Batch: 0.857914983142754 Loss: 3.6725862\n",
      "TRAIN: Batch: 0.8588832844781296 Loss: 7.004763\n",
      "TRAIN: Batch: 0.8598515858135052 Loss: 5.7708254\n",
      "TRAIN: Batch: 0.8608198871488807 Loss: 7.3635645\n",
      "TRAIN: Batch: 0.8617881884842563 Loss: 2.0921903\n",
      "TRAIN: Batch: 0.8627564898196318 Loss: 2.492149\n",
      "TRAIN: Batch: 0.8637247911550074 Loss: 5.649463\n",
      "TRAIN: Batch: 0.864693092490383 Loss: 3.3413582\n",
      "TRAIN: Batch: 0.8656613938257586 Loss: 1.5977364\n",
      "TRAIN: Batch: 0.8666296951611342 Loss: 3.2801666\n",
      "TRAIN: Batch: 0.8675979964965097 Loss: 4.7702\n",
      "TRAIN: Batch: 0.8685662978318853 Loss: 3.1805444\n",
      "TRAIN: Batch: 0.8695345991672608 Loss: 4.1171837\n",
      "TRAIN: Batch: 0.8705029005026365 Loss: 2.2388115\n",
      "TRAIN: Batch: 0.871471201838012 Loss: 5.0114584\n",
      "TRAIN: Batch: 0.8724395031733876 Loss: 7.2831416\n",
      "TRAIN: Batch: 0.8734078045087631 Loss: 4.351378\n",
      "TRAIN: Batch: 0.8743761058441387 Loss: 1.6686332\n",
      "TRAIN: Batch: 0.8753444071795142 Loss: 3.1479125\n",
      "TRAIN: Batch: 0.8763127085148898 Loss: 2.9549747\n",
      "TRAIN: Batch: 0.8772810098502654 Loss: 2.7844274\n",
      "TRAIN: Batch: 0.878249311185641 Loss: 3.0238144\n",
      "TRAIN: Batch: 0.8792176125210165 Loss: 1.3205702\n",
      "TRAIN: Batch: 0.8801859138563921 Loss: 3.9475133\n",
      "TRAIN: Batch: 0.8811542151917677 Loss: 2.9435656\n",
      "TRAIN: Batch: 0.8821225165271432 Loss: 0.68319786\n",
      "TRAIN: Batch: 0.8830908178625189 Loss: 1.9600767\n",
      "TRAIN: Batch: 0.8840591191978944 Loss: 1.8134588\n",
      "TRAIN: Batch: 0.88502742053327 Loss: 3.743541\n",
      "TRAIN: Batch: 0.8859957218686455 Loss: 4.584995\n",
      "TRAIN: Batch: 0.8869640232040211 Loss: 5.59477\n",
      "TRAIN: Batch: 0.8879323245393966 Loss: 2.1756482\n",
      "TRAIN: Batch: 0.8889006258747723 Loss: 4.311799\n",
      "TRAIN: Batch: 0.8898689272101478 Loss: 8.78086\n",
      "TRAIN: Batch: 0.8908372285455234 Loss: 2.5583973\n",
      "TRAIN: Batch: 0.8918055298808989 Loss: 1.3433819\n",
      "TRAIN: Batch: 0.8927738312162745 Loss: 3.4720976\n",
      "TRAIN: Batch: 0.89374213255165 Loss: 4.654725\n",
      "TRAIN: Batch: 0.8947104338870256 Loss: 3.8309517\n",
      "TRAIN: Batch: 0.8956787352224012 Loss: 2.0138395\n",
      "TRAIN: Batch: 0.8966470365577768 Loss: 1.5275114\n",
      "TRAIN: Batch: 0.8976153378931524 Loss: 4.0941277\n",
      "TRAIN: Batch: 0.8985836392285279 Loss: 5.385753\n",
      "TRAIN: Batch: 0.8995519405639035 Loss: 3.5149512\n",
      "TRAIN: Batch: 0.900520241899279 Loss: 3.762449\n",
      "TRAIN: Batch: 0.9014885432346547 Loss: 4.9472733\n",
      "TRAIN: Batch: 0.9024568445700302 Loss: 6.968816\n",
      "TRAIN: Batch: 0.9034251459054058 Loss: 1.0910985\n",
      "TRAIN: Batch: 0.9043934472407813 Loss: 3.1424587\n",
      "TRAIN: Batch: 0.9053617485761569 Loss: 6.4723177\n",
      "TRAIN: Batch: 0.9063300499115324 Loss: 3.5521467\n",
      "TRAIN: Batch: 0.907298351246908 Loss: 2.7966182\n",
      "TRAIN: Batch: 0.9082666525822836 Loss: 5.199403\n",
      "TRAIN: Batch: 0.9092349539176592 Loss: 3.0748925\n",
      "TRAIN: Batch: 0.9102032552530347 Loss: 2.4300766\n",
      "TRAIN: Batch: 0.9111715565884103 Loss: 4.4226\n",
      "TRAIN: Batch: 0.9121398579237859 Loss: 2.1297445\n",
      "TRAIN: Batch: 0.9131081592591614 Loss: 1.9306238\n",
      "TRAIN: Batch: 0.9140764605945371 Loss: 4.298543\n",
      "TRAIN: Batch: 0.9150447619299126 Loss: 4.693494\n",
      "TRAIN: Batch: 0.9160130632652882 Loss: 3.2244012\n",
      "TRAIN: Batch: 0.9169813646006637 Loss: 2.4281256\n",
      "TRAIN: Batch: 0.9179496659360393 Loss: 7.6573324\n",
      "TRAIN: Batch: 0.9189179672714148 Loss: 2.3182583\n",
      "TRAIN: Batch: 0.9198862686067905 Loss: 2.431376\n",
      "TRAIN: Batch: 0.920854569942166 Loss: 2.041334\n",
      "TRAIN: Batch: 0.9218228712775416 Loss: 4.264728\n",
      "TRAIN: Batch: 0.9227911726129171 Loss: 1.5416894\n",
      "TRAIN: Batch: 0.9237594739482927 Loss: 1.3359914\n",
      "TRAIN: Batch: 0.9247277752836682 Loss: 2.843858\n",
      "TRAIN: Batch: 0.9256960766190439 Loss: 5.6876683\n",
      "TRAIN: Batch: 0.9266643779544194 Loss: 1.7082311\n",
      "TRAIN: Batch: 0.927632679289795 Loss: 1.4603705\n",
      "TRAIN: Batch: 0.9286009806251706 Loss: 2.5978835\n",
      "TRAIN: Batch: 0.9295692819605461 Loss: 2.3506827\n",
      "TRAIN: Batch: 0.9305375832959217 Loss: 2.9481385\n",
      "TRAIN: Batch: 0.9315058846312972 Loss: 3.7445872\n",
      "TRAIN: Batch: 0.9324741859666729 Loss: 5.8857884\n",
      "TRAIN: Batch: 0.9334424873020484 Loss: 3.3803706\n",
      "TRAIN: Batch: 0.934410788637424 Loss: 1.2465322\n",
      "TRAIN: Batch: 0.9353790899727995 Loss: 3.615629\n",
      "TRAIN: Batch: 0.9363473913081751 Loss: 2.0110774\n",
      "TRAIN: Batch: 0.9373156926435506 Loss: 3.9532404\n",
      "TRAIN: Batch: 0.9382839939789263 Loss: 1.2982823\n",
      "TRAIN: Batch: 0.9392522953143018 Loss: 0.9880974\n",
      "TRAIN: Batch: 0.9402205966496774 Loss: 2.396078\n",
      "TRAIN: Batch: 0.9411888979850529 Loss: 3.432641\n",
      "TRAIN: Batch: 0.9421571993204285 Loss: 4.1751695\n",
      "TRAIN: Batch: 0.9431255006558041 Loss: 2.1197937\n",
      "TRAIN: Batch: 0.9440938019911796 Loss: 6.4352417\n",
      "TRAIN: Batch: 0.9450621033265553 Loss: 3.0176969\n",
      "TRAIN: Batch: 0.9460304046619308 Loss: 1.6892886\n",
      "TRAIN: Batch: 0.9469987059973064 Loss: 1.6291411\n",
      "TRAIN: Batch: 0.9479670073326819 Loss: 3.5801387\n",
      "TRAIN: Batch: 0.9489353086680575 Loss: 5.22578\n",
      "TRAIN: Batch: 0.949903610003433 Loss: 6.339419\n",
      "TRAIN: Batch: 0.9508719113388087 Loss: 1.111587\n",
      "TRAIN: Batch: 0.9518402126741842 Loss: 3.3648853\n",
      "TRAIN: Batch: 0.9528085140095598 Loss: 1.9925294\n",
      "TRAIN: Batch: 0.9537768153449353 Loss: 3.0633078\n",
      "TRAIN: Batch: 0.9547451166803109 Loss: 2.6559\n",
      "TRAIN: Batch: 0.9557134180156864 Loss: 2.4130788\n",
      "TRAIN: Batch: 0.956681719351062 Loss: 1.1563905\n",
      "TRAIN: Batch: 0.9576500206864376 Loss: 1.5506239\n",
      "TRAIN: Batch: 0.9586183220218132 Loss: 1.8832879\n",
      "TRAIN: Batch: 0.9595866233571888 Loss: 1.4454646\n",
      "TRAIN: Batch: 0.9605549246925643 Loss: 2.9228191\n",
      "TRAIN: Batch: 0.9615232260279399 Loss: 3.691591\n",
      "TRAIN: Batch: 0.9624915273633154 Loss: 0.7365695\n",
      "TRAIN: Batch: 0.9634598286986911 Loss: 1.1114844\n",
      "TRAIN: Batch: 0.9644281300340666 Loss: 2.1876419\n",
      "TRAIN: Batch: 0.9653964313694422 Loss: 0.86688185\n",
      "TRAIN: Batch: 0.9663647327048177 Loss: 2.531226\n",
      "TRAIN: Batch: 0.9673330340401933 Loss: 3.586959\n",
      "TRAIN: Batch: 0.9683013353755688 Loss: 2.3264039\n",
      "TRAIN: Batch: 0.9692696367109445 Loss: 3.240973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.97023793804632 Loss: 0.7233839\n",
      "TRAIN: Batch: 0.9712062393816956 Loss: 1.7606142\n",
      "TRAIN: Batch: 0.9721745407170711 Loss: 2.9956305\n",
      "TRAIN: Batch: 0.9731428420524467 Loss: 1.8629218\n",
      "TRAIN: Batch: 0.9741111433878223 Loss: 1.1057466\n",
      "TRAIN: Batch: 0.9750794447231979 Loss: 2.726692\n",
      "TRAIN: Batch: 0.9760477460585735 Loss: 4.395439\n",
      "TRAIN: Batch: 0.977016047393949 Loss: 5.3403006\n",
      "TRAIN: Batch: 0.9779843487293246 Loss: 1.658014\n",
      "TRAIN: Batch: 0.9789526500647001 Loss: 3.7428641\n",
      "TRAIN: Batch: 0.9799209514000757 Loss: 3.61937\n",
      "TRAIN: Batch: 0.9808892527354512 Loss: 3.1461062\n",
      "TRAIN: Batch: 0.9818575540708269 Loss: 1.5514914\n",
      "TRAIN: Batch: 0.9828258554062024 Loss: 2.478772\n",
      "TRAIN: Batch: 0.983794156741578 Loss: 2.5198839\n",
      "TRAIN: Batch: 0.9847624580769535 Loss: 2.9938028\n",
      "TRAIN: Batch: 0.9857307594123291 Loss: 2.3037105\n",
      "TRAIN: Batch: 0.9866990607477046 Loss: 5.8608413\n",
      "TRAIN: Batch: 0.9876673620830803 Loss: 3.341284\n",
      "TRAIN: Batch: 0.9886356634184559 Loss: 3.5761955\n",
      "TRAIN: Batch: 0.9896039647538314 Loss: 0.8613632\n",
      "TRAIN: Batch: 0.990572266089207 Loss: 1.8873233\n",
      "TRAIN: Batch: 0.9915405674245825 Loss: 3.2127206\n",
      "TRAIN: Batch: 0.9925088687599581 Loss: 7.470658\n",
      "TRAIN: Batch: 0.9934771700953337 Loss: 2.5675633\n",
      "TRAIN: Batch: 0.9944454714307093 Loss: 1.738304\n",
      "TRAIN: Batch: 0.9954137727660848 Loss: 2.8626075\n",
      "TRAIN: Batch: 0.9963820741014604 Loss: 1.8498842\n",
      "TRAIN: Batch: 0.9973503754368359 Loss: 3.2268734\n",
      "TRAIN: Batch: 0.9983186767722115 Loss: 1.5550336\n",
      "TRAIN: Batch: 0.999286978107587 Loss: 2.4443214\n",
      "Validating NN\n",
      "0\n",
      "4000\n",
      "8000\n",
      "12000\n",
      "16000\n",
      "20000\n",
      "24000\n",
      "28000\n",
      "32000\n",
      "36000\n",
      "40000\n",
      "44000\n",
      "48000\n",
      "52000\n",
      "56000\n",
      "60000\n",
      "64000\n",
      "68000\n",
      "72000\n",
      "76000\n",
      "80000\n",
      "84000\n",
      "88000\n",
      "92000\n",
      "96000\n",
      "100000\n",
      "104000\n",
      "108000\n",
      "112000\n",
      "116000\n",
      "120000\n",
      "124000\n",
      "128000\n",
      "132000\n",
      "136000\n",
      "140000\n",
      "144000\n",
      "148000\n",
      "152000\n",
      "156000\n",
      "160000\n",
      "164000\n",
      "168000\n",
      "172000\n",
      "176000\n",
      "180000\n",
      "184000\n",
      "188000\n",
      "192000\n",
      "196000\n",
      "200000\n",
      "204000\n",
      "208000\n",
      "212000\n",
      "216000\n",
      "220000\n",
      "224000\n",
      "228000\n",
      "232000\n",
      "236000\n",
      "240000\n",
      "244000\n",
      "248000\n",
      "252000\n",
      "256000\n",
      "260000\n",
      "264000\n",
      "268000\n",
      "272000\n",
      "276000\n",
      "280000\n",
      "284000\n",
      "288000\n",
      "292000\n",
      "296000\n",
      "300000\n",
      "304000\n",
      "308000\n",
      "312000\n",
      "316000\n",
      "320000\n",
      "324000\n",
      "328000\n",
      "332000\n",
      "336000\n",
      "340000\n",
      "344000\n",
      "348000\n",
      "352000\n",
      "356000\n",
      "360000\n",
      "364000\n",
      "368000\n",
      "372000\n",
      "376000\n",
      "380000\n",
      "384000\n",
      "388000\n",
      "392000\n",
      "396000\n",
      "400000\n",
      "404000\n",
      "408000\n",
      "412000\n",
      "416000\n",
      "420000\n",
      "424000\n",
      "428000\n",
      "432000\n",
      "436000\n",
      "440000\n",
      "444000\n",
      "448000\n",
      "452000\n",
      "456000\n",
      "460000\n",
      "464000\n",
      "468000\n",
      "472000\n",
      "476000\n",
      "480000\n",
      "484000\n",
      "488000\n",
      "492000\n",
      "496000\n",
      "500000\n",
      "504000\n",
      "508000\n",
      "512000\n",
      "516000\n",
      "520000\n",
      "524000\n",
      "528000\n",
      "532000\n",
      "536000\n",
      "540000\n",
      "544000\n",
      "548000\n",
      "552000\n",
      "556000\n",
      "560000\n",
      "564000\n",
      "568000\n",
      "572000\n",
      "576000\n",
      "580000\n",
      "584000\n",
      "588000\n",
      "592000\n",
      "596000\n",
      "600000\n",
      "604000\n",
      "608000\n",
      "612000\n",
      "616000\n",
      "620000\n",
      "624000\n",
      "628000\n",
      "632000\n",
      "636000\n",
      "640000\n",
      "644000\n",
      "648000\n",
      "652000\n",
      "656000\n",
      "660000\n",
      "664000\n",
      "668000\n",
      "672000\n",
      "676000\n",
      "680000\n",
      "684000\n",
      "688000\n",
      "692000\n",
      "696000\n",
      "700000\n",
      "704000\n",
      "708000\n",
      "712000\n",
      "716000\n",
      "720000\n",
      "724000\n",
      "728000\n",
      "732000\n",
      "736000\n",
      "740000\n",
      "744000\n",
      "748000\n",
      "752000\n",
      "756000\n",
      "760000\n",
      "764000\n",
      "768000\n",
      "772000\n",
      "776000\n",
      "780000\n",
      "784000\n",
      "788000\n",
      "792000\n",
      "796000\n",
      "800000\n",
      "804000\n",
      "808000\n",
      "812000\n",
      "816000\n",
      "820000\n",
      "824000\n",
      "828000\n",
      "832000\n",
      "836000\n",
      "840000\n",
      "844000\n",
      "848000\n",
      "852000\n",
      "856000\n",
      "860000\n",
      "864000\n",
      "868000\n",
      "872000\n",
      "876000\n",
      "880000\n",
      "884000\n",
      "888000\n",
      "892000\n",
      "896000\n",
      "900000\n",
      "904000\n",
      "908000\n",
      "912000\n",
      "916000\n",
      "920000\n",
      "924000\n",
      "928000\n",
      "932000\n",
      "936000\n",
      "940000\n",
      "944000\n",
      "948000\n",
      "952000\n",
      "956000\n",
      "960000\n",
      "964000\n",
      "968000\n",
      "972000\n",
      "976000\n",
      "980000\n",
      "984000\n",
      "988000\n",
      "992000\n",
      "996000\n",
      "1000000\n",
      "1004000\n",
      "1008000\n",
      "1012000\n",
      "1016000\n",
      "1020000\n",
      "1024000\n",
      "1028000\n",
      "1032000\n",
      "1036000\n",
      "1040000\n",
      "1044000\n",
      "1048000\n",
      "1052000\n",
      "1056000\n",
      "1060000\n",
      "1064000\n",
      "1068000\n",
      "1072000\n",
      "1076000\n",
      "1080000\n",
      "1084000\n",
      "1088000\n",
      "1092000\n",
      "1096000\n",
      "1100000\n",
      "1104000\n",
      "1108000\n",
      "1112000\n",
      "1116000\n",
      "1120000\n",
      "1124000\n",
      "1128000\n",
      "1132000\n",
      "1136000\n",
      "1140000\n",
      "1144000\n",
      "1148000\n",
      "1152000\n",
      "1156000\n",
      "1160000\n",
      "1164000\n",
      "1168000\n",
      "1172000\n",
      "1176000\n",
      "1180000\n",
      "1184000\n",
      "1188000\n",
      "1192000\n",
      "1196000\n",
      "1200000\n",
      "1204000\n",
      "1208000\n",
      "1212000\n",
      "1216000\n",
      "1220000\n",
      "1224000\n",
      "1228000\n",
      "1232000\n",
      "1236000\n",
      "1240000\n",
      "1244000\n",
      "1248000\n",
      "1252000\n",
      "1256000\n",
      "1260000\n",
      "1264000\n",
      "1268000\n",
      "1272000\n",
      "1276000\n",
      "1280000\n",
      "1284000\n",
      "1288000\n",
      "1292000\n",
      "1296000\n",
      "1300000\n",
      "1304000\n",
      "1308000\n",
      "1312000\n",
      "1316000\n",
      "1320000\n",
      "1324000\n",
      "1328000\n",
      "1332000\n",
      "1336000\n",
      "1340000\n",
      "1344000\n",
      "1348000\n",
      "1352000\n",
      "1356000\n",
      "1360000\n",
      "1364000\n",
      "1368000\n",
      "1372000\n",
      "1376000\n",
      "1380000\n",
      "1384000\n",
      "1388000\n",
      "1392000\n",
      "1396000\n",
      "1400000\n",
      "1404000\n",
      "1408000\n",
      "1412000\n",
      "1416000\n",
      "1420000\n",
      "1424000\n",
      "1428000\n",
      "1432000\n",
      "1436000\n",
      "1440000\n",
      "1444000\n",
      "1448000\n",
      "1452000\n",
      "1456000\n",
      "1460000\n",
      "1464000\n",
      "1468000\n",
      "1472000\n",
      "1476000\n",
      "1480000\n",
      "1484000\n",
      "1488000\n",
      "1492000\n",
      "1496000\n",
      "1500000\n",
      "1504000\n",
      "1508000\n",
      "1512000\n",
      "1516000\n",
      "1520000\n",
      "1524000\n",
      "1528000\n",
      "1532000\n",
      "1536000\n",
      "1540000\n",
      "1544000\n",
      "1548000\n",
      "1552000\n",
      "1556000\n",
      "1560000\n",
      "1564000\n",
      "1568000\n",
      "1572000\n",
      "1576000\n",
      "1580000\n",
      "1584000\n",
      "1588000\n",
      "1592000\n",
      "1596000\n",
      "1600000\n",
      "1604000\n",
      "1608000\n",
      "1612000\n",
      "1616000\n",
      "1620000\n",
      "1624000\n",
      "1628000\n",
      "1632000\n"
     ]
    }
   ],
   "source": [
    "decoderType = DecoderType.BestPath\n",
    "if args.beamsearch:\n",
    "    decoderType = DecoderType.BeamSearch\n",
    "elif args.wordbeamsearch:\n",
    "    decoderType = DecoderType.WordBeamSearch\n",
    "if args.train or args.validate:\n",
    "\n",
    "    # load training data, create TF model\n",
    "    # loader = DataLoader(FilePaths.fnTrain, args.batchsize, args.imgsize, Model.maxTextLen, args)\n",
    "    # testloader = DataLoader(FilePaths.fnTest, args.batchsize, args.imgsize, Model.maxTextLen, args, is_test=True)\n",
    "\n",
    "    # tnansforms#\n",
    "    transform_train = transforms.Compose([\n",
    "        # lambda img: (np.zeros([args.imgsize[1], args.imgsize[0]]) if img is None or np.min(img.shape) <= 1 else cv2.resize(img, (args.imgsize[1],args.imgsize[0]), interpolation=cv2.INTER_CUBIC)),\n",
    "        # lambda img: np.zeros([args.imgsize[1], args.imgsize[0]]) if (img is None or np.min(img.shape) <= 1) else cv2.resize(img, (args.imgsize[1],args.imgsize[0]), interpolation=cv2.INTER_CUBIC)\n",
    "        transforms.Lambda(\n",
    "            lambda img: cv2.resize(img, (args.imgsize[0], args.imgsize[1]), interpolation=cv2.INTER_CUBIC)),\n",
    "        # (img, (32,128), interpolation=cv2.INTER_CUBIC),\n",
    "        #transforms.Lambda(lambda img: add_artifacts(img, args)),\n",
    "        # transforms.Lambda(lambda img: img_normalize(img)),\n",
    "        transforms.Lambda(lambda img: cv2.transpose(img))\n",
    "        # lambda img: cv2.resize(img, (args.imgsize[1], args.imgsize[0]), interpolation=cv2.INTER_CUBIC),\n",
    "    ])\n",
    "\n",
    "    # yike: to use torch.transform.classes, please convert numpy to PIL first. i.e.transforms.Resize(size=(args.imgsize[1], args.imgsize[0]), interpolation=PIL.Image.BICUBIC)\n",
    "\n",
    "    # instantiate datasets\n",
    "    iam = IAM(args.dataroot, transform=transform_train)\n",
    "    eydigits = EyDigitStrings(args.dataroot, transform=transform_train)\n",
    "    #printed = PRT(args.dataroot, transform=transform_train)  # yike todo\n",
    "    printed =PRT_WORD(args.dataroot,transform=transform_train)\n",
    "    irs = IRS(args.dataroot,transform=transform_train) #yike todo\n",
    "    freal=REAL(args.dataroot,transform=transform_train)\n",
    "\n",
    "    # tst=irs.__getitem__(1)\n",
    "    # print(type(tst[0]))\n",
    "    # print(tst[0].shape)\n",
    "    # cv2.imshow('tst',tst[0])\n",
    "    # cv2.imwrite('/root/Engagements/test/tst1.jpg', tst[0])\n",
    "    # concatenate datasets\n",
    "    concat =  ConcatDataset([iam, eydigits,irs,printed,freal]) # concatenate the multiple datasets yike notice!!!!\n",
    "    print(len(concat))\n",
    "    # concat= printed\n",
    "    # concat=eydigits\n",
    "    idxTrain = int(.9 * len(concat))\n",
    "    trainset, testset = random_split(concat, [idxTrain, len(concat) - idxTrain])\n",
    "    print(str(len(trainset) / 50))\n",
    "    print(str(len(testset) / 50))\n",
    "    trainloader = DataLoader(trainset, batch_size=args.batchsize_recg, shuffle=True, drop_last=True, num_workers=4)\n",
    "    validateloader = DataLoader(trainset, batch_size=args.batchsize_recg * 8, shuffle=False, drop_last=False, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=args.batchsize_recg * 8, shuffle=False, drop_last=False,\n",
    "                            num_workers=2)  # yike: feel not right\n",
    "    # testloader=DataLoader(testset, batch_size=args.batchsize,shuffle=False, num_workers=2) # yike: all test data included, no sampling. validation is not training. , sampler=SequentialSampler\n",
    "\n",
    "    # save characters of model for inference mode\n",
    "    charlist = list(set.union(set(iam.charList),set(eydigits.charList),set(irs.charList),set(printed.charList),set(freal.charList))) # yike notice !!!!\n",
    "    #charlist = list(set(printed.charList))\n",
    "    charlist.sort()\n",
    "    # charlist=eydigits.charList\n",
    "    open(join(args.ckptpath_recg, 'charList.txt'), 'w').write(str().join(charlist))\n",
    "\n",
    "    # # save words contained in dataset into file\n",
    "    # open(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
    "\n",
    "    # execute training or validation\n",
    "    if args.train:\n",
    "        model = Model(args, charList=charlist, loss_beta=0.6,loss_weight=[.5,.5], decoderType=DecoderType.BeamSearch,experiment=experiment,mustRestore_seg=False,mustRestore_recg=False, joint=False)  # yike: pay notice here, add mustRestore if wanna continue with pretrained model !!!!!!!!!\n",
    "        model.trainRecg(trainloader, validateloader, testloader)  # yike added validateloader !!!!!!!!!!\n",
    "    elif args.validate:\n",
    "        #model = Model(args, charlist, decoderType, mustRestore=True)\n",
    "        model = Model(args, charList=charlist, loss_beta=0.6,loss_weight=[.5,.5], decoderType=DecoderType.BeamSearch,experiment=experiment,mustRestore_seg=False,mustRestore_recg=True, joint=False)\n",
    "        model.validateRecg(testloader)\n",
    "\n",
    "# infer text on test image\n",
    "else:\n",
    "    print(open(join(args.ckptpath_recg, 'accuracy.txt')).read())\n",
    "    #model = Model(args, open(join(args.ckptpath, 'charList.txt')).read(), decoderType, mustRestore=True)\n",
    "    model = Model(args, charList=open(join(args.ckptpath_recg, 'charList.txt')).read(), loss_beta=0.6,loss_weight=[.5,.5], decoderType=DecoderType.BeamSearch,experiment=experiment,mustRestore_seg=False,mustRestore_recg=True, joint=False)\n",
    "    infer(model, FilePaths.fnInfer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_name('debug')\n",
    "experiment.log_parameters(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_seg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkArgs():\n",
    "    if args.test:\n",
    "        print('The model is set to Testing')\n",
    "        print(\"Check point file: %s\"%args.ckptpath_seg)\n",
    "        #print(\"CamVid testing dir: %s\"%FLAGS.test_dir)\n",
    "    elif args.transfer:\n",
    "        print('The model is set to transfer learn from ckpt')\n",
    "        print(\"Check point file: %s\"%args.ckptpath_seg)\n",
    "        #print(\"CamVid Image dir: %s\"%FLAGS.image_dir)\n",
    "        #print(\"CamVid Val dir: %s\"%FLAGS.val_dir)\n",
    "    else:\n",
    "        print('The model is set to Training')\n",
    "        print(\"Max training Iteration: %d\"%args.max_epoch)\n",
    "        print(\"Initial lr: %f\"%args.lrInit)\n",
    "        print(\"First Drop Steps: %i\"%args.lrDrop1)\n",
    "        print(\"Second Drop Steps: %i\"%args.lrDrop2)\n",
    "        print(\"Data root: %s\"%args.data_root)\n",
    "        print(\"Check point file: %s\"%args.ckptpath_seg)\n",
    "        #print(\"CamVid Val dir: %s\"%FLAGS.val_dir)\n",
    "\n",
    "    print(\"Batch Size: %d\"%args.batch_size_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is set to Training\n",
      "Max training Iteration: 100\n",
      "Initial lr: 0.001000\n",
      "First Drop Steps: 10\n",
      "Second Drop Steps: 1000\n",
      "Data root: /root/datasets\n",
      "Check point file: /root/ckpt/debug_seg\n",
      "Batch Size: 10\n",
      "/root/datasets/artifact_images_no_intersect already exists, skipping download\n",
      "[0.1 0.9]\n",
      "GGG\n",
      "[None, 32, 128, 1]\n",
      "0 conv1: (?, ?, ?, 32)\n",
      "0 conv2: (?, ?, ?, 32)\n",
      "1 conv1: (?, ?, ?, 64)\n",
      "1 conv2: (?, ?, ?, 64)\n",
      "2 conv1: (?, ?, ?, 128)\n",
      "2 conv2: (?, ?, ?, 128)\n",
      "1 h_deconv: (?, ?, ?, 64)\n",
      "1 h_deconv_concat: (?, ?, ?, ?)\n",
      "1 h_conv1_post_deconv: (?, ?, ?, 64)\n",
      "1 h_conv2_post_deconv: (?, ?, ?, 64)\n",
      "0 h_deconv: (?, ?, ?, 32)\n",
      "0 h_deconv_concat: (?, ?, ?, ?)\n",
      "0 h_conv1_post_deconv: (?, ?, ?, 32)\n",
      "0 h_conv2_post_deconv: (?, ?, ?, 32)\n",
      "0 outmap: (?, ?, ?, 2)\n",
      "(?, ?, ?, 2)\n",
      "loss_seg: ()\n",
      "clean output from seg: (?, 32, 128)\n",
      "recg input: (?, 128, 32)\n",
      "shape of cnn input: [None, 128, 32]\n",
      "Build Densenet4htr model with 5 blocks, 9 bottleneck layers and 9 composite layers each.\n",
      "Depth: 96\n",
      "Reduction at transition layers: 0.4\n",
      "densenet feature extractor graph built in (sec): 6.272006273269653\n",
      "Total training params: 1.0M\n",
      "shape of cnn output: [None, 32, 1, 178]\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n",
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toto_loss_shape: Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "Ran global_variables_initializer first\n",
      "Ran initializers.variables on segnet trainable variables\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1557: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1557: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/debug_recg/model-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/debug_recg/model-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init with stored values from /root/ckpt/debug_recg/model-1\n",
      "Epoch: 1  Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.0 Loss_Total: 69.04067\n",
      "TRAIN: Batch: 0.0 Loss_Seg: 119.83568\n",
      "accuracy = 0.790549\n",
      "mean IU  = 0.429998\n",
      "    class # 0 capture rate = 0.835037 \n",
      "    class # 1 capture rate = 0.225753 \n",
      "TRAIN: Batch: 0.003908998514580564 Loss_Total: 21.510185\n",
      "TRAIN: Batch: 0.003908998514580564 Loss_Seg: 27.185595\n",
      "accuracy = 0.861262\n",
      "mean IU  = 0.549289\n",
      "    class # 0 capture rate = 0.866055 \n",
      "    class # 1 capture rate = 0.782237 \n",
      "TRAIN: Batch: 0.007817997029161129 Loss_Total: 17.741007\n",
      "TRAIN: Batch: 0.007817997029161129 Loss_Seg: 22.68701\n",
      "accuracy = 0.901792\n",
      "mean IU  = 0.630465\n",
      "    class # 0 capture rate = 0.906639 \n",
      "    class # 1 capture rate = 0.834958 \n",
      "TRAIN: Batch: 0.011726995543741693 Loss_Total: 18.125402\n",
      "TRAIN: Batch: 0.011726995543741693 Loss_Seg: 22.558826\n",
      "accuracy = 0.859930\n",
      "mean IU  = 0.575830\n",
      "    class # 0 capture rate = 0.854794 \n",
      "    class # 1 capture rate = 0.934470 \n",
      "TRAIN: Batch: 0.015635994058322257 Loss_Total: 12.916971\n",
      "TRAIN: Batch: 0.015635994058322257 Loss_Seg: 13.756218\n",
      "accuracy = 0.929607\n",
      "mean IU  = 0.633690\n",
      "    class # 0 capture rate = 0.930230 \n",
      "    class # 1 capture rate = 0.914567 \n",
      "TRAIN: Batch: 0.019544992572902823 Loss_Total: 16.809547\n",
      "TRAIN: Batch: 0.019544992572902823 Loss_Seg: 13.622722\n",
      "accuracy = 0.929948\n",
      "mean IU  = 0.666396\n",
      "    class # 0 capture rate = 0.930740 \n",
      "    class # 1 capture rate = 0.915618 \n",
      "TRAIN: Batch: 0.023453991087483386 Loss_Total: 14.697517\n",
      "TRAIN: Batch: 0.023453991087483386 Loss_Seg: 14.835626\n",
      "accuracy = 0.935734\n",
      "mean IU  = 0.695401\n",
      "    class # 0 capture rate = 0.937942 \n",
      "    class # 1 capture rate = 0.901414 \n",
      "TRAIN: Batch: 0.02736298960206395 Loss_Total: 13.507683\n",
      "TRAIN: Batch: 0.02736298960206395 Loss_Seg: 13.844747\n",
      "accuracy = 0.924183\n",
      "mean IU  = 0.667831\n",
      "    class # 0 capture rate = 0.923218 \n",
      "    class # 1 capture rate = 0.940026 \n",
      "TRAIN: Batch: 0.031271988116644514 Loss_Total: 13.111177\n",
      "TRAIN: Batch: 0.031271988116644514 Loss_Seg: 15.270302\n",
      "accuracy = 0.943647\n",
      "mean IU  = 0.672515\n",
      "    class # 0 capture rate = 0.948273 \n",
      "    class # 1 capture rate = 0.845696 \n",
      "TRAIN: Batch: 0.035180986631225084 Loss_Total: 12.527312\n",
      "TRAIN: Batch: 0.035180986631225084 Loss_Seg: 14.036578\n",
      "accuracy = 0.912811\n",
      "mean IU  = 0.651500\n",
      "    class # 0 capture rate = 0.910413 \n",
      "    class # 1 capture rate = 0.950366 \n",
      "TRAIN: Batch: 0.039089985145805646 Loss_Total: 11.313669\n",
      "TRAIN: Batch: 0.039089985145805646 Loss_Seg: 11.249839\n",
      "accuracy = 0.956219\n",
      "mean IU  = 0.733175\n",
      "    class # 0 capture rate = 0.959240 \n",
      "    class # 1 capture rate = 0.900096 \n",
      "TRAIN: Batch: 0.04299898366038621 Loss_Total: 10.824783\n",
      "TRAIN: Batch: 0.04299898366038621 Loss_Seg: 10.823709\n",
      "accuracy = 0.959074\n",
      "mean IU  = 0.734023\n",
      "    class # 0 capture rate = 0.961589 \n",
      "    class # 1 capture rate = 0.908147 \n",
      "TRAIN: Batch: 0.04690798217496677 Loss_Total: 14.508962\n",
      "TRAIN: Batch: 0.04690798217496677 Loss_Seg: 15.587601\n",
      "accuracy = 0.932461\n",
      "mean IU  = 0.675451\n",
      "    class # 0 capture rate = 0.936487 \n",
      "    class # 1 capture rate = 0.865780 \n",
      "TRAIN: Batch: 0.05081698068954734 Loss_Total: 11.45956\n",
      "TRAIN: Batch: 0.05081698068954734 Loss_Seg: 12.039717\n",
      "accuracy = 0.945792\n",
      "mean IU  = 0.706735\n",
      "    class # 0 capture rate = 0.946521 \n",
      "    class # 1 capture rate = 0.932388 \n",
      "TRAIN: Batch: 0.0547259792041279 Loss_Total: 13.30666\n",
      "TRAIN: Batch: 0.0547259792041279 Loss_Seg: 13.41785\n",
      "accuracy = 0.929902\n",
      "mean IU  = 0.691892\n",
      "    class # 0 capture rate = 0.929003 \n",
      "    class # 1 capture rate = 0.943301 \n",
      "TRAIN: Batch: 0.058634977718708466 Loss_Total: 16.020103\n",
      "TRAIN: Batch: 0.058634977718708466 Loss_Seg: 19.058723\n",
      "accuracy = 0.916909\n",
      "mean IU  = 0.680628\n",
      "    class # 0 capture rate = 0.918902 \n",
      "    class # 1 capture rate = 0.892766 \n",
      "TRAIN: Batch: 0.06254397623328903 Loss_Total: 13.803257\n",
      "TRAIN: Batch: 0.06254397623328903 Loss_Seg: 13.990331\n",
      "accuracy = 0.938413\n",
      "mean IU  = 0.705543\n",
      "    class # 0 capture rate = 0.940157 \n",
      "    class # 1 capture rate = 0.911765 \n",
      "TRAIN: Batch: 0.0664529747478696 Loss_Total: 12.423037\n",
      "TRAIN: Batch: 0.0664529747478696 Loss_Seg: 12.762872\n",
      "accuracy = 0.942651\n",
      "mean IU  = 0.707645\n",
      "    class # 0 capture rate = 0.944513 \n",
      "    class # 1 capture rate = 0.911891 \n",
      "TRAIN: Batch: 0.07036197326245017 Loss_Total: 11.2107525\n",
      "TRAIN: Batch: 0.07036197326245017 Loss_Seg: 12.321178\n",
      "accuracy = 0.944131\n",
      "mean IU  = 0.689850\n",
      "    class # 0 capture rate = 0.944819 \n",
      "    class # 1 capture rate = 0.930136 \n",
      "TRAIN: Batch: 0.07427097177703072 Loss_Total: 10.802042\n",
      "TRAIN: Batch: 0.07427097177703072 Loss_Seg: 13.388422\n",
      "accuracy = 0.934178\n",
      "mean IU  = 0.676650\n",
      "    class # 0 capture rate = 0.935649 \n",
      "    class # 1 capture rate = 0.907919 \n",
      "TRAIN: Batch: 0.07817997029161129 Loss_Total: 10.555035\n",
      "TRAIN: Batch: 0.07817997029161129 Loss_Seg: 11.495695\n",
      "accuracy = 0.940866\n",
      "mean IU  = 0.686345\n",
      "    class # 0 capture rate = 0.941639 \n",
      "    class # 1 capture rate = 0.925908 \n",
      "TRAIN: Batch: 0.08208896880619185 Loss_Total: 15.520438\n",
      "TRAIN: Batch: 0.08208896880619185 Loss_Seg: 15.607566\n",
      "accuracy = 0.930256\n",
      "mean IU  = 0.706953\n",
      "    class # 0 capture rate = 0.930413 \n",
      "    class # 1 capture rate = 0.928231 \n",
      "TRAIN: Batch: 0.08599796732077242 Loss_Total: 13.5295105\n",
      "TRAIN: Batch: 0.08599796732077242 Loss_Seg: 15.622163\n",
      "accuracy = 0.937959\n",
      "mean IU  = 0.677649\n",
      "    class # 0 capture rate = 0.944211 \n",
      "    class # 1 capture rate = 0.828983 \n",
      "TRAIN: Batch: 0.08990696583535299 Loss_Total: 12.695314\n",
      "TRAIN: Batch: 0.08990696583535299 Loss_Seg: 12.244729\n",
      "accuracy = 0.941352\n",
      "mean IU  = 0.694987\n",
      "    class # 0 capture rate = 0.941588 \n",
      "    class # 1 capture rate = 0.936997 \n",
      "TRAIN: Batch: 0.09381596434993354 Loss_Total: 15.429348\n",
      "TRAIN: Batch: 0.09381596434993354 Loss_Seg: 15.805546\n",
      "accuracy = 0.940514\n",
      "mean IU  = 0.702790\n",
      "    class # 0 capture rate = 0.943914 \n",
      "    class # 1 capture rate = 0.886411 \n",
      "TRAIN: Batch: 0.09772496286451411 Loss_Total: 14.271118\n",
      "TRAIN: Batch: 0.09772496286451411 Loss_Seg: 15.002007\n",
      "accuracy = 0.932661\n",
      "mean IU  = 0.650315\n",
      "    class # 0 capture rate = 0.935444 \n",
      "    class # 1 capture rate = 0.874126 \n",
      "TRAIN: Batch: 0.10163396137909468 Loss_Total: 15.05077\n",
      "TRAIN: Batch: 0.10163396137909468 Loss_Seg: 11.665795\n",
      "accuracy = 0.941135\n",
      "mean IU  = 0.735888\n",
      "    class # 0 capture rate = 0.939888 \n",
      "    class # 1 capture rate = 0.957528 \n",
      "TRAIN: Batch: 0.10554295989367524 Loss_Total: 11.483133\n",
      "TRAIN: Batch: 0.10554295989367524 Loss_Seg: 13.958735\n",
      "accuracy = 0.938286\n",
      "mean IU  = 0.688212\n",
      "    class # 0 capture rate = 0.939877 \n",
      "    class # 1 capture rate = 0.910169 \n",
      "TRAIN: Batch: 0.1094519584082558 Loss_Total: 9.744625\n",
      "TRAIN: Batch: 0.1094519584082558 Loss_Seg: 12.471877\n",
      "accuracy = 0.935687\n",
      "mean IU  = 0.675934\n",
      "    class # 0 capture rate = 0.936560 \n",
      "    class # 1 capture rate = 0.919285 \n",
      "TRAIN: Batch: 0.11336095692283638 Loss_Total: 15.502916\n",
      "TRAIN: Batch: 0.11336095692283638 Loss_Seg: 18.856297\n",
      "accuracy = 0.915079\n",
      "mean IU  = 0.658835\n",
      "    class # 0 capture rate = 0.919029 \n",
      "    class # 1 capture rate = 0.860891 \n",
      "TRAIN: Batch: 0.11726995543741693 Loss_Total: 12.389325\n",
      "TRAIN: Batch: 0.11726995543741693 Loss_Seg: 11.545678\n",
      "accuracy = 0.948188\n",
      "mean IU  = 0.731378\n",
      "    class # 0 capture rate = 0.948301 \n",
      "    class # 1 capture rate = 0.946384 \n",
      "TRAIN: Batch: 0.1211789539519975 Loss_Total: 16.107105\n",
      "TRAIN: Batch: 0.1211789539519975 Loss_Seg: 15.915318\n",
      "accuracy = 0.915830\n",
      "mean IU  = 0.698229\n",
      "    class # 0 capture rate = 0.913047 \n",
      "    class # 1 capture rate = 0.945868 \n",
      "TRAIN: Batch: 0.12508795246657806 Loss_Total: 18.203133\n",
      "TRAIN: Batch: 0.12508795246657806 Loss_Seg: 17.977179\n",
      "accuracy = 0.942037\n",
      "mean IU  = 0.733439\n",
      "    class # 0 capture rate = 0.950036 \n",
      "    class # 1 capture rate = 0.846032 \n",
      "TRAIN: Batch: 0.12899695098115863 Loss_Total: 15.4699745\n",
      "TRAIN: Batch: 0.12899695098115863 Loss_Seg: 16.22386\n",
      "accuracy = 0.934292\n",
      "mean IU  = 0.683314\n",
      "    class # 0 capture rate = 0.937749 \n",
      "    class # 1 capture rate = 0.877956 \n",
      "TRAIN: Batch: 0.1329059494957392 Loss_Total: 15.863392\n",
      "TRAIN: Batch: 0.1329059494957392 Loss_Seg: 19.3914\n",
      "accuracy = 0.927438\n",
      "mean IU  = 0.646942\n",
      "    class # 0 capture rate = 0.935038 \n",
      "    class # 1 capture rate = 0.793355 \n",
      "TRAIN: Batch: 0.13681494801031976 Loss_Total: 12.344643\n",
      "TRAIN: Batch: 0.13681494801031976 Loss_Seg: 11.115068\n",
      "accuracy = 0.954358\n",
      "mean IU  = 0.732540\n",
      "    class # 0 capture rate = 0.955705 \n",
      "    class # 1 capture rate = 0.929651 \n",
      "TRAIN: Batch: 0.14072394652490033 Loss_Total: 12.37229\n",
      "TRAIN: Batch: 0.14072394652490033 Loss_Seg: 11.136979\n",
      "accuracy = 0.937790\n",
      "mean IU  = 0.698136\n",
      "    class # 0 capture rate = 0.936913 \n",
      "    class # 1 capture rate = 0.952547 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.14463294503948088 Loss_Total: 14.03543\n",
      "TRAIN: Batch: 0.14463294503948088 Loss_Seg: 12.1186\n",
      "accuracy = 0.947939\n",
      "mean IU  = 0.705166\n",
      "    class # 0 capture rate = 0.950188 \n",
      "    class # 1 capture rate = 0.905181 \n",
      "TRAIN: Batch: 0.14854194355406145 Loss_Total: 17.54755\n",
      "TRAIN: Batch: 0.14854194355406145 Loss_Seg: 18.19168\n",
      "accuracy = 0.917833\n",
      "mean IU  = 0.665792\n",
      "    class # 0 capture rate = 0.923202 \n",
      "    class # 1 capture rate = 0.846476 \n",
      "TRAIN: Batch: 0.15245094206864201 Loss_Total: 17.145653\n",
      "TRAIN: Batch: 0.15245094206864201 Loss_Seg: 17.494654\n",
      "accuracy = 0.926140\n",
      "mean IU  = 0.704982\n",
      "    class # 0 capture rate = 0.929475 \n",
      "    class # 1 capture rate = 0.887665 \n",
      "TRAIN: Batch: 0.15635994058322258 Loss_Total: 12.789807\n",
      "TRAIN: Batch: 0.15635994058322258 Loss_Seg: 16.069374\n",
      "accuracy = 0.934038\n",
      "mean IU  = 0.714372\n",
      "    class # 0 capture rate = 0.935679 \n",
      "    class # 1 capture rate = 0.912911 \n",
      "TRAIN: Batch: 0.16026893909780315 Loss_Total: 15.265148\n",
      "TRAIN: Batch: 0.16026893909780315 Loss_Seg: 12.110039\n",
      "accuracy = 0.941840\n",
      "mean IU  = 0.739949\n",
      "    class # 0 capture rate = 0.941063 \n",
      "    class # 1 capture rate = 0.951787 \n",
      "TRAIN: Batch: 0.1641779376123837 Loss_Total: 12.631971\n",
      "TRAIN: Batch: 0.1641779376123837 Loss_Seg: 14.018041\n",
      "accuracy = 0.934263\n",
      "mean IU  = 0.708752\n",
      "    class # 0 capture rate = 0.934476 \n",
      "    class # 1 capture rate = 0.931298 \n",
      "TRAIN: Batch: 0.16808693612696426 Loss_Total: 15.261749\n",
      "TRAIN: Batch: 0.16808693612696426 Loss_Seg: 12.026118\n",
      "accuracy = 0.933973\n",
      "mean IU  = 0.681149\n",
      "    class # 0 capture rate = 0.933148 \n",
      "    class # 1 capture rate = 0.948753 \n",
      "TRAIN: Batch: 0.17199593464154483 Loss_Total: 14.322638\n",
      "TRAIN: Batch: 0.17199593464154483 Loss_Seg: 14.2443495\n",
      "accuracy = 0.934105\n",
      "mean IU  = 0.691967\n",
      "    class # 0 capture rate = 0.935534 \n",
      "    class # 1 capture rate = 0.911717 \n",
      "TRAIN: Batch: 0.1759049331561254 Loss_Total: 10.447521\n",
      "TRAIN: Batch: 0.1759049331561254 Loss_Seg: 11.346286\n",
      "accuracy = 0.940819\n",
      "mean IU  = 0.697353\n",
      "    class # 0 capture rate = 0.940763 \n",
      "    class # 1 capture rate = 0.941828 \n",
      "TRAIN: Batch: 0.17981393167070597 Loss_Total: 15.1854\n",
      "TRAIN: Batch: 0.17981393167070597 Loss_Seg: 16.733007\n",
      "accuracy = 0.935696\n",
      "mean IU  = 0.718127\n",
      "    class # 0 capture rate = 0.937551 \n",
      "    class # 1 capture rate = 0.911775 \n",
      "TRAIN: Batch: 0.18372293018528654 Loss_Total: 10.913844\n",
      "TRAIN: Batch: 0.18372293018528654 Loss_Seg: 11.4720745\n",
      "accuracy = 0.945987\n",
      "mean IU  = 0.719484\n",
      "    class # 0 capture rate = 0.947009 \n",
      "    class # 1 capture rate = 0.929151 \n",
      "TRAIN: Batch: 0.18763192869986708 Loss_Total: 13.570374\n",
      "TRAIN: Batch: 0.18763192869986708 Loss_Seg: 14.205524\n",
      "accuracy = 0.936102\n",
      "mean IU  = 0.662240\n",
      "    class # 0 capture rate = 0.939130 \n",
      "    class # 1 capture rate = 0.874610 \n",
      "TRAIN: Batch: 0.19154092721444765 Loss_Total: 15.16357\n",
      "TRAIN: Batch: 0.19154092721444765 Loss_Seg: 12.356281\n",
      "accuracy = 0.945428\n",
      "mean IU  = 0.726376\n",
      "    class # 0 capture rate = 0.946692 \n",
      "    class # 1 capture rate = 0.926132 \n",
      "TRAIN: Batch: 0.19544992572902822 Loss_Total: 10.33518\n",
      "TRAIN: Batch: 0.19544992572902822 Loss_Seg: 10.037127\n",
      "accuracy = 0.954270\n",
      "mean IU  = 0.755527\n",
      "    class # 0 capture rate = 0.954269 \n",
      "    class # 1 capture rate = 0.954290 \n",
      "TRAIN: Batch: 0.1993589242436088 Loss_Total: 11.756004\n",
      "TRAIN: Batch: 0.1993589242436088 Loss_Seg: 9.454655\n",
      "accuracy = 0.963129\n",
      "mean IU  = 0.775425\n",
      "    class # 0 capture rate = 0.964822 \n",
      "    class # 1 capture rate = 0.934970 \n",
      "TRAIN: Batch: 0.20326792275818936 Loss_Total: 11.374859\n",
      "TRAIN: Batch: 0.20326792275818936 Loss_Seg: 9.613844\n",
      "accuracy = 0.946261\n",
      "mean IU  = 0.687331\n",
      "    class # 0 capture rate = 0.946609 \n",
      "    class # 1 capture rate = 0.938557 \n",
      "TRAIN: Batch: 0.2071769212727699 Loss_Total: 11.859783\n",
      "TRAIN: Batch: 0.2071769212727699 Loss_Seg: 14.597792\n",
      "accuracy = 0.937936\n",
      "mean IU  = 0.705425\n",
      "    class # 0 capture rate = 0.940106 \n",
      "    class # 1 capture rate = 0.905358 \n",
      "TRAIN: Batch: 0.21108591978735047 Loss_Total: 12.445778\n",
      "TRAIN: Batch: 0.21108591978735047 Loss_Seg: 15.195233\n",
      "accuracy = 0.943694\n",
      "mean IU  = 0.703919\n",
      "    class # 0 capture rate = 0.948887 \n",
      "    class # 1 capture rate = 0.858539 \n",
      "TRAIN: Batch: 0.21499491830193104 Loss_Total: 12.212589\n",
      "TRAIN: Batch: 0.21499491830193104 Loss_Seg: 12.161196\n",
      "accuracy = 0.946843\n",
      "mean IU  = 0.715469\n",
      "    class # 0 capture rate = 0.948482 \n",
      "    class # 1 capture rate = 0.918631 \n",
      "TRAIN: Batch: 0.2189039168165116 Loss_Total: 16.874119\n",
      "TRAIN: Batch: 0.2189039168165116 Loss_Seg: 11.265894\n",
      "accuracy = 0.939813\n",
      "mean IU  = 0.722579\n",
      "    class # 0 capture rate = 0.939399 \n",
      "    class # 1 capture rate = 0.945676 \n",
      "TRAIN: Batch: 0.22281291533109218 Loss_Total: 12.581415\n",
      "TRAIN: Batch: 0.22281291533109218 Loss_Seg: 14.724387\n",
      "accuracy = 0.929536\n",
      "mean IU  = 0.687701\n",
      "    class # 0 capture rate = 0.929315 \n",
      "    class # 1 capture rate = 0.932886 \n",
      "TRAIN: Batch: 0.22672191384567275 Loss_Total: 12.394133\n",
      "TRAIN: Batch: 0.22672191384567275 Loss_Seg: 13.755363\n",
      "accuracy = 0.932389\n",
      "mean IU  = 0.701576\n",
      "    class # 0 capture rate = 0.931226 \n",
      "    class # 1 capture rate = 0.949262 \n",
      "TRAIN: Batch: 0.2306309123602533 Loss_Total: 13.00169\n",
      "TRAIN: Batch: 0.2306309123602533 Loss_Seg: 17.232265\n",
      "accuracy = 0.935049\n",
      "mean IU  = 0.685313\n",
      "    class # 0 capture rate = 0.941280 \n",
      "    class # 1 capture rate = 0.838502 \n",
      "TRAIN: Batch: 0.23453991087483386 Loss_Total: 10.964634\n",
      "TRAIN: Batch: 0.23453991087483386 Loss_Seg: 8.651698\n",
      "accuracy = 0.959907\n",
      "mean IU  = 0.763460\n",
      "    class # 0 capture rate = 0.959693 \n",
      "    class # 1 capture rate = 0.963588 \n",
      "TRAIN: Batch: 0.23844890938941443 Loss_Total: 13.102877\n",
      "TRAIN: Batch: 0.23844890938941443 Loss_Seg: 11.881603\n",
      "accuracy = 0.945040\n",
      "mean IU  = 0.712652\n",
      "    class # 0 capture rate = 0.946741 \n",
      "    class # 1 capture rate = 0.916413 \n",
      "TRAIN: Batch: 0.242357907903995 Loss_Total: 10.075125\n",
      "TRAIN: Batch: 0.242357907903995 Loss_Seg: 10.416106\n",
      "accuracy = 0.955341\n",
      "mean IU  = 0.752880\n",
      "    class # 0 capture rate = 0.956636 \n",
      "    class # 1 capture rate = 0.934738 \n",
      "TRAIN: Batch: 0.24626690641857557 Loss_Total: 10.122164\n",
      "TRAIN: Batch: 0.24626690641857557 Loss_Seg: 14.090876\n",
      "accuracy = 0.929386\n",
      "mean IU  = 0.703617\n",
      "    class # 0 capture rate = 0.928943 \n",
      "    class # 1 capture rate = 0.935227 \n",
      "TRAIN: Batch: 0.2501759049331561 Loss_Total: 10.772703\n",
      "TRAIN: Batch: 0.2501759049331561 Loss_Seg: 10.477332\n",
      "accuracy = 0.956907\n",
      "mean IU  = 0.754991\n",
      "    class # 0 capture rate = 0.958560 \n",
      "    class # 1 capture rate = 0.930017 \n",
      "TRAIN: Batch: 0.2540849034477367 Loss_Total: 15.217247\n",
      "TRAIN: Batch: 0.2540849034477367 Loss_Seg: 17.614422\n",
      "accuracy = 0.946302\n",
      "mean IU  = 0.731480\n",
      "    class # 0 capture rate = 0.952768 \n",
      "    class # 1 capture rate = 0.857451 \n",
      "TRAIN: Batch: 0.25799390196231725 Loss_Total: 11.486933\n",
      "TRAIN: Batch: 0.25799390196231725 Loss_Seg: 11.297552\n",
      "accuracy = 0.936639\n",
      "mean IU  = 0.684139\n",
      "    class # 0 capture rate = 0.935649 \n",
      "    class # 1 capture rate = 0.955045 \n",
      "TRAIN: Batch: 0.2619029004768978 Loss_Total: 13.554228\n",
      "TRAIN: Batch: 0.2619029004768978 Loss_Seg: 16.744831\n",
      "accuracy = 0.926660\n",
      "mean IU  = 0.706130\n",
      "    class # 0 capture rate = 0.928342 \n",
      "    class # 1 capture rate = 0.906788 \n",
      "TRAIN: Batch: 0.2658118989914784 Loss_Total: 12.323319\n",
      "TRAIN: Batch: 0.2658118989914784 Loss_Seg: 13.632186\n",
      "accuracy = 0.944636\n",
      "mean IU  = 0.719932\n",
      "    class # 0 capture rate = 0.947509 \n",
      "    class # 1 capture rate = 0.900480 \n",
      "TRAIN: Batch: 0.26972089750605893 Loss_Total: 12.99631\n",
      "TRAIN: Batch: 0.26972089750605893 Loss_Seg: 12.194377\n",
      "accuracy = 0.949242\n",
      "mean IU  = 0.732141\n",
      "    class # 0 capture rate = 0.951301 \n",
      "    class # 1 capture rate = 0.916701 \n",
      "TRAIN: Batch: 0.27362989602063953 Loss_Total: 12.725039\n",
      "TRAIN: Batch: 0.27362989602063953 Loss_Seg: 15.218625\n",
      "accuracy = 0.936620\n",
      "mean IU  = 0.708105\n",
      "    class # 0 capture rate = 0.937756 \n",
      "    class # 1 capture rate = 0.920136 \n",
      "TRAIN: Batch: 0.27753889453522007 Loss_Total: 12.818572\n",
      "TRAIN: Batch: 0.27753889453522007 Loss_Seg: 14.094648\n",
      "accuracy = 0.933874\n",
      "mean IU  = 0.667862\n",
      "    class # 0 capture rate = 0.935398 \n",
      "    class # 1 capture rate = 0.904762 \n",
      "TRAIN: Batch: 0.28144789304980067 Loss_Total: 12.009129\n",
      "TRAIN: Batch: 0.28144789304980067 Loss_Seg: 13.26889\n",
      "accuracy = 0.935855\n",
      "mean IU  = 0.706920\n",
      "    class # 0 capture rate = 0.935792 \n",
      "    class # 1 capture rate = 0.936782 \n",
      "TRAIN: Batch: 0.2853568915643812 Loss_Total: 11.871309\n",
      "TRAIN: Batch: 0.2853568915643812 Loss_Seg: 12.306395\n",
      "accuracy = 0.939519\n",
      "mean IU  = 0.710817\n",
      "    class # 0 capture rate = 0.939894 \n",
      "    class # 1 capture rate = 0.933759 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.28926589007896175 Loss_Total: 14.657756\n",
      "TRAIN: Batch: 0.28926589007896175 Loss_Seg: 16.152006\n",
      "accuracy = 0.928060\n",
      "mean IU  = 0.681733\n",
      "    class # 0 capture rate = 0.930984 \n",
      "    class # 1 capture rate = 0.885145 \n",
      "TRAIN: Batch: 0.29317488859354235 Loss_Total: 12.882719\n",
      "TRAIN: Batch: 0.29317488859354235 Loss_Seg: 15.386385\n",
      "accuracy = 0.937289\n",
      "mean IU  = 0.700756\n",
      "    class # 0 capture rate = 0.939995 \n",
      "    class # 1 capture rate = 0.896032 \n",
      "TRAIN: Batch: 0.2970838871081229 Loss_Total: 10.805511\n",
      "TRAIN: Batch: 0.2970838871081229 Loss_Seg: 12.468171\n",
      "accuracy = 0.946091\n",
      "mean IU  = 0.716433\n",
      "    class # 0 capture rate = 0.947615 \n",
      "    class # 1 capture rate = 0.920504 \n",
      "TRAIN: Batch: 0.3009928856227035 Loss_Total: 13.404684\n",
      "TRAIN: Batch: 0.3009928856227035 Loss_Seg: 14.055597\n",
      "accuracy = 0.931420\n",
      "mean IU  = 0.692918\n",
      "    class # 0 capture rate = 0.932680 \n",
      "    class # 1 capture rate = 0.912893 \n",
      "TRAIN: Batch: 0.30490188413728403 Loss_Total: 12.158969\n",
      "TRAIN: Batch: 0.30490188413728403 Loss_Seg: 14.425596\n",
      "accuracy = 0.926165\n",
      "mean IU  = 0.709331\n",
      "    class # 0 capture rate = 0.925049 \n",
      "    class # 1 capture rate = 0.939337 \n",
      "TRAIN: Batch: 0.30881088265186457 Loss_Total: 12.592354\n",
      "TRAIN: Batch: 0.30881088265186457 Loss_Seg: 11.44251\n",
      "accuracy = 0.944959\n",
      "mean IU  = 0.711797\n",
      "    class # 0 capture rate = 0.946425 \n",
      "    class # 1 capture rate = 0.920035 \n",
      "TRAIN: Batch: 0.31271988116644517 Loss_Total: 14.826992\n",
      "TRAIN: Batch: 0.31271988116644517 Loss_Seg: 15.042008\n",
      "accuracy = 0.929290\n",
      "mean IU  = 0.690441\n",
      "    class # 0 capture rate = 0.930437 \n",
      "    class # 1 capture rate = 0.912782 \n",
      "TRAIN: Batch: 0.3166288796810257 Loss_Total: 12.75359\n",
      "TRAIN: Batch: 0.3166288796810257 Loss_Seg: 12.122032\n",
      "accuracy = 0.930614\n",
      "mean IU  = 0.696066\n",
      "    class # 0 capture rate = 0.929475 \n",
      "    class # 1 capture rate = 0.947288 \n",
      "TRAIN: Batch: 0.3205378781956063 Loss_Total: 12.810575\n",
      "TRAIN: Batch: 0.3205378781956063 Loss_Seg: 10.7941475\n",
      "accuracy = 0.950680\n",
      "mean IU  = 0.740183\n",
      "    class # 0 capture rate = 0.951484 \n",
      "    class # 1 capture rate = 0.938060 \n",
      "TRAIN: Batch: 0.32444687671018685 Loss_Total: 12.706646\n",
      "TRAIN: Batch: 0.32444687671018685 Loss_Seg: 10.463043\n",
      "accuracy = 0.950357\n",
      "mean IU  = 0.735136\n",
      "    class # 0 capture rate = 0.950718 \n",
      "    class # 1 capture rate = 0.944444 \n",
      "TRAIN: Batch: 0.3283558752247674 Loss_Total: 11.016581\n",
      "TRAIN: Batch: 0.3283558752247674 Loss_Seg: 12.25953\n",
      "accuracy = 0.939542\n",
      "mean IU  = 0.703354\n",
      "    class # 0 capture rate = 0.939405 \n",
      "    class # 1 capture rate = 0.941806 \n",
      "TRAIN: Batch: 0.332264873739348 Loss_Total: 11.694708\n",
      "TRAIN: Batch: 0.332264873739348 Loss_Seg: 11.323074\n",
      "accuracy = 0.952147\n",
      "mean IU  = 0.742122\n",
      "    class # 0 capture rate = 0.952881 \n",
      "    class # 1 capture rate = 0.940342 \n",
      "TRAIN: Batch: 0.33617387225392853 Loss_Total: 8.663042\n",
      "TRAIN: Batch: 0.33617387225392853 Loss_Seg: 9.116441\n",
      "accuracy = 0.950922\n",
      "mean IU  = 0.706584\n",
      "    class # 0 capture rate = 0.950461 \n",
      "    class # 1 capture rate = 0.960860 \n",
      "TRAIN: Batch: 0.3400828707685091 Loss_Total: 10.565762\n",
      "TRAIN: Batch: 0.3400828707685091 Loss_Seg: 11.563172\n",
      "accuracy = 0.938342\n",
      "mean IU  = 0.708215\n",
      "    class # 0 capture rate = 0.938165 \n",
      "    class # 1 capture rate = 0.941082 \n",
      "TRAIN: Batch: 0.34399186928308967 Loss_Total: 13.151674\n",
      "TRAIN: Batch: 0.34399186928308967 Loss_Seg: 11.2811365\n",
      "accuracy = 0.938646\n",
      "mean IU  = 0.717513\n",
      "    class # 0 capture rate = 0.937555 \n",
      "    class # 1 capture rate = 0.954494 \n",
      "TRAIN: Batch: 0.3479008677976702 Loss_Total: 13.504065\n",
      "TRAIN: Batch: 0.3479008677976702 Loss_Seg: 12.191048\n",
      "accuracy = 0.934457\n",
      "mean IU  = 0.706224\n",
      "    class # 0 capture rate = 0.933497 \n",
      "    class # 1 capture rate = 0.948407 \n",
      "TRAIN: Batch: 0.3518098663122508 Loss_Total: 12.545227\n",
      "TRAIN: Batch: 0.3518098663122508 Loss_Seg: 13.617873\n",
      "accuracy = 0.935222\n",
      "mean IU  = 0.713739\n",
      "    class # 0 capture rate = 0.935728 \n",
      "    class # 1 capture rate = 0.928369 \n",
      "TRAIN: Batch: 0.35571886482683135 Loss_Total: 12.454511\n",
      "TRAIN: Batch: 0.35571886482683135 Loss_Seg: 12.532657\n",
      "accuracy = 0.940697\n",
      "mean IU  = 0.711711\n",
      "    class # 0 capture rate = 0.941016 \n",
      "    class # 1 capture rate = 0.935694 \n",
      "TRAIN: Batch: 0.35962786334141195 Loss_Total: 12.732819\n",
      "TRAIN: Batch: 0.35962786334141195 Loss_Seg: 10.631586\n",
      "accuracy = 0.938060\n",
      "mean IU  = 0.701750\n",
      "    class # 0 capture rate = 0.936386 \n",
      "    class # 1 capture rate = 0.965948 \n",
      "TRAIN: Batch: 0.3635368618559925 Loss_Total: 15.759346\n",
      "TRAIN: Batch: 0.3635368618559925 Loss_Seg: 15.588062\n",
      "accuracy = 0.939206\n",
      "mean IU  = 0.736009\n",
      "    class # 0 capture rate = 0.941611 \n",
      "    class # 1 capture rate = 0.910607 \n",
      "TRAIN: Batch: 0.3674458603705731 Loss_Total: 18.704477\n",
      "TRAIN: Batch: 0.3674458603705731 Loss_Seg: 20.272806\n",
      "accuracy = 0.931266\n",
      "mean IU  = 0.706490\n",
      "    class # 0 capture rate = 0.938067 \n",
      "    class # 1 capture rate = 0.849363 \n",
      "TRAIN: Batch: 0.3713548588851536 Loss_Total: 15.160987\n",
      "TRAIN: Batch: 0.3713548588851536 Loss_Seg: 16.362041\n",
      "accuracy = 0.933503\n",
      "mean IU  = 0.708437\n",
      "    class # 0 capture rate = 0.936550 \n",
      "    class # 1 capture rate = 0.893558 \n",
      "TRAIN: Batch: 0.37526385739973417 Loss_Total: 13.382025\n",
      "TRAIN: Batch: 0.37526385739973417 Loss_Seg: 14.459449\n",
      "accuracy = 0.938739\n",
      "mean IU  = 0.714446\n",
      "    class # 0 capture rate = 0.940631 \n",
      "    class # 1 capture rate = 0.911798 \n",
      "TRAIN: Batch: 0.37917285591431477 Loss_Total: 14.092209\n",
      "TRAIN: Batch: 0.37917285591431477 Loss_Seg: 11.532337\n",
      "accuracy = 0.942768\n",
      "mean IU  = 0.705229\n",
      "    class # 0 capture rate = 0.942486 \n",
      "    class # 1 capture rate = 0.947727 \n",
      "TRAIN: Batch: 0.3830818544288953 Loss_Total: 11.411718\n",
      "TRAIN: Batch: 0.3830818544288953 Loss_Seg: 13.294485\n",
      "accuracy = 0.927759\n",
      "mean IU  = 0.669080\n",
      "    class # 0 capture rate = 0.926610 \n",
      "    class # 1 capture rate = 0.947917 \n",
      "TRAIN: Batch: 0.3869908529434759 Loss_Total: 10.511551\n",
      "TRAIN: Batch: 0.3869908529434759 Loss_Seg: 10.24119\n",
      "accuracy = 0.955497\n",
      "mean IU  = 0.750036\n",
      "    class # 0 capture rate = 0.955831 \n",
      "    class # 1 capture rate = 0.949935 \n",
      "TRAIN: Batch: 0.39089985145805645 Loss_Total: 11.444076\n",
      "TRAIN: Batch: 0.39089985145805645 Loss_Seg: 11.404271\n",
      "accuracy = 0.947424\n",
      "mean IU  = 0.747025\n",
      "    class # 0 capture rate = 0.947246 \n",
      "    class # 1 capture rate = 0.949874 \n",
      "TRAIN: Batch: 0.394808849972637 Loss_Total: 12.366951\n",
      "TRAIN: Batch: 0.394808849972637 Loss_Seg: 11.617069\n",
      "accuracy = 0.948853\n",
      "mean IU  = 0.697009\n",
      "    class # 0 capture rate = 0.950954 \n",
      "    class # 1 capture rate = 0.905016 \n",
      "TRAIN: Batch: 0.3987178484872176 Loss_Total: 10.881131\n",
      "TRAIN: Batch: 0.3987178484872176 Loss_Seg: 12.025453\n",
      "accuracy = 0.943351\n",
      "mean IU  = 0.694122\n",
      "    class # 0 capture rate = 0.945149 \n",
      "    class # 1 capture rate = 0.909531 \n",
      "TRAIN: Batch: 0.4026268470017981 Loss_Total: 14.679033\n",
      "TRAIN: Batch: 0.4026268470017981 Loss_Seg: 11.915159\n",
      "accuracy = 0.937175\n",
      "mean IU  = 0.689242\n",
      "    class # 0 capture rate = 0.936158 \n",
      "    class # 1 capture rate = 0.955473 \n",
      "TRAIN: Batch: 0.4065358455163787 Loss_Total: 12.227331\n",
      "TRAIN: Batch: 0.4065358455163787 Loss_Seg: 13.305021\n",
      "accuracy = 0.931515\n",
      "mean IU  = 0.686858\n",
      "    class # 0 capture rate = 0.932189 \n",
      "    class # 1 capture rate = 0.920945 \n",
      "TRAIN: Batch: 0.41044484403095927 Loss_Total: 12.572439\n",
      "TRAIN: Batch: 0.41044484403095927 Loss_Seg: 13.014957\n",
      "accuracy = 0.938831\n",
      "mean IU  = 0.717717\n",
      "    class # 0 capture rate = 0.939798 \n",
      "    class # 1 capture rate = 0.925203 \n",
      "TRAIN: Batch: 0.4143538425455398 Loss_Total: 16.457714\n",
      "TRAIN: Batch: 0.4143538425455398 Loss_Seg: 11.860002\n",
      "accuracy = 0.929391\n",
      "mean IU  = 0.676116\n",
      "    class # 0 capture rate = 0.928008 \n",
      "    class # 1 capture rate = 0.953077 \n",
      "TRAIN: Batch: 0.4182628410601204 Loss_Total: 9.9854145\n",
      "TRAIN: Batch: 0.4182628410601204 Loss_Seg: 10.33545\n",
      "accuracy = 0.946987\n",
      "mean IU  = 0.722066\n",
      "    class # 0 capture rate = 0.946678 \n",
      "    class # 1 capture rate = 0.952214 \n",
      "TRAIN: Batch: 0.42217183957470095 Loss_Total: 11.905102\n",
      "TRAIN: Batch: 0.42217183957470095 Loss_Seg: 12.36867\n",
      "accuracy = 0.940517\n",
      "mean IU  = 0.719283\n",
      "    class # 0 capture rate = 0.940242 \n",
      "    class # 1 capture rate = 0.944573 \n",
      "TRAIN: Batch: 0.42608083808928154 Loss_Total: 13.959835\n",
      "TRAIN: Batch: 0.42608083808928154 Loss_Seg: 13.395734\n",
      "accuracy = 0.935341\n",
      "mean IU  = 0.696881\n",
      "    class # 0 capture rate = 0.936572 \n",
      "    class # 1 capture rate = 0.916264 \n",
      "TRAIN: Batch: 0.4299898366038621 Loss_Total: 11.169878\n",
      "TRAIN: Batch: 0.4299898366038621 Loss_Seg: 12.409081\n",
      "accuracy = 0.939937\n",
      "mean IU  = 0.705814\n",
      "    class # 0 capture rate = 0.941931 \n",
      "    class # 1 capture rate = 0.908609 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.4338988351184426 Loss_Total: 12.755939\n",
      "TRAIN: Batch: 0.4338988351184426 Loss_Seg: 9.208458\n",
      "accuracy = 0.944530\n",
      "mean IU  = 0.697197\n",
      "    class # 0 capture rate = 0.944159 \n",
      "    class # 1 capture rate = 0.951850 \n",
      "TRAIN: Batch: 0.4378078336330232 Loss_Total: 8.581817\n",
      "TRAIN: Batch: 0.4378078336330232 Loss_Seg: 11.114575\n",
      "accuracy = 0.949683\n",
      "mean IU  = 0.743543\n",
      "    class # 0 capture rate = 0.949893 \n",
      "    class # 1 capture rate = 0.946526 \n",
      "TRAIN: Batch: 0.44171683214760377 Loss_Total: 14.113697\n",
      "TRAIN: Batch: 0.44171683214760377 Loss_Seg: 14.384409\n",
      "accuracy = 0.934632\n",
      "mean IU  = 0.695688\n",
      "    class # 0 capture rate = 0.935242 \n",
      "    class # 1 capture rate = 0.925132 \n",
      "TRAIN: Batch: 0.44562583066218436 Loss_Total: 13.892193\n",
      "TRAIN: Batch: 0.44562583066218436 Loss_Seg: 18.299128\n",
      "accuracy = 0.949676\n",
      "mean IU  = 0.738689\n",
      "    class # 0 capture rate = 0.957623 \n",
      "    class # 1 capture rate = 0.840303 \n",
      "TRAIN: Batch: 0.4495348291767649 Loss_Total: 14.425501\n",
      "TRAIN: Batch: 0.4495348291767649 Loss_Seg: 12.104461\n",
      "accuracy = 0.955077\n",
      "mean IU  = 0.769497\n",
      "    class # 0 capture rate = 0.958110 \n",
      "    class # 1 capture rate = 0.914655 \n",
      "TRAIN: Batch: 0.4534438276913455 Loss_Total: 13.317753\n",
      "TRAIN: Batch: 0.4534438276913455 Loss_Seg: 14.397361\n",
      "accuracy = 0.920457\n",
      "mean IU  = 0.681064\n",
      "    class # 0 capture rate = 0.920585 \n",
      "    class # 1 capture rate = 0.918759 \n",
      "TRAIN: Batch: 0.45735282620592604 Loss_Total: 12.837008\n",
      "TRAIN: Batch: 0.45735282620592604 Loss_Seg: 10.229025\n",
      "accuracy = 0.954341\n",
      "mean IU  = 0.710062\n",
      "    class # 0 capture rate = 0.957230 \n",
      "    class # 1 capture rate = 0.892935 \n",
      "TRAIN: Batch: 0.4612618247205066 Loss_Total: 10.801678\n",
      "TRAIN: Batch: 0.4612618247205066 Loss_Seg: 12.135422\n",
      "accuracy = 0.946871\n",
      "mean IU  = 0.730324\n",
      "    class # 0 capture rate = 0.948332 \n",
      "    class # 1 capture rate = 0.924573 \n",
      "TRAIN: Batch: 0.4651708232350872 Loss_Total: 16.922184\n",
      "TRAIN: Batch: 0.4651708232350872 Loss_Seg: 18.201626\n",
      "accuracy = 0.924313\n",
      "mean IU  = 0.711042\n",
      "    class # 0 capture rate = 0.926830 \n",
      "    class # 1 capture rate = 0.897465 \n",
      "TRAIN: Batch: 0.4690798217496677 Loss_Total: 12.169823\n",
      "TRAIN: Batch: 0.4690798217496677 Loss_Seg: 13.89732\n",
      "accuracy = 0.928069\n",
      "mean IU  = 0.689459\n",
      "    class # 0 capture rate = 0.928142 \n",
      "    class # 1 capture rate = 0.927013 \n",
      "TRAIN: Batch: 0.4729888202642483 Loss_Total: 13.641189\n",
      "TRAIN: Batch: 0.4729888202642483 Loss_Seg: 9.799225\n",
      "accuracy = 0.940738\n",
      "mean IU  = 0.700183\n",
      "    class # 0 capture rate = 0.939266 \n",
      "    class # 1 capture rate = 0.967160 \n",
      "TRAIN: Batch: 0.47689781877882886 Loss_Total: 11.841552\n",
      "TRAIN: Batch: 0.47689781877882886 Loss_Seg: 10.324585\n",
      "accuracy = 0.942958\n",
      "mean IU  = 0.716223\n",
      "    class # 0 capture rate = 0.941850 \n",
      "    class # 1 capture rate = 0.961050 \n",
      "TRAIN: Batch: 0.4808068172934094 Loss_Total: 14.459801\n",
      "TRAIN: Batch: 0.4808068172934094 Loss_Seg: 13.797837\n",
      "accuracy = 0.947066\n",
      "mean IU  = 0.721769\n",
      "    class # 0 capture rate = 0.949918 \n",
      "    class # 1 capture rate = 0.901250 \n",
      "TRAIN: Batch: 0.48471581580799 Loss_Total: 12.884867\n",
      "TRAIN: Batch: 0.48471581580799 Loss_Seg: 11.81079\n",
      "accuracy = 0.943235\n",
      "mean IU  = 0.735198\n",
      "    class # 0 capture rate = 0.943026 \n",
      "    class # 1 capture rate = 0.946101 \n",
      "TRAIN: Batch: 0.48862481432257054 Loss_Total: 11.260712\n",
      "TRAIN: Batch: 0.48862481432257054 Loss_Seg: 9.739828\n",
      "accuracy = 0.950577\n",
      "mean IU  = 0.727437\n",
      "    class # 0 capture rate = 0.949985 \n",
      "    class # 1 capture rate = 0.961201 \n",
      "TRAIN: Batch: 0.49253381283715114 Loss_Total: 13.4127865\n",
      "TRAIN: Batch: 0.49253381283715114 Loss_Seg: 11.322225\n",
      "accuracy = 0.949927\n",
      "mean IU  = 0.739374\n",
      "    class # 0 capture rate = 0.952206 \n",
      "    class # 1 capture rate = 0.915521 \n",
      "TRAIN: Batch: 0.4964428113517317 Loss_Total: 15.475048\n",
      "TRAIN: Batch: 0.4964428113517317 Loss_Seg: 15.631351\n",
      "accuracy = 0.931144\n",
      "mean IU  = 0.709908\n",
      "    class # 0 capture rate = 0.932069 \n",
      "    class # 1 capture rate = 0.919398 \n",
      "TRAIN: Batch: 0.5003518098663122 Loss_Total: 24.864956\n",
      "TRAIN: Batch: 0.5003518098663122 Loss_Seg: 33.175728\n",
      "accuracy = 0.899311\n",
      "mean IU  = 0.672219\n",
      "    class # 0 capture rate = 0.912549 \n",
      "    class # 1 capture rate = 0.788108 \n",
      "TRAIN: Batch: 0.5042608083808928 Loss_Total: 14.5437\n",
      "TRAIN: Batch: 0.5042608083808928 Loss_Seg: 12.341215\n",
      "accuracy = 0.941520\n",
      "mean IU  = 0.687804\n",
      "    class # 0 capture rate = 0.943252 \n",
      "    class # 1 capture rate = 0.908557 \n",
      "TRAIN: Batch: 0.5081698068954734 Loss_Total: 14.270704\n",
      "TRAIN: Batch: 0.5081698068954734 Loss_Seg: 10.402609\n",
      "accuracy = 0.951969\n",
      "mean IU  = 0.735191\n",
      "    class # 0 capture rate = 0.952191 \n",
      "    class # 1 capture rate = 0.948161 \n",
      "TRAIN: Batch: 0.5120788054100539 Loss_Total: 15.745489\n",
      "TRAIN: Batch: 0.5120788054100539 Loss_Seg: 12.87095\n",
      "accuracy = 0.942475\n",
      "mean IU  = 0.702897\n",
      "    class # 0 capture rate = 0.943627 \n",
      "    class # 1 capture rate = 0.922491 \n",
      "TRAIN: Batch: 0.5159878039246345 Loss_Total: 11.540047\n",
      "TRAIN: Batch: 0.5159878039246345 Loss_Seg: 13.379556\n",
      "accuracy = 0.953416\n",
      "mean IU  = 0.753199\n",
      "    class # 0 capture rate = 0.957382 \n",
      "    class # 1 capture rate = 0.896396 \n",
      "TRAIN: Batch: 0.5198968024392151 Loss_Total: 16.231522\n",
      "TRAIN: Batch: 0.5198968024392151 Loss_Seg: 9.943118\n",
      "accuracy = 0.954098\n",
      "mean IU  = 0.777916\n",
      "    class # 0 capture rate = 0.953479 \n",
      "    class # 1 capture rate = 0.961949 \n",
      "TRAIN: Batch: 0.5238058009537956 Loss_Total: 9.510815\n",
      "TRAIN: Batch: 0.5238058009537956 Loss_Seg: 8.648032\n",
      "accuracy = 0.952902\n",
      "mean IU  = 0.733174\n",
      "    class # 0 capture rate = 0.952347 \n",
      "    class # 1 capture rate = 0.962998 \n",
      "TRAIN: Batch: 0.5277147994683762 Loss_Total: 14.690704\n",
      "TRAIN: Batch: 0.5277147994683762 Loss_Seg: 17.738544\n",
      "accuracy = 0.949582\n",
      "mean IU  = 0.709803\n",
      "    class # 0 capture rate = 0.958200 \n",
      "    class # 1 capture rate = 0.804613 \n",
      "TRAIN: Batch: 0.5316237979829568 Loss_Total: 10.672964\n",
      "TRAIN: Batch: 0.5316237979829568 Loss_Seg: 9.560925\n",
      "accuracy = 0.955343\n",
      "mean IU  = 0.733605\n",
      "    class # 0 capture rate = 0.955750 \n",
      "    class # 1 capture rate = 0.947600 \n",
      "TRAIN: Batch: 0.5355327964975374 Loss_Total: 17.072668\n",
      "TRAIN: Batch: 0.5355327964975374 Loss_Seg: 18.51734\n",
      "accuracy = 0.917177\n",
      "mean IU  = 0.710518\n",
      "    class # 0 capture rate = 0.916337 \n",
      "    class # 1 capture rate = 0.925299 \n",
      "TRAIN: Batch: 0.5394417950121179 Loss_Total: 12.585939\n",
      "TRAIN: Batch: 0.5394417950121179 Loss_Seg: 11.949284\n",
      "accuracy = 0.940955\n",
      "mean IU  = 0.701169\n",
      "    class # 0 capture rate = 0.942473 \n",
      "    class # 1 capture rate = 0.915358 \n",
      "TRAIN: Batch: 0.5433507935266985 Loss_Total: 12.096472\n",
      "TRAIN: Batch: 0.5433507935266985 Loss_Seg: 11.010353\n",
      "accuracy = 0.943917\n",
      "mean IU  = 0.697846\n",
      "    class # 0 capture rate = 0.944215 \n",
      "    class # 1 capture rate = 0.938235 \n",
      "TRAIN: Batch: 0.5472597920412791 Loss_Total: 13.016415\n",
      "TRAIN: Batch: 0.5472597920412791 Loss_Seg: 11.663358\n",
      "accuracy = 0.940276\n",
      "mean IU  = 0.745011\n",
      "    class # 0 capture rate = 0.938946 \n",
      "    class # 1 capture rate = 0.956044 \n",
      "TRAIN: Batch: 0.5511687905558595 Loss_Total: 8.943476\n",
      "TRAIN: Batch: 0.5511687905558595 Loss_Seg: 9.566131\n",
      "accuracy = 0.957687\n",
      "mean IU  = 0.752452\n",
      "    class # 0 capture rate = 0.959758 \n",
      "    class # 1 capture rate = 0.922741 \n",
      "TRAIN: Batch: 0.5550777890704401 Loss_Total: 10.644749\n",
      "TRAIN: Batch: 0.5550777890704401 Loss_Seg: 12.336838\n",
      "accuracy = 0.939278\n",
      "mean IU  = 0.681026\n",
      "    class # 0 capture rate = 0.942707 \n",
      "    class # 1 capture rate = 0.875951 \n",
      "TRAIN: Batch: 0.5589867875850207 Loss_Total: 10.937361\n",
      "TRAIN: Batch: 0.5589867875850207 Loss_Seg: 11.907263\n",
      "accuracy = 0.935830\n",
      "mean IU  = 0.704684\n",
      "    class # 0 capture rate = 0.935034 \n",
      "    class # 1 capture rate = 0.947908 \n",
      "TRAIN: Batch: 0.5628957860996013 Loss_Total: 13.759079\n",
      "TRAIN: Batch: 0.5628957860996013 Loss_Seg: 18.43071\n",
      "accuracy = 0.926852\n",
      "mean IU  = 0.681861\n",
      "    class # 0 capture rate = 0.933297 \n",
      "    class # 1 capture rate = 0.839659 \n",
      "TRAIN: Batch: 0.5668047846141818 Loss_Total: 10.541897\n",
      "TRAIN: Batch: 0.5668047846141818 Loss_Seg: 8.952852\n",
      "accuracy = 0.954822\n",
      "mean IU  = 0.731135\n",
      "    class # 0 capture rate = 0.954700 \n",
      "    class # 1 capture rate = 0.957193 \n",
      "TRAIN: Batch: 0.5707137831287624 Loss_Total: 13.826235\n",
      "TRAIN: Batch: 0.5707137831287624 Loss_Seg: 11.935426\n",
      "accuracy = 0.949039\n",
      "mean IU  = 0.706520\n",
      "    class # 0 capture rate = 0.952432 \n",
      "    class # 1 capture rate = 0.885007 \n",
      "TRAIN: Batch: 0.574622781643343 Loss_Total: 12.353267\n",
      "TRAIN: Batch: 0.574622781643343 Loss_Seg: 11.525543\n",
      "accuracy = 0.939447\n",
      "mean IU  = 0.692537\n",
      "    class # 0 capture rate = 0.939856 \n",
      "    class # 1 capture rate = 0.932133 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.5785317801579235 Loss_Total: 11.119186\n",
      "TRAIN: Batch: 0.5785317801579235 Loss_Seg: 9.585261\n",
      "accuracy = 0.944842\n",
      "mean IU  = 0.700848\n",
      "    class # 0 capture rate = 0.943893 \n",
      "    class # 1 capture rate = 0.963390 \n",
      "TRAIN: Batch: 0.5824407786725041 Loss_Total: 10.931178\n",
      "TRAIN: Batch: 0.5824407786725041 Loss_Seg: 10.924797\n",
      "accuracy = 0.945281\n",
      "mean IU  = 0.720671\n",
      "    class # 0 capture rate = 0.945519 \n",
      "    class # 1 capture rate = 0.941424 \n",
      "TRAIN: Batch: 0.5863497771870847 Loss_Total: 10.619135\n",
      "TRAIN: Batch: 0.5863497771870847 Loss_Seg: 9.252837\n",
      "accuracy = 0.957785\n",
      "mean IU  = 0.741646\n",
      "    class # 0 capture rate = 0.958299 \n",
      "    class # 1 capture rate = 0.947963 \n",
      "TRAIN: Batch: 0.5902587757016652 Loss_Total: 9.350042\n",
      "TRAIN: Batch: 0.5902587757016652 Loss_Seg: 9.694891\n",
      "accuracy = 0.961081\n",
      "mean IU  = 0.746389\n",
      "    class # 0 capture rate = 0.963503 \n",
      "    class # 1 capture rate = 0.913784 \n",
      "TRAIN: Batch: 0.5941677742162458 Loss_Total: 14.107313\n",
      "TRAIN: Batch: 0.5941677742162458 Loss_Seg: 12.020708\n",
      "accuracy = 0.946230\n",
      "mean IU  = 0.733471\n",
      "    class # 0 capture rate = 0.946777 \n",
      "    class # 1 capture rate = 0.938104 \n",
      "TRAIN: Batch: 0.5980767727308264 Loss_Total: 14.892303\n",
      "TRAIN: Batch: 0.5980767727308264 Loss_Seg: 11.758718\n",
      "accuracy = 0.950411\n",
      "mean IU  = 0.750442\n",
      "    class # 0 capture rate = 0.950548 \n",
      "    class # 1 capture rate = 0.948438 \n",
      "TRAIN: Batch: 0.601985771245407 Loss_Total: 17.136833\n",
      "TRAIN: Batch: 0.601985771245407 Loss_Seg: 17.292503\n",
      "accuracy = 0.925083\n",
      "mean IU  = 0.723502\n",
      "    class # 0 capture rate = 0.924690 \n",
      "    class # 1 capture rate = 0.929034 \n",
      "TRAIN: Batch: 0.6058947697599875 Loss_Total: 10.953746\n",
      "TRAIN: Batch: 0.6058947697599875 Loss_Seg: 10.9644375\n",
      "accuracy = 0.944599\n",
      "mean IU  = 0.736566\n",
      "    class # 0 capture rate = 0.944564 \n",
      "    class # 1 capture rate = 0.945095 \n",
      "TRAIN: Batch: 0.6098037682745681 Loss_Total: 12.826627\n",
      "TRAIN: Batch: 0.6098037682745681 Loss_Seg: 11.593599\n",
      "accuracy = 0.939595\n",
      "mean IU  = 0.698015\n",
      "    class # 0 capture rate = 0.939005 \n",
      "    class # 1 capture rate = 0.949910 \n",
      "TRAIN: Batch: 0.6137127667891487 Loss_Total: 14.125088\n",
      "TRAIN: Batch: 0.6137127667891487 Loss_Seg: 13.144583\n",
      "accuracy = 0.935759\n",
      "mean IU  = 0.726873\n",
      "    class # 0 capture rate = 0.935810 \n",
      "    class # 1 capture rate = 0.935128 \n",
      "TRAIN: Batch: 0.6176217653037291 Loss_Total: 12.527454\n",
      "TRAIN: Batch: 0.6176217653037291 Loss_Seg: 12.360057\n",
      "accuracy = 0.947233\n",
      "mean IU  = 0.730903\n",
      "    class # 0 capture rate = 0.948928 \n",
      "    class # 1 capture rate = 0.921366 \n",
      "TRAIN: Batch: 0.6215307638183097 Loss_Total: 13.83666\n",
      "TRAIN: Batch: 0.6215307638183097 Loss_Seg: 16.425257\n",
      "accuracy = 0.921732\n",
      "mean IU  = 0.694426\n",
      "    class # 0 capture rate = 0.923947 \n",
      "    class # 1 capture rate = 0.895704 \n",
      "TRAIN: Batch: 0.6254397623328903 Loss_Total: 11.37775\n",
      "TRAIN: Batch: 0.6254397623328903 Loss_Seg: 10.082426\n",
      "accuracy = 0.951958\n",
      "mean IU  = 0.731733\n",
      "    class # 0 capture rate = 0.952252 \n",
      "    class # 1 capture rate = 0.946770 \n",
      "TRAIN: Batch: 0.6293487608474708 Loss_Total: 12.664211\n",
      "TRAIN: Batch: 0.6293487608474708 Loss_Seg: 11.931642\n",
      "accuracy = 0.946116\n",
      "mean IU  = 0.722303\n",
      "    class # 0 capture rate = 0.948240 \n",
      "    class # 1 capture rate = 0.912490 \n",
      "TRAIN: Batch: 0.6332577593620514 Loss_Total: 9.803886\n",
      "TRAIN: Batch: 0.6332577593620514 Loss_Seg: 10.067029\n",
      "accuracy = 0.957079\n",
      "mean IU  = 0.736022\n",
      "    class # 0 capture rate = 0.958889 \n",
      "    class # 1 capture rate = 0.922549 \n",
      "TRAIN: Batch: 0.637166757876632 Loss_Total: 17.913347\n",
      "TRAIN: Batch: 0.637166757876632 Loss_Seg: 25.821571\n",
      "accuracy = 0.907119\n",
      "mean IU  = 0.707729\n",
      "    class # 0 capture rate = 0.909601 \n",
      "    class # 1 capture rate = 0.887589 \n",
      "TRAIN: Batch: 0.6410757563912126 Loss_Total: 10.288013\n",
      "TRAIN: Batch: 0.6410757563912126 Loss_Seg: 12.632171\n",
      "accuracy = 0.951947\n",
      "mean IU  = 0.733899\n",
      "    class # 0 capture rate = 0.954412 \n",
      "    class # 1 capture rate = 0.911006 \n",
      "TRAIN: Batch: 0.6449847549057931 Loss_Total: 10.8030815\n",
      "TRAIN: Batch: 0.6449847549057931 Loss_Seg: 10.891035\n",
      "accuracy = 0.952929\n",
      "mean IU  = 0.741209\n",
      "    class # 0 capture rate = 0.955144 \n",
      "    class # 1 capture rate = 0.917189 \n",
      "TRAIN: Batch: 0.6488937534203737 Loss_Total: 13.431438\n",
      "TRAIN: Batch: 0.6488937534203737 Loss_Seg: 15.116794\n",
      "accuracy = 0.940129\n",
      "mean IU  = 0.737026\n",
      "    class # 0 capture rate = 0.942465 \n",
      "    class # 1 capture rate = 0.911962 \n",
      "TRAIN: Batch: 0.6528027519349543 Loss_Total: 13.175999\n",
      "TRAIN: Batch: 0.6528027519349543 Loss_Seg: 11.350618\n",
      "accuracy = 0.946178\n",
      "mean IU  = 0.740120\n",
      "    class # 0 capture rate = 0.944973 \n",
      "    class # 1 capture rate = 0.963534 \n",
      "TRAIN: Batch: 0.6567117504495348 Loss_Total: 11.647058\n",
      "TRAIN: Batch: 0.6567117504495348 Loss_Seg: 9.918618\n",
      "accuracy = 0.950217\n",
      "mean IU  = 0.677690\n",
      "    class # 0 capture rate = 0.951343 \n",
      "    class # 1 capture rate = 0.921001 \n",
      "TRAIN: Batch: 0.6606207489641154 Loss_Total: 11.543528\n",
      "TRAIN: Batch: 0.6606207489641154 Loss_Seg: 12.731033\n",
      "accuracy = 0.933932\n",
      "mean IU  = 0.694725\n",
      "    class # 0 capture rate = 0.933164 \n",
      "    class # 1 capture rate = 0.946113 \n",
      "TRAIN: Batch: 0.664529747478696 Loss_Total: 12.498787\n",
      "TRAIN: Batch: 0.664529747478696 Loss_Seg: 12.793633\n",
      "accuracy = 0.942917\n",
      "mean IU  = 0.693717\n",
      "    class # 0 capture rate = 0.944772 \n",
      "    class # 1 capture rate = 0.908305 \n",
      "TRAIN: Batch: 0.6684387459932766 Loss_Total: 16.09446\n",
      "TRAIN: Batch: 0.6684387459932766 Loss_Seg: 16.71047\n",
      "accuracy = 0.925932\n",
      "mean IU  = 0.721357\n",
      "    class # 0 capture rate = 0.926940 \n",
      "    class # 1 capture rate = 0.915590 \n",
      "TRAIN: Batch: 0.6723477445078571 Loss_Total: 14.651032\n",
      "TRAIN: Batch: 0.6723477445078571 Loss_Seg: 15.458483\n",
      "accuracy = 0.921005\n",
      "mean IU  = 0.642315\n",
      "    class # 0 capture rate = 0.921688 \n",
      "    class # 1 capture rate = 0.908168 \n",
      "TRAIN: Batch: 0.6762567430224377 Loss_Total: 13.811757\n",
      "TRAIN: Batch: 0.6762567430224377 Loss_Seg: 15.07088\n",
      "accuracy = 0.932337\n",
      "mean IU  = 0.740238\n",
      "    class # 0 capture rate = 0.930959 \n",
      "    class # 1 capture rate = 0.946458 \n",
      "TRAIN: Batch: 0.6801657415370183 Loss_Total: 10.271848\n",
      "TRAIN: Batch: 0.6801657415370183 Loss_Seg: 9.434292\n",
      "accuracy = 0.956763\n",
      "mean IU  = 0.730241\n",
      "    class # 0 capture rate = 0.958532 \n",
      "    class # 1 capture rate = 0.921668 \n",
      "TRAIN: Batch: 0.6840747400515987 Loss_Total: 10.548637\n",
      "TRAIN: Batch: 0.6840747400515987 Loss_Seg: 10.660091\n",
      "accuracy = 0.948921\n",
      "mean IU  = 0.736270\n",
      "    class # 0 capture rate = 0.949579 \n",
      "    class # 1 capture rate = 0.938710 \n",
      "TRAIN: Batch: 0.6879837385661793 Loss_Total: 11.139591\n",
      "TRAIN: Batch: 0.6879837385661793 Loss_Seg: 10.619961\n",
      "accuracy = 0.944864\n",
      "mean IU  = 0.713163\n",
      "    class # 0 capture rate = 0.944599 \n",
      "    class # 1 capture rate = 0.949441 \n",
      "TRAIN: Batch: 0.6918927370807599 Loss_Total: 13.292971\n",
      "TRAIN: Batch: 0.6918927370807599 Loss_Seg: 12.686583\n",
      "accuracy = 0.936309\n",
      "mean IU  = 0.706248\n",
      "    class # 0 capture rate = 0.936337 \n",
      "    class # 1 capture rate = 0.935897 \n",
      "TRAIN: Batch: 0.6958017355953404 Loss_Total: 15.113707\n",
      "TRAIN: Batch: 0.6958017355953404 Loss_Seg: 10.654923\n",
      "accuracy = 0.946475\n",
      "mean IU  = 0.726363\n",
      "    class # 0 capture rate = 0.946605 \n",
      "    class # 1 capture rate = 0.944398 \n",
      "TRAIN: Batch: 0.699710734109921 Loss_Total: 11.493469\n",
      "TRAIN: Batch: 0.699710734109921 Loss_Seg: 9.922221\n",
      "accuracy = 0.946160\n",
      "mean IU  = 0.697983\n",
      "    class # 0 capture rate = 0.946461 \n",
      "    class # 1 capture rate = 0.940114 \n",
      "TRAIN: Batch: 0.7036197326245016 Loss_Total: 10.266691\n",
      "TRAIN: Batch: 0.7036197326245016 Loss_Seg: 9.226223\n",
      "accuracy = 0.957925\n",
      "mean IU  = 0.744808\n",
      "    class # 0 capture rate = 0.958057 \n",
      "    class # 1 capture rate = 0.955448 \n",
      "TRAIN: Batch: 0.7075287311390822 Loss_Total: 12.061926\n",
      "TRAIN: Batch: 0.7075287311390822 Loss_Seg: 9.714757\n",
      "accuracy = 0.949088\n",
      "mean IU  = 0.717167\n",
      "    class # 0 capture rate = 0.949564 \n",
      "    class # 1 capture rate = 0.940341 \n",
      "TRAIN: Batch: 0.7114377296536627 Loss_Total: 13.6038\n",
      "TRAIN: Batch: 0.7114377296536627 Loss_Seg: 10.750209\n",
      "accuracy = 0.952587\n",
      "mean IU  = 0.758367\n",
      "    class # 0 capture rate = 0.952469 \n",
      "    class # 1 capture rate = 0.954273 \n",
      "TRAIN: Batch: 0.7153467281682433 Loss_Total: 12.3346195\n",
      "TRAIN: Batch: 0.7153467281682433 Loss_Seg: 10.951897\n",
      "accuracy = 0.948143\n",
      "mean IU  = 0.713169\n",
      "    class # 0 capture rate = 0.950402 \n",
      "    class # 1 capture rate = 0.907707 \n",
      "TRAIN: Batch: 0.7192557266828239 Loss_Total: 14.80515\n",
      "TRAIN: Batch: 0.7192557266828239 Loss_Seg: 13.238144\n",
      "accuracy = 0.928341\n",
      "mean IU  = 0.676462\n",
      "    class # 0 capture rate = 0.927933 \n",
      "    class # 1 capture rate = 0.935032 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.7231647251974044 Loss_Total: 10.605475\n",
      "TRAIN: Batch: 0.7231647251974044 Loss_Seg: 9.972358\n",
      "accuracy = 0.953951\n",
      "mean IU  = 0.759894\n",
      "    class # 0 capture rate = 0.954023 \n",
      "    class # 1 capture rate = 0.952892 \n",
      "TRAIN: Batch: 0.727073723711985 Loss_Total: 15.870716\n",
      "TRAIN: Batch: 0.727073723711985 Loss_Seg: 14.149777\n",
      "accuracy = 0.937738\n",
      "mean IU  = 0.702897\n",
      "    class # 0 capture rate = 0.940370 \n",
      "    class # 1 capture rate = 0.897871 \n",
      "TRAIN: Batch: 0.7309827222265656 Loss_Total: 11.334179\n",
      "TRAIN: Batch: 0.7309827222265656 Loss_Seg: 10.445247\n",
      "accuracy = 0.946258\n",
      "mean IU  = 0.710709\n",
      "    class # 0 capture rate = 0.947516 \n",
      "    class # 1 capture rate = 0.923888 \n",
      "TRAIN: Batch: 0.7348917207411462 Loss_Total: 10.320846\n",
      "TRAIN: Batch: 0.7348917207411462 Loss_Seg: 9.1461935\n",
      "accuracy = 0.951361\n",
      "mean IU  = 0.748708\n",
      "    class # 0 capture rate = 0.951212 \n",
      "    class # 1 capture rate = 0.953616 \n",
      "TRAIN: Batch: 0.7388007192557267 Loss_Total: 12.343693\n",
      "TRAIN: Batch: 0.7388007192557267 Loss_Seg: 13.858395\n",
      "accuracy = 0.934618\n",
      "mean IU  = 0.709449\n",
      "    class # 0 capture rate = 0.935719 \n",
      "    class # 1 capture rate = 0.919511 \n",
      "TRAIN: Batch: 0.7427097177703073 Loss_Total: 10.337962\n",
      "TRAIN: Batch: 0.7427097177703073 Loss_Seg: 10.240255\n",
      "accuracy = 0.946352\n",
      "mean IU  = 0.731981\n",
      "    class # 0 capture rate = 0.945136 \n",
      "    class # 1 capture rate = 0.965253 \n",
      "TRAIN: Batch: 0.7466187162848879 Loss_Total: 11.361453\n",
      "TRAIN: Batch: 0.7466187162848879 Loss_Seg: 10.050798\n",
      "accuracy = 0.952534\n",
      "mean IU  = 0.756148\n",
      "    class # 0 capture rate = 0.952442 \n",
      "    class # 1 capture rate = 0.953887 \n",
      "TRAIN: Batch: 0.7505277147994683 Loss_Total: 9.688945\n",
      "TRAIN: Batch: 0.7505277147994683 Loss_Seg: 6.552239\n",
      "accuracy = 0.965325\n",
      "mean IU  = 0.796964\n",
      "    class # 0 capture rate = 0.964293 \n",
      "    class # 1 capture rate = 0.981392 \n",
      "TRAIN: Batch: 0.7544367133140489 Loss_Total: 12.382311\n",
      "TRAIN: Batch: 0.7544367133140489 Loss_Seg: 10.292949\n",
      "accuracy = 0.938354\n",
      "mean IU  = 0.667692\n",
      "    class # 0 capture rate = 0.938440 \n",
      "    class # 1 capture rate = 0.936490 \n",
      "TRAIN: Batch: 0.7583457118286295 Loss_Total: 13.473333\n",
      "TRAIN: Batch: 0.7583457118286295 Loss_Seg: 13.530356\n",
      "accuracy = 0.936862\n",
      "mean IU  = 0.685772\n",
      "    class # 0 capture rate = 0.937689 \n",
      "    class # 1 capture rate = 0.922197 \n",
      "TRAIN: Batch: 0.76225471034321 Loss_Total: 9.885561\n",
      "TRAIN: Batch: 0.76225471034321 Loss_Seg: 11.207652\n",
      "accuracy = 0.945725\n",
      "mean IU  = 0.724859\n",
      "    class # 0 capture rate = 0.946282 \n",
      "    class # 1 capture rate = 0.936937 \n",
      "TRAIN: Batch: 0.7661637088577906 Loss_Total: 10.018224\n",
      "TRAIN: Batch: 0.7661637088577906 Loss_Seg: 10.371233\n",
      "accuracy = 0.958056\n",
      "mean IU  = 0.765973\n",
      "    class # 0 capture rate = 0.960891 \n",
      "    class # 1 capture rate = 0.915427 \n",
      "TRAIN: Batch: 0.7700727073723712 Loss_Total: 14.87433\n",
      "TRAIN: Batch: 0.7700727073723712 Loss_Seg: 16.163063\n",
      "accuracy = 0.923933\n",
      "mean IU  = 0.700969\n",
      "    class # 0 capture rate = 0.925884 \n",
      "    class # 1 capture rate = 0.901235 \n",
      "TRAIN: Batch: 0.7739817058869518 Loss_Total: 9.934982\n",
      "TRAIN: Batch: 0.7739817058869518 Loss_Seg: 9.705635\n",
      "accuracy = 0.956567\n",
      "mean IU  = 0.706022\n",
      "    class # 0 capture rate = 0.958221 \n",
      "    class # 1 capture rate = 0.916769 \n",
      "TRAIN: Batch: 0.7778907044015323 Loss_Total: 11.502128\n",
      "TRAIN: Batch: 0.7778907044015323 Loss_Seg: 10.420409\n",
      "accuracy = 0.942090\n",
      "mean IU  = 0.686512\n",
      "    class # 0 capture rate = 0.942533 \n",
      "    class # 1 capture rate = 0.933196 \n",
      "TRAIN: Batch: 0.7817997029161129 Loss_Total: 20.482965\n",
      "TRAIN: Batch: 0.7817997029161129 Loss_Seg: 24.305723\n",
      "accuracy = 0.909735\n",
      "mean IU  = 0.687885\n",
      "    class # 0 capture rate = 0.914727 \n",
      "    class # 1 capture rate = 0.861837 \n",
      "TRAIN: Batch: 0.7857087014306935 Loss_Total: 16.369493\n",
      "TRAIN: Batch: 0.7857087014306935 Loss_Seg: 18.530882\n",
      "accuracy = 0.908800\n",
      "mean IU  = 0.671576\n",
      "    class # 0 capture rate = 0.908700 \n",
      "    class # 1 capture rate = 0.909960 \n",
      "TRAIN: Batch: 0.789617699945274 Loss_Total: 14.534148\n",
      "TRAIN: Batch: 0.789617699945274 Loss_Seg: 14.56598\n",
      "accuracy = 0.934512\n",
      "mean IU  = 0.688368\n",
      "    class # 0 capture rate = 0.936566 \n",
      "    class # 1 capture rate = 0.901420 \n",
      "TRAIN: Batch: 0.7935266984598546 Loss_Total: 11.769428\n",
      "TRAIN: Batch: 0.7935266984598546 Loss_Seg: 10.572324\n",
      "accuracy = 0.946637\n",
      "mean IU  = 0.716328\n",
      "    class # 0 capture rate = 0.947351 \n",
      "    class # 1 capture rate = 0.934287 \n",
      "TRAIN: Batch: 0.7974356969744352 Loss_Total: 9.816406\n",
      "TRAIN: Batch: 0.7974356969744352 Loss_Seg: 9.668611\n",
      "accuracy = 0.948851\n",
      "mean IU  = 0.738097\n",
      "    class # 0 capture rate = 0.948146 \n",
      "    class # 1 capture rate = 0.959854 \n",
      "TRAIN: Batch: 0.8013446954890158 Loss_Total: 11.211092\n",
      "TRAIN: Batch: 0.8013446954890158 Loss_Seg: 10.412213\n",
      "accuracy = 0.944709\n",
      "mean IU  = 0.719147\n",
      "    class # 0 capture rate = 0.944004 \n",
      "    class # 1 capture rate = 0.956354 \n",
      "TRAIN: Batch: 0.8052536940035963 Loss_Total: 13.679897\n",
      "TRAIN: Batch: 0.8052536940035963 Loss_Seg: 14.191119\n",
      "accuracy = 0.945159\n",
      "mean IU  = 0.703321\n",
      "    class # 0 capture rate = 0.950415 \n",
      "    class # 1 capture rate = 0.855761 \n",
      "TRAIN: Batch: 0.8091626925181769 Loss_Total: 13.552687\n",
      "TRAIN: Batch: 0.8091626925181769 Loss_Seg: 10.884521\n",
      "accuracy = 0.948106\n",
      "mean IU  = 0.725107\n",
      "    class # 0 capture rate = 0.948041 \n",
      "    class # 1 capture rate = 0.949212 \n",
      "TRAIN: Batch: 0.8130716910327574 Loss_Total: 11.933996\n",
      "TRAIN: Batch: 0.8130716910327574 Loss_Seg: 12.723851\n",
      "accuracy = 0.951242\n",
      "mean IU  = 0.728452\n",
      "    class # 0 capture rate = 0.956152 \n",
      "    class # 1 capture rate = 0.871254 \n",
      "TRAIN: Batch: 0.8169806895473379 Loss_Total: 12.305872\n",
      "TRAIN: Batch: 0.8169806895473379 Loss_Seg: 12.079246\n",
      "accuracy = 0.945865\n",
      "mean IU  = 0.744173\n",
      "    class # 0 capture rate = 0.946467 \n",
      "    class # 1 capture rate = 0.937807 \n",
      "TRAIN: Batch: 0.8208896880619185 Loss_Total: 10.041811\n",
      "TRAIN: Batch: 0.8208896880619185 Loss_Seg: 10.69508\n",
      "accuracy = 0.948165\n",
      "mean IU  = 0.724856\n",
      "    class # 0 capture rate = 0.948505 \n",
      "    class # 1 capture rate = 0.942433 \n",
      "TRAIN: Batch: 0.8247986865764991 Loss_Total: 12.643032\n",
      "TRAIN: Batch: 0.8247986865764991 Loss_Seg: 14.176244\n",
      "accuracy = 0.942624\n",
      "mean IU  = 0.710712\n",
      "    class # 0 capture rate = 0.943696 \n",
      "    class # 1 capture rate = 0.925127 \n",
      "TRAIN: Batch: 0.8287076850910796 Loss_Total: 11.77877\n",
      "TRAIN: Batch: 0.8287076850910796 Loss_Seg: 11.769043\n",
      "accuracy = 0.949819\n",
      "mean IU  = 0.738280\n",
      "    class # 0 capture rate = 0.950379 \n",
      "    class # 1 capture rate = 0.941057 \n",
      "TRAIN: Batch: 0.8326166836056602 Loss_Total: 14.284863\n",
      "TRAIN: Batch: 0.8326166836056602 Loss_Seg: 17.200243\n",
      "accuracy = 0.910989\n",
      "mean IU  = 0.674428\n",
      "    class # 0 capture rate = 0.909081 \n",
      "    class # 1 capture rate = 0.934080 \n",
      "TRAIN: Batch: 0.8365256821202408 Loss_Total: 12.578421\n",
      "TRAIN: Batch: 0.8365256821202408 Loss_Seg: 8.096585\n",
      "accuracy = 0.958469\n",
      "mean IU  = 0.750015\n",
      "    class # 0 capture rate = 0.957832 \n",
      "    class # 1 capture rate = 0.970321 \n",
      "TRAIN: Batch: 0.8404346806348214 Loss_Total: 10.460171\n",
      "TRAIN: Batch: 0.8404346806348214 Loss_Seg: 9.881439\n",
      "accuracy = 0.940839\n",
      "mean IU  = 0.686866\n",
      "    class # 0 capture rate = 0.940148 \n",
      "    class # 1 capture rate = 0.954592 \n",
      "TRAIN: Batch: 0.8443436791494019 Loss_Total: 14.105257\n",
      "TRAIN: Batch: 0.8443436791494019 Loss_Seg: 10.050992\n",
      "accuracy = 0.951459\n",
      "mean IU  = 0.743539\n",
      "    class # 0 capture rate = 0.951178 \n",
      "    class # 1 capture rate = 0.955913 \n",
      "TRAIN: Batch: 0.8482526776639825 Loss_Total: 8.87287\n",
      "TRAIN: Batch: 0.8482526776639825 Loss_Seg: 8.806092\n",
      "accuracy = 0.956222\n",
      "mean IU  = 0.734810\n",
      "    class # 0 capture rate = 0.957664 \n",
      "    class # 1 capture rate = 0.928919 \n",
      "TRAIN: Batch: 0.8521616761785631 Loss_Total: 9.697231\n",
      "TRAIN: Batch: 0.8521616761785631 Loss_Seg: 9.490365\n",
      "accuracy = 0.955951\n",
      "mean IU  = 0.751673\n",
      "    class # 0 capture rate = 0.956382 \n",
      "    class # 1 capture rate = 0.948773 \n",
      "TRAIN: Batch: 0.8560706746931436 Loss_Total: 11.211842\n",
      "TRAIN: Batch: 0.8560706746931436 Loss_Seg: 10.594569\n",
      "accuracy = 0.944892\n",
      "mean IU  = 0.705445\n",
      "    class # 0 capture rate = 0.945813 \n",
      "    class # 1 capture rate = 0.928239 \n",
      "TRAIN: Batch: 0.8599796732077242 Loss_Total: 16.312948\n",
      "TRAIN: Batch: 0.8599796732077242 Loss_Seg: 22.434172\n",
      "accuracy = 0.919904\n",
      "mean IU  = 0.692028\n",
      "    class # 0 capture rate = 0.925894 \n",
      "    class # 1 capture rate = 0.853959 \n",
      "TRAIN: Batch: 0.8638886717223048 Loss_Total: 12.653962\n",
      "TRAIN: Batch: 0.8638886717223048 Loss_Seg: 10.810833\n",
      "accuracy = 0.950284\n",
      "mean IU  = 0.753310\n",
      "    class # 0 capture rate = 0.949927 \n",
      "    class # 1 capture rate = 0.955334 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.8677976702368853 Loss_Total: 13.642321\n",
      "TRAIN: Batch: 0.8677976702368853 Loss_Seg: 10.900052\n",
      "accuracy = 0.944227\n",
      "mean IU  = 0.737523\n",
      "    class # 0 capture rate = 0.943956 \n",
      "    class # 1 capture rate = 0.947977 \n",
      "TRAIN: Batch: 0.8717066687514659 Loss_Total: 10.99448\n",
      "TRAIN: Batch: 0.8717066687514659 Loss_Seg: 9.139123\n",
      "accuracy = 0.952851\n",
      "mean IU  = 0.723321\n",
      "    class # 0 capture rate = 0.953167 \n",
      "    class # 1 capture rate = 0.946713 \n",
      "TRAIN: Batch: 0.8756156672660464 Loss_Total: 13.558284\n",
      "TRAIN: Batch: 0.8756156672660464 Loss_Seg: 9.402849\n",
      "accuracy = 0.947969\n",
      "mean IU  = 0.730136\n",
      "    class # 0 capture rate = 0.946805 \n",
      "    class # 1 capture rate = 0.967136 \n",
      "TRAIN: Batch: 0.879524665780627 Loss_Total: 11.202413\n",
      "TRAIN: Batch: 0.879524665780627 Loss_Seg: 13.267897\n",
      "accuracy = 0.932645\n",
      "mean IU  = 0.703664\n",
      "    class # 0 capture rate = 0.932688 \n",
      "    class # 1 capture rate = 0.932035 \n",
      "TRAIN: Batch: 0.8834336642952075 Loss_Total: 13.245\n",
      "TRAIN: Batch: 0.8834336642952075 Loss_Seg: 18.847576\n",
      "accuracy = 0.932229\n",
      "mean IU  = 0.685241\n",
      "    class # 0 capture rate = 0.938875 \n",
      "    class # 1 capture rate = 0.835486 \n",
      "TRAIN: Batch: 0.8873426628097881 Loss_Total: 11.771017\n",
      "TRAIN: Batch: 0.8873426628097881 Loss_Seg: 12.742167\n",
      "accuracy = 0.930753\n",
      "mean IU  = 0.676285\n",
      "    class # 0 capture rate = 0.930217 \n",
      "    class # 1 capture rate = 0.940045 \n",
      "TRAIN: Batch: 0.8912516613243687 Loss_Total: 15.743223\n",
      "TRAIN: Batch: 0.8912516613243687 Loss_Seg: 16.074993\n",
      "accuracy = 0.923458\n",
      "mean IU  = 0.710365\n",
      "    class # 0 capture rate = 0.923563 \n",
      "    class # 1 capture rate = 0.922319 \n",
      "TRAIN: Batch: 0.8951606598389492 Loss_Total: 10.061672\n",
      "TRAIN: Batch: 0.8951606598389492 Loss_Seg: 7.9408464\n",
      "accuracy = 0.957686\n",
      "mean IU  = 0.716840\n",
      "    class # 0 capture rate = 0.958198 \n",
      "    class # 1 capture rate = 0.945704 \n",
      "TRAIN: Batch: 0.8990696583535298 Loss_Total: 10.161032\n",
      "TRAIN: Batch: 0.8990696583535298 Loss_Seg: 8.824251\n",
      "accuracy = 0.960837\n",
      "mean IU  = 0.743293\n",
      "    class # 0 capture rate = 0.961920 \n",
      "    class # 1 capture rate = 0.938679 \n",
      "TRAIN: Batch: 0.9029786568681104 Loss_Total: 13.246386\n",
      "TRAIN: Batch: 0.9029786568681104 Loss_Seg: 12.7474985\n",
      "accuracy = 0.928221\n",
      "mean IU  = 0.714851\n",
      "    class # 0 capture rate = 0.926599 \n",
      "    class # 1 capture rate = 0.947401 \n",
      "TRAIN: Batch: 0.906887655382691 Loss_Total: 11.533176\n",
      "TRAIN: Batch: 0.906887655382691 Loss_Seg: 12.172625\n",
      "accuracy = 0.940169\n",
      "mean IU  = 0.729746\n",
      "    class # 0 capture rate = 0.940582 \n",
      "    class # 1 capture rate = 0.934722 \n",
      "TRAIN: Batch: 0.9107966538972715 Loss_Total: 13.286992\n",
      "TRAIN: Batch: 0.9107966538972715 Loss_Seg: 14.903182\n",
      "accuracy = 0.949948\n",
      "mean IU  = 0.713872\n",
      "    class # 0 capture rate = 0.955988 \n",
      "    class # 1 capture rate = 0.845536 \n",
      "TRAIN: Batch: 0.9147056524118521 Loss_Total: 12.40074\n",
      "TRAIN: Batch: 0.9147056524118521 Loss_Seg: 12.61771\n",
      "accuracy = 0.938001\n",
      "mean IU  = 0.734568\n",
      "    class # 0 capture rate = 0.937882 \n",
      "    class # 1 capture rate = 0.939442 \n",
      "TRAIN: Batch: 0.9186146509264327 Loss_Total: 11.308874\n",
      "TRAIN: Batch: 0.9186146509264327 Loss_Seg: 8.675359\n",
      "accuracy = 0.959807\n",
      "mean IU  = 0.763443\n",
      "    class # 0 capture rate = 0.960375 \n",
      "    class # 1 capture rate = 0.950218 \n",
      "TRAIN: Batch: 0.9225236494410132 Loss_Total: 11.543017\n",
      "TRAIN: Batch: 0.9225236494410132 Loss_Seg: 10.449703\n",
      "accuracy = 0.957908\n",
      "mean IU  = 0.767718\n",
      "    class # 0 capture rate = 0.958016 \n",
      "    class # 1 capture rate = 0.956242 \n",
      "TRAIN: Batch: 0.9264326479555938 Loss_Total: 14.665491\n",
      "TRAIN: Batch: 0.9264326479555938 Loss_Seg: 15.219606\n",
      "accuracy = 0.924796\n",
      "mean IU  = 0.698081\n",
      "    class # 0 capture rate = 0.925593 \n",
      "    class # 1 capture rate = 0.914956 \n",
      "TRAIN: Batch: 0.9303416464701744 Loss_Total: 9.551842\n",
      "TRAIN: Batch: 0.9303416464701744 Loss_Seg: 10.930972\n",
      "accuracy = 0.942058\n",
      "mean IU  = 0.700345\n",
      "    class # 0 capture rate = 0.941787 \n",
      "    class # 1 capture rate = 0.946952 \n",
      "TRAIN: Batch: 0.9342506449847549 Loss_Total: 11.925406\n",
      "TRAIN: Batch: 0.9342506449847549 Loss_Seg: 12.031239\n",
      "accuracy = 0.951387\n",
      "mean IU  = 0.745201\n",
      "    class # 0 capture rate = 0.954503 \n",
      "    class # 1 capture rate = 0.905457 \n",
      "TRAIN: Batch: 0.9381596434993354 Loss_Total: 10.887158\n",
      "TRAIN: Batch: 0.9381596434993354 Loss_Seg: 10.79159\n",
      "accuracy = 0.956855\n",
      "mean IU  = 0.765913\n",
      "    class # 0 capture rate = 0.957678 \n",
      "    class # 1 capture rate = 0.944510 \n",
      "TRAIN: Batch: 0.942068642013916 Loss_Total: 12.742773\n",
      "TRAIN: Batch: 0.942068642013916 Loss_Seg: 13.038655\n",
      "accuracy = 0.940438\n",
      "mean IU  = 0.716657\n",
      "    class # 0 capture rate = 0.940404 \n",
      "    class # 1 capture rate = 0.940946 \n",
      "TRAIN: Batch: 0.9459776405284966 Loss_Total: 18.140312\n",
      "TRAIN: Batch: 0.9459776405284966 Loss_Seg: 16.29892\n",
      "accuracy = 0.906735\n",
      "mean IU  = 0.649402\n",
      "    class # 0 capture rate = 0.905646 \n",
      "    class # 1 capture rate = 0.921926 \n",
      "TRAIN: Batch: 0.9498866390430771 Loss_Total: 17.657013\n",
      "TRAIN: Batch: 0.9498866390430771 Loss_Seg: 21.508926\n",
      "accuracy = 0.946182\n",
      "mean IU  = 0.749016\n",
      "    class # 0 capture rate = 0.952195 \n",
      "    class # 1 capture rate = 0.874128 \n",
      "TRAIN: Batch: 0.9537956375576577 Loss_Total: 11.709659\n",
      "TRAIN: Batch: 0.9537956375576577 Loss_Seg: 10.001499\n",
      "accuracy = 0.943746\n",
      "mean IU  = 0.692358\n",
      "    class # 0 capture rate = 0.942864 \n",
      "    class # 1 capture rate = 0.961780 \n",
      "TRAIN: Batch: 0.9577046360722383 Loss_Total: 13.381563\n",
      "TRAIN: Batch: 0.9577046360722383 Loss_Seg: 15.543224\n",
      "accuracy = 0.939928\n",
      "mean IU  = 0.691473\n",
      "    class # 0 capture rate = 0.944338 \n",
      "    class # 1 capture rate = 0.865443 \n",
      "TRAIN: Batch: 0.9616136345868188 Loss_Total: 9.195647\n",
      "TRAIN: Batch: 0.9616136345868188 Loss_Seg: 9.171744\n",
      "accuracy = 0.962816\n",
      "mean IU  = 0.762956\n",
      "    class # 0 capture rate = 0.964095 \n",
      "    class # 1 capture rate = 0.939221 \n",
      "TRAIN: Batch: 0.9655226331013994 Loss_Total: 10.050827\n",
      "TRAIN: Batch: 0.9655226331013994 Loss_Seg: 9.586137\n",
      "accuracy = 0.957584\n",
      "mean IU  = 0.759618\n",
      "    class # 0 capture rate = 0.958290 \n",
      "    class # 1 capture rate = 0.946128 \n",
      "TRAIN: Batch: 0.96943163161598 Loss_Total: 13.291998\n",
      "TRAIN: Batch: 0.96943163161598 Loss_Seg: 10.150893\n",
      "accuracy = 0.946920\n",
      "mean IU  = 0.733801\n",
      "    class # 0 capture rate = 0.946325 \n",
      "    class # 1 capture rate = 0.956053 \n",
      "TRAIN: Batch: 0.9733406301305606 Loss_Total: 12.684206\n",
      "TRAIN: Batch: 0.9733406301305606 Loss_Seg: 10.386963\n",
      "accuracy = 0.945867\n",
      "mean IU  = 0.724516\n",
      "    class # 0 capture rate = 0.945055 \n",
      "    class # 1 capture rate = 0.959089 \n",
      "TRAIN: Batch: 0.9772496286451411 Loss_Total: 10.919821\n",
      "TRAIN: Batch: 0.9772496286451411 Loss_Seg: 10.676934\n",
      "accuracy = 0.953197\n",
      "mean IU  = 0.741670\n",
      "    class # 0 capture rate = 0.954077 \n",
      "    class # 1 capture rate = 0.938600 \n",
      "TRAIN: Batch: 0.9811586271597217 Loss_Total: 13.025188\n",
      "TRAIN: Batch: 0.9811586271597217 Loss_Seg: 9.583023\n",
      "accuracy = 0.942468\n",
      "mean IU  = 0.690060\n",
      "    class # 0 capture rate = 0.941353 \n",
      "    class # 1 capture rate = 0.965122 \n",
      "TRAIN: Batch: 0.9850676256743023 Loss_Total: 10.490307\n",
      "TRAIN: Batch: 0.9850676256743023 Loss_Seg: 9.203007\n",
      "accuracy = 0.950018\n",
      "mean IU  = 0.748875\n",
      "    class # 0 capture rate = 0.949321 \n",
      "    class # 1 capture rate = 0.960245 \n",
      "TRAIN: Batch: 0.9889766241888828 Loss_Total: 10.339746\n",
      "TRAIN: Batch: 0.9889766241888828 Loss_Seg: 12.064668\n",
      "accuracy = 0.929989\n",
      "mean IU  = 0.693160\n",
      "    class # 0 capture rate = 0.927945 \n",
      "    class # 1 capture rate = 0.960784 \n",
      "TRAIN: Batch: 0.9928856227034634 Loss_Total: 15.035762\n",
      "TRAIN: Batch: 0.9928856227034634 Loss_Seg: 17.933125\n",
      "accuracy = 0.937389\n",
      "mean IU  = 0.706474\n",
      "    class # 0 capture rate = 0.943707 \n",
      "    class # 1 capture rate = 0.850504 \n",
      "TRAIN: Batch: 0.996794621218044 Loss_Total: 11.747531\n",
      "TRAIN: Batch: 0.996794621218044 Loss_Seg: 10.505465\n",
      "accuracy = 0.950990\n",
      "mean IU  = 0.736577\n",
      "    class # 0 capture rate = 0.950687 \n",
      "    class # 1 capture rate = 0.956034 \n",
      "Validating NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: Total accuracy: 94.820869%. Class 0 capture: 94.930846%. Class 1 capture: 93.088522%\n",
      "Character error rate improved, save model\n",
      "Epoch: 2  Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.0 Loss_Total: 11.771904\n",
      "TRAIN: Batch: 0.0 Loss_Seg: 13.088664\n",
      "accuracy = 0.946306\n",
      "mean IU  = 0.722357\n",
      "    class # 0 capture rate = 0.949046 \n",
      "    class # 1 capture rate = 0.903226 \n",
      "TRAIN: Batch: 0.003908998514580564 Loss_Total: 13.25333\n",
      "TRAIN: Batch: 0.003908998514580564 Loss_Seg: 13.958004\n",
      "accuracy = 0.930657\n",
      "mean IU  = 0.685781\n",
      "    class # 0 capture rate = 0.932021 \n",
      "    class # 1 capture rate = 0.909708 \n",
      "TRAIN: Batch: 0.007817997029161129 Loss_Total: 10.245403\n",
      "TRAIN: Batch: 0.007817997029161129 Loss_Seg: 10.617004\n",
      "accuracy = 0.938364\n",
      "mean IU  = 0.706856\n",
      "    class # 0 capture rate = 0.937232 \n",
      "    class # 1 capture rate = 0.956325 \n",
      "TRAIN: Batch: 0.011726995543741693 Loss_Total: 15.091477\n",
      "TRAIN: Batch: 0.011726995543741693 Loss_Seg: 14.97229\n",
      "accuracy = 0.940566\n",
      "mean IU  = 0.719412\n",
      "    class # 0 capture rate = 0.944901 \n",
      "    class # 1 capture rate = 0.881149 \n",
      "TRAIN: Batch: 0.015635994058322257 Loss_Total: 14.76417\n",
      "TRAIN: Batch: 0.015635994058322257 Loss_Seg: 16.08379\n",
      "accuracy = 0.927026\n",
      "mean IU  = 0.713024\n",
      "    class # 0 capture rate = 0.928385 \n",
      "    class # 1 capture rate = 0.911730 \n",
      "TRAIN: Batch: 0.019544992572902823 Loss_Total: 11.4468\n",
      "TRAIN: Batch: 0.019544992572902823 Loss_Seg: 10.846294\n",
      "accuracy = 0.948800\n",
      "mean IU  = 0.744407\n",
      "    class # 0 capture rate = 0.949329 \n",
      "    class # 1 capture rate = 0.941154 \n",
      "TRAIN: Batch: 0.023453991087483386 Loss_Total: 11.636444\n",
      "TRAIN: Batch: 0.023453991087483386 Loss_Seg: 9.527279\n",
      "accuracy = 0.948963\n",
      "mean IU  = 0.710161\n",
      "    class # 0 capture rate = 0.949177 \n",
      "    class # 1 capture rate = 0.944779 \n",
      "TRAIN: Batch: 0.02736298960206395 Loss_Total: 11.678892\n",
      "TRAIN: Batch: 0.02736298960206395 Loss_Seg: 11.460105\n",
      "accuracy = 0.942236\n",
      "mean IU  = 0.698433\n",
      "    class # 0 capture rate = 0.942373 \n",
      "    class # 1 capture rate = 0.939736 \n",
      "TRAIN: Batch: 0.031271988116644514 Loss_Total: 13.187942\n",
      "TRAIN: Batch: 0.031271988116644514 Loss_Seg: 9.207293\n",
      "accuracy = 0.958129\n",
      "mean IU  = 0.778875\n",
      "    class # 0 capture rate = 0.958215 \n",
      "    class # 1 capture rate = 0.956922 \n",
      "TRAIN: Batch: 0.035180986631225084 Loss_Total: 9.593007\n",
      "TRAIN: Batch: 0.035180986631225084 Loss_Seg: 9.438977\n",
      "accuracy = 0.946504\n",
      "mean IU  = 0.719695\n",
      "    class # 0 capture rate = 0.945531 \n",
      "    class # 1 capture rate = 0.963344 \n",
      "TRAIN: Batch: 0.039089985145805646 Loss_Total: 9.688713\n",
      "TRAIN: Batch: 0.039089985145805646 Loss_Seg: 7.168802\n",
      "accuracy = 0.963110\n",
      "mean IU  = 0.745835\n",
      "    class # 0 capture rate = 0.963447 \n",
      "    class # 1 capture rate = 0.955717 \n",
      "TRAIN: Batch: 0.04299898366038621 Loss_Total: 8.613953\n",
      "TRAIN: Batch: 0.04299898366038621 Loss_Seg: 10.103638\n",
      "accuracy = 0.959077\n",
      "mean IU  = 0.770197\n",
      "    class # 0 capture rate = 0.960366 \n",
      "    class # 1 capture rate = 0.939273 \n",
      "TRAIN: Batch: 0.04690798217496677 Loss_Total: 11.56797\n",
      "TRAIN: Batch: 0.04690798217496677 Loss_Seg: 11.396579\n",
      "accuracy = 0.952875\n",
      "mean IU  = 0.723072\n",
      "    class # 0 capture rate = 0.953786 \n",
      "    class # 1 capture rate = 0.935372 \n",
      "TRAIN: Batch: 0.05081698068954734 Loss_Total: 13.654899\n",
      "TRAIN: Batch: 0.05081698068954734 Loss_Seg: 13.012779\n",
      "accuracy = 0.938588\n",
      "mean IU  = 0.724947\n",
      "    class # 0 capture rate = 0.940139 \n",
      "    class # 1 capture rate = 0.918353 \n",
      "TRAIN: Batch: 0.0547259792041279 Loss_Total: 10.762151\n",
      "TRAIN: Batch: 0.0547259792041279 Loss_Seg: 9.379547\n",
      "accuracy = 0.954479\n",
      "mean IU  = 0.736588\n",
      "    class # 0 capture rate = 0.954043 \n",
      "    class # 1 capture rate = 0.962506 \n",
      "TRAIN: Batch: 0.058634977718708466 Loss_Total: 15.61125\n",
      "TRAIN: Batch: 0.058634977718708466 Loss_Seg: 17.036705\n",
      "accuracy = 0.929309\n",
      "mean IU  = 0.700192\n",
      "    class # 0 capture rate = 0.931680 \n",
      "    class # 1 capture rate = 0.898496 \n",
      "TRAIN: Batch: 0.06254397623328903 Loss_Total: 9.86837\n",
      "TRAIN: Batch: 0.06254397623328903 Loss_Seg: 10.352826\n",
      "accuracy = 0.951090\n",
      "mean IU  = 0.731653\n",
      "    class # 0 capture rate = 0.952090 \n",
      "    class # 1 capture rate = 0.934095 \n",
      "TRAIN: Batch: 0.0664529747478696 Loss_Total: 12.22471\n",
      "TRAIN: Batch: 0.0664529747478696 Loss_Seg: 12.220057\n",
      "accuracy = 0.937486\n",
      "mean IU  = 0.717042\n",
      "    class # 0 capture rate = 0.937113 \n",
      "    class # 1 capture rate = 0.942731 \n",
      "TRAIN: Batch: 0.07036197326245017 Loss_Total: 10.035315\n",
      "TRAIN: Batch: 0.07036197326245017 Loss_Seg: 9.492744\n",
      "accuracy = 0.950411\n",
      "mean IU  = 0.735785\n",
      "    class # 0 capture rate = 0.950272 \n",
      "    class # 1 capture rate = 0.952706 \n",
      "TRAIN: Batch: 0.07427097177703072 Loss_Total: 16.54137\n",
      "TRAIN: Batch: 0.07427097177703072 Loss_Seg: 15.652062\n",
      "accuracy = 0.935946\n",
      "mean IU  = 0.710036\n",
      "    class # 0 capture rate = 0.939375 \n",
      "    class # 1 capture rate = 0.889481 \n",
      "TRAIN: Batch: 0.07817997029161129 Loss_Total: 13.733405\n",
      "TRAIN: Batch: 0.07817997029161129 Loss_Seg: 14.065106\n",
      "accuracy = 0.938477\n",
      "mean IU  = 0.719873\n",
      "    class # 0 capture rate = 0.939022 \n",
      "    class # 1 capture rate = 0.930947 \n",
      "TRAIN: Batch: 0.08208896880619185 Loss_Total: 11.392101\n",
      "TRAIN: Batch: 0.08208896880619185 Loss_Seg: 11.873238\n",
      "accuracy = 0.949165\n",
      "mean IU  = 0.729636\n",
      "    class # 0 capture rate = 0.950605 \n",
      "    class # 1 capture rate = 0.925707 \n",
      "TRAIN: Batch: 0.08599796732077242 Loss_Total: 13.50108\n",
      "TRAIN: Batch: 0.08599796732077242 Loss_Seg: 12.422516\n",
      "accuracy = 0.933348\n",
      "mean IU  = 0.693373\n",
      "    class # 0 capture rate = 0.933486 \n",
      "    class # 1 capture rate = 0.931202 \n",
      "TRAIN: Batch: 0.08990696583535299 Loss_Total: 12.8652935\n",
      "TRAIN: Batch: 0.08990696583535299 Loss_Seg: 11.576009\n",
      "accuracy = 0.936799\n",
      "mean IU  = 0.693651\n",
      "    class # 0 capture rate = 0.935827 \n",
      "    class # 1 capture rate = 0.953478 \n",
      "TRAIN: Batch: 0.09381596434993354 Loss_Total: 9.08034\n",
      "TRAIN: Batch: 0.09381596434993354 Loss_Seg: 8.426389\n",
      "accuracy = 0.963400\n",
      "mean IU  = 0.769667\n",
      "    class # 0 capture rate = 0.964618 \n",
      "    class # 1 capture rate = 0.941716 \n",
      "TRAIN: Batch: 0.09772496286451411 Loss_Total: 12.297274\n",
      "TRAIN: Batch: 0.09772496286451411 Loss_Seg: 13.563141\n",
      "accuracy = 0.932100\n",
      "mean IU  = 0.710412\n",
      "    class # 0 capture rate = 0.931355 \n",
      "    class # 1 capture rate = 0.941953 \n",
      "TRAIN: Batch: 0.10163396137909468 Loss_Total: 14.639616\n",
      "TRAIN: Batch: 0.10163396137909468 Loss_Seg: 15.628064\n",
      "accuracy = 0.929208\n",
      "mean IU  = 0.706788\n",
      "    class # 0 capture rate = 0.930144 \n",
      "    class # 1 capture rate = 0.917492 \n",
      "TRAIN: Batch: 0.10554295989367524 Loss_Total: 14.234616\n",
      "TRAIN: Batch: 0.10554295989367524 Loss_Seg: 12.22142\n",
      "accuracy = 0.944309\n",
      "mean IU  = 0.727696\n",
      "    class # 0 capture rate = 0.945969 \n",
      "    class # 1 capture rate = 0.920091 \n",
      "TRAIN: Batch: 0.1094519584082558 Loss_Total: 11.573032\n",
      "TRAIN: Batch: 0.1094519584082558 Loss_Seg: 9.541053\n",
      "accuracy = 0.959784\n",
      "mean IU  = 0.767621\n",
      "    class # 0 capture rate = 0.961167 \n",
      "    class # 1 capture rate = 0.937604 \n",
      "TRAIN: Batch: 0.11336095692283638 Loss_Total: 10.136732\n",
      "TRAIN: Batch: 0.11336095692283638 Loss_Seg: 9.586246\n",
      "accuracy = 0.952089\n",
      "mean IU  = 0.748685\n",
      "    class # 0 capture rate = 0.951376 \n",
      "    class # 1 capture rate = 0.963188 \n",
      "TRAIN: Batch: 0.11726995543741693 Loss_Total: 15.15656\n",
      "TRAIN: Batch: 0.11726995543741693 Loss_Seg: 15.312029\n",
      "accuracy = 0.937048\n",
      "mean IU  = 0.719186\n",
      "    class # 0 capture rate = 0.939928 \n",
      "    class # 1 capture rate = 0.899693 \n",
      "TRAIN: Batch: 0.1211789539519975 Loss_Total: 13.146229\n",
      "TRAIN: Batch: 0.1211789539519975 Loss_Seg: 17.1354\n",
      "accuracy = 0.913187\n",
      "mean IU  = 0.664952\n",
      "    class # 0 capture rate = 0.914186 \n",
      "    class # 1 capture rate = 0.900035 \n",
      "TRAIN: Batch: 0.12508795246657806 Loss_Total: 13.631344\n",
      "TRAIN: Batch: 0.12508795246657806 Loss_Seg: 14.653749\n",
      "accuracy = 0.915287\n",
      "mean IU  = 0.627363\n",
      "    class # 0 capture rate = 0.914585 \n",
      "    class # 1 capture rate = 0.929303 \n",
      "TRAIN: Batch: 0.12899695098115863 Loss_Total: 11.13505\n",
      "TRAIN: Batch: 0.12899695098115863 Loss_Seg: 9.0336\n",
      "accuracy = 0.953952\n",
      "mean IU  = 0.726911\n",
      "    class # 0 capture rate = 0.953809 \n",
      "    class # 1 capture rate = 0.956740 \n",
      "TRAIN: Batch: 0.1329059494957392 Loss_Total: 12.097126\n",
      "TRAIN: Batch: 0.1329059494957392 Loss_Seg: 11.800388\n",
      "accuracy = 0.942992\n",
      "mean IU  = 0.727929\n",
      "    class # 0 capture rate = 0.942922 \n",
      "    class # 1 capture rate = 0.944003 \n",
      "TRAIN: Batch: 0.13681494801031976 Loss_Total: 13.656237\n",
      "TRAIN: Batch: 0.13681494801031976 Loss_Seg: 10.619039\n",
      "accuracy = 0.957591\n",
      "mean IU  = 0.730400\n",
      "    class # 0 capture rate = 0.960402 \n",
      "    class # 1 capture rate = 0.901831 \n",
      "TRAIN: Batch: 0.14072394652490033 Loss_Total: 12.522333\n",
      "TRAIN: Batch: 0.14072394652490033 Loss_Seg: 10.612873\n",
      "accuracy = 0.956141\n",
      "mean IU  = 0.778870\n",
      "    class # 0 capture rate = 0.957245 \n",
      "    class # 1 capture rate = 0.941741 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.14463294503948088 Loss_Total: 9.385923\n",
      "TRAIN: Batch: 0.14463294503948088 Loss_Seg: 9.031535\n",
      "accuracy = 0.958245\n",
      "mean IU  = 0.768939\n",
      "    class # 0 capture rate = 0.958348 \n",
      "    class # 1 capture rate = 0.956644 \n",
      "TRAIN: Batch: 0.14854194355406145 Loss_Total: 12.50868\n",
      "TRAIN: Batch: 0.14854194355406145 Loss_Seg: 12.24127\n",
      "accuracy = 0.932393\n",
      "mean IU  = 0.703994\n",
      "    class # 0 capture rate = 0.931505 \n",
      "    class # 1 capture rate = 0.944937 \n",
      "TRAIN: Batch: 0.15245094206864201 Loss_Total: 10.736628\n",
      "TRAIN: Batch: 0.15245094206864201 Loss_Seg: 9.615151\n",
      "accuracy = 0.950508\n",
      "mean IU  = 0.725058\n",
      "    class # 0 capture rate = 0.950741 \n",
      "    class # 1 capture rate = 0.946321 \n",
      "TRAIN: Batch: 0.15635994058322258 Loss_Total: 14.529728\n",
      "TRAIN: Batch: 0.15635994058322258 Loss_Seg: 10.392198\n",
      "accuracy = 0.946448\n",
      "mean IU  = 0.709972\n",
      "    class # 0 capture rate = 0.946842 \n",
      "    class # 1 capture rate = 0.939237 \n",
      "TRAIN: Batch: 0.16026893909780315 Loss_Total: 12.95123\n",
      "TRAIN: Batch: 0.16026893909780315 Loss_Seg: 14.602104\n",
      "accuracy = 0.946839\n",
      "mean IU  = 0.719580\n",
      "    class # 0 capture rate = 0.950254 \n",
      "    class # 1 capture rate = 0.891858 \n",
      "TRAIN: Batch: 0.1641779376123837 Loss_Total: 13.177728\n",
      "TRAIN: Batch: 0.1641779376123837 Loss_Seg: 10.245171\n",
      "accuracy = 0.955614\n",
      "mean IU  = 0.754737\n",
      "    class # 0 capture rate = 0.956583 \n",
      "    class # 1 capture rate = 0.940231 \n",
      "TRAIN: Batch: 0.16808693612696426 Loss_Total: 12.448774\n",
      "TRAIN: Batch: 0.16808693612696426 Loss_Seg: 11.880137\n",
      "accuracy = 0.931369\n",
      "mean IU  = 0.691005\n",
      "    class # 0 capture rate = 0.930333 \n",
      "    class # 1 capture rate = 0.947475 \n",
      "TRAIN: Batch: 0.17199593464154483 Loss_Total: 10.9416485\n",
      "TRAIN: Batch: 0.17199593464154483 Loss_Seg: 8.627723\n",
      "accuracy = 0.960712\n",
      "mean IU  = 0.791537\n",
      "    class # 0 capture rate = 0.960921 \n",
      "    class # 1 capture rate = 0.957872 \n",
      "TRAIN: Batch: 0.1759049331561254 Loss_Total: 10.154672\n",
      "TRAIN: Batch: 0.1759049331561254 Loss_Seg: 10.662375\n",
      "accuracy = 0.956567\n",
      "mean IU  = 0.725896\n",
      "    class # 0 capture rate = 0.958997 \n",
      "    class # 1 capture rate = 0.907637 \n",
      "TRAIN: Batch: 0.17981393167070597 Loss_Total: 11.3417425\n",
      "TRAIN: Batch: 0.17981393167070597 Loss_Seg: 10.244945\n",
      "accuracy = 0.955706\n",
      "mean IU  = 0.722729\n",
      "    class # 0 capture rate = 0.956481 \n",
      "    class # 1 capture rate = 0.939507 \n",
      "TRAIN: Batch: 0.18372293018528654 Loss_Total: 11.434405\n",
      "TRAIN: Batch: 0.18372293018528654 Loss_Seg: 7.582061\n",
      "accuracy = 0.964688\n",
      "mean IU  = 0.791004\n",
      "    class # 0 capture rate = 0.964308 \n",
      "    class # 1 capture rate = 0.970722 \n",
      "TRAIN: Batch: 0.18763192869986708 Loss_Total: 13.936195\n",
      "TRAIN: Batch: 0.18763192869986708 Loss_Seg: 15.797\n",
      "accuracy = 0.932606\n",
      "mean IU  = 0.720549\n",
      "    class # 0 capture rate = 0.933379 \n",
      "    class # 1 capture rate = 0.923345 \n",
      "TRAIN: Batch: 0.19154092721444765 Loss_Total: 10.431386\n",
      "TRAIN: Batch: 0.19154092721444765 Loss_Seg: 9.251555\n",
      "accuracy = 0.957149\n",
      "mean IU  = 0.772049\n",
      "    class # 0 capture rate = 0.957025 \n",
      "    class # 1 capture rate = 0.958951 \n",
      "TRAIN: Batch: 0.19544992572902822 Loss_Total: 13.342575\n",
      "TRAIN: Batch: 0.19544992572902822 Loss_Seg: 14.370415\n",
      "accuracy = 0.929262\n",
      "mean IU  = 0.688007\n",
      "    class # 0 capture rate = 0.930298 \n",
      "    class # 1 capture rate = 0.914012 \n",
      "TRAIN: Batch: 0.1993589242436088 Loss_Total: 12.331545\n",
      "TRAIN: Batch: 0.1993589242436088 Loss_Seg: 10.640962\n",
      "accuracy = 0.946924\n",
      "mean IU  = 0.713818\n",
      "    class # 0 capture rate = 0.948291 \n",
      "    class # 1 capture rate = 0.922902 \n",
      "TRAIN: Batch: 0.20326792275818936 Loss_Total: 17.080633\n",
      "TRAIN: Batch: 0.20326792275818936 Loss_Seg: 15.161338\n",
      "accuracy = 0.920778\n",
      "mean IU  = 0.706981\n",
      "    class # 0 capture rate = 0.918419 \n",
      "    class # 1 capture rate = 0.946601 \n",
      "TRAIN: Batch: 0.2071769212727699 Loss_Total: 9.387613\n",
      "TRAIN: Batch: 0.2071769212727699 Loss_Seg: 8.256981\n",
      "accuracy = 0.955196\n",
      "mean IU  = 0.748606\n",
      "    class # 0 capture rate = 0.954803 \n",
      "    class # 1 capture rate = 0.961859 \n",
      "TRAIN: Batch: 0.21108591978735047 Loss_Total: 9.682087\n",
      "TRAIN: Batch: 0.21108591978735047 Loss_Seg: 9.5993805\n",
      "accuracy = 0.950291\n",
      "mean IU  = 0.724753\n",
      "    class # 0 capture rate = 0.949941 \n",
      "    class # 1 capture rate = 0.956623 \n",
      "TRAIN: Batch: 0.21499491830193104 Loss_Total: 12.740597\n",
      "TRAIN: Batch: 0.21499491830193104 Loss_Seg: 10.030464\n",
      "accuracy = 0.949059\n",
      "mean IU  = 0.733703\n",
      "    class # 0 capture rate = 0.948297 \n",
      "    class # 1 capture rate = 0.961490 \n",
      "TRAIN: Batch: 0.2189039168165116 Loss_Total: 10.695341\n",
      "TRAIN: Batch: 0.2189039168165116 Loss_Seg: 7.5235267\n",
      "accuracy = 0.964746\n",
      "mean IU  = 0.768202\n",
      "    class # 0 capture rate = 0.964797 \n",
      "    class # 1 capture rate = 0.963754 \n",
      "TRAIN: Batch: 0.22281291533109218 Loss_Total: 12.124649\n",
      "TRAIN: Batch: 0.22281291533109218 Loss_Seg: 10.748302\n",
      "accuracy = 0.954781\n",
      "mean IU  = 0.778679\n",
      "    class # 0 capture rate = 0.954608 \n",
      "    class # 1 capture rate = 0.956989 \n",
      "TRAIN: Batch: 0.22672191384567275 Loss_Total: 8.951075\n",
      "TRAIN: Batch: 0.22672191384567275 Loss_Seg: 8.9731045\n",
      "accuracy = 0.954634\n",
      "mean IU  = 0.744902\n",
      "    class # 0 capture rate = 0.955457 \n",
      "    class # 1 capture rate = 0.940792 \n",
      "TRAIN: Batch: 0.2306309123602533 Loss_Total: 15.574973\n",
      "TRAIN: Batch: 0.2306309123602533 Loss_Seg: 17.471647\n",
      "accuracy = 0.916559\n",
      "mean IU  = 0.684264\n",
      "    class # 0 capture rate = 0.915876 \n",
      "    class # 1 capture rate = 0.924824 \n",
      "TRAIN: Batch: 0.23453991087483386 Loss_Total: 12.188395\n",
      "TRAIN: Batch: 0.23453991087483386 Loss_Seg: 8.419311\n",
      "accuracy = 0.963793\n",
      "mean IU  = 0.778504\n",
      "    class # 0 capture rate = 0.964917 \n",
      "    class # 1 capture rate = 0.944974 \n",
      "TRAIN: Batch: 0.23844890938941443 Loss_Total: 9.396624\n",
      "TRAIN: Batch: 0.23844890938941443 Loss_Seg: 8.9719515\n",
      "accuracy = 0.951488\n",
      "mean IU  = 0.746592\n",
      "    class # 0 capture rate = 0.950989 \n",
      "    class # 1 capture rate = 0.959241 \n",
      "TRAIN: Batch: 0.242357907903995 Loss_Total: 11.762966\n",
      "TRAIN: Batch: 0.242357907903995 Loss_Seg: 12.011165\n",
      "accuracy = 0.953198\n",
      "mean IU  = 0.746249\n",
      "    class # 0 capture rate = 0.954574 \n",
      "    class # 1 capture rate = 0.931445 \n",
      "TRAIN: Batch: 0.24626690641857557 Loss_Total: 10.8067255\n",
      "TRAIN: Batch: 0.24626690641857557 Loss_Seg: 9.513356\n",
      "accuracy = 0.952532\n",
      "mean IU  = 0.770565\n",
      "    class # 0 capture rate = 0.950415 \n",
      "    class # 1 capture rate = 0.980542 \n",
      "TRAIN: Batch: 0.2501759049331561 Loss_Total: 11.464535\n",
      "TRAIN: Batch: 0.2501759049331561 Loss_Seg: 7.2790174\n",
      "accuracy = 0.960148\n",
      "mean IU  = 0.743912\n",
      "    class # 0 capture rate = 0.959774 \n",
      "    class # 1 capture rate = 0.967861 \n",
      "TRAIN: Batch: 0.2540849034477367 Loss_Total: 12.7033615\n",
      "TRAIN: Batch: 0.2540849034477367 Loss_Seg: 15.399538\n",
      "accuracy = 0.930783\n",
      "mean IU  = 0.677428\n",
      "    class # 0 capture rate = 0.931899 \n",
      "    class # 1 capture rate = 0.912220 \n",
      "TRAIN: Batch: 0.25799390196231725 Loss_Total: 13.430002\n",
      "TRAIN: Batch: 0.25799390196231725 Loss_Seg: 11.210196\n",
      "accuracy = 0.952640\n",
      "mean IU  = 0.743831\n",
      "    class # 0 capture rate = 0.953576 \n",
      "    class # 1 capture rate = 0.937656 \n",
      "TRAIN: Batch: 0.2619029004768978 Loss_Total: 10.7289715\n",
      "TRAIN: Batch: 0.2619029004768978 Loss_Seg: 10.623516\n",
      "accuracy = 0.936546\n",
      "mean IU  = 0.692765\n",
      "    class # 0 capture rate = 0.936001 \n",
      "    class # 1 capture rate = 0.945839 \n",
      "TRAIN: Batch: 0.2658118989914784 Loss_Total: 9.563876\n",
      "TRAIN: Batch: 0.2658118989914784 Loss_Seg: 9.365574\n",
      "accuracy = 0.958762\n",
      "mean IU  = 0.762977\n",
      "    class # 0 capture rate = 0.958709 \n",
      "    class # 1 capture rate = 0.959639 \n",
      "TRAIN: Batch: 0.26972089750605893 Loss_Total: 12.762104\n",
      "TRAIN: Batch: 0.26972089750605893 Loss_Seg: 11.889506\n",
      "accuracy = 0.945478\n",
      "mean IU  = 0.748251\n",
      "    class # 0 capture rate = 0.945438 \n",
      "    class # 1 capture rate = 0.945992 \n",
      "TRAIN: Batch: 0.27362989602063953 Loss_Total: 9.431331\n",
      "TRAIN: Batch: 0.27362989602063953 Loss_Seg: 9.432046\n",
      "accuracy = 0.954149\n",
      "mean IU  = 0.742342\n",
      "    class # 0 capture rate = 0.954149 \n",
      "    class # 1 capture rate = 0.954161 \n",
      "TRAIN: Batch: 0.27753889453522007 Loss_Total: 9.160264\n",
      "TRAIN: Batch: 0.27753889453522007 Loss_Seg: 9.9620905\n",
      "accuracy = 0.954882\n",
      "mean IU  = 0.759078\n",
      "    class # 0 capture rate = 0.954983 \n",
      "    class # 1 capture rate = 0.953341 \n",
      "TRAIN: Batch: 0.28144789304980067 Loss_Total: 14.01203\n",
      "TRAIN: Batch: 0.28144789304980067 Loss_Seg: 14.31721\n",
      "accuracy = 0.927827\n",
      "mean IU  = 0.720002\n",
      "    class # 0 capture rate = 0.926361 \n",
      "    class # 1 capture rate = 0.944181 \n",
      "TRAIN: Batch: 0.2853568915643812 Loss_Total: 11.89177\n",
      "TRAIN: Batch: 0.2853568915643812 Loss_Seg: 11.947562\n",
      "accuracy = 0.940520\n",
      "mean IU  = 0.694345\n",
      "    class # 0 capture rate = 0.941377 \n",
      "    class # 1 capture rate = 0.925173 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.28926589007896175 Loss_Total: 19.248941\n",
      "TRAIN: Batch: 0.28926589007896175 Loss_Seg: 17.190273\n",
      "accuracy = 0.914398\n",
      "mean IU  = 0.683161\n",
      "    class # 0 capture rate = 0.914324 \n",
      "    class # 1 capture rate = 0.915254 \n",
      "TRAIN: Batch: 0.29317488859354235 Loss_Total: 12.779602\n",
      "TRAIN: Batch: 0.29317488859354235 Loss_Seg: 11.170352\n",
      "accuracy = 0.945272\n",
      "mean IU  = 0.736123\n",
      "    class # 0 capture rate = 0.945355 \n",
      "    class # 1 capture rate = 0.944092 \n",
      "TRAIN: Batch: 0.2970838871081229 Loss_Total: 14.875124\n",
      "TRAIN: Batch: 0.2970838871081229 Loss_Seg: 16.40065\n",
      "accuracy = 0.929519\n",
      "mean IU  = 0.703039\n",
      "    class # 0 capture rate = 0.933216 \n",
      "    class # 1 capture rate = 0.883322 \n",
      "TRAIN: Batch: 0.3009928856227035 Loss_Total: 10.620148\n",
      "TRAIN: Batch: 0.3009928856227035 Loss_Seg: 11.338858\n",
      "accuracy = 0.946455\n",
      "mean IU  = 0.707981\n",
      "    class # 0 capture rate = 0.948333 \n",
      "    class # 1 capture rate = 0.912558 \n",
      "TRAIN: Batch: 0.30490188413728403 Loss_Total: 11.552452\n",
      "TRAIN: Batch: 0.30490188413728403 Loss_Seg: 11.527665\n",
      "accuracy = 0.945527\n",
      "mean IU  = 0.719300\n",
      "    class # 0 capture rate = 0.945562 \n",
      "    class # 1 capture rate = 0.944946 \n",
      "TRAIN: Batch: 0.30881088265186457 Loss_Total: 10.85788\n",
      "TRAIN: Batch: 0.30881088265186457 Loss_Seg: 10.091891\n",
      "accuracy = 0.955068\n",
      "mean IU  = 0.789162\n",
      "    class # 0 capture rate = 0.954626 \n",
      "    class # 1 capture rate = 0.960248 \n",
      "TRAIN: Batch: 0.31271988116644517 Loss_Total: 12.58563\n",
      "TRAIN: Batch: 0.31271988116644517 Loss_Seg: 11.529812\n",
      "accuracy = 0.949208\n",
      "mean IU  = 0.721208\n",
      "    class # 0 capture rate = 0.950568 \n",
      "    class # 1 capture rate = 0.925373 \n",
      "TRAIN: Batch: 0.3166288796810257 Loss_Total: 11.39044\n",
      "TRAIN: Batch: 0.3166288796810257 Loss_Seg: 9.512561\n",
      "accuracy = 0.949621\n",
      "mean IU  = 0.733140\n",
      "    class # 0 capture rate = 0.949342 \n",
      "    class # 1 capture rate = 0.954234 \n",
      "TRAIN: Batch: 0.3205378781956063 Loss_Total: 14.234333\n",
      "TRAIN: Batch: 0.3205378781956063 Loss_Seg: 9.905256\n",
      "accuracy = 0.953704\n",
      "mean IU  = 0.753721\n",
      "    class # 0 capture rate = 0.953517 \n",
      "    class # 1 capture rate = 0.956592 \n",
      "TRAIN: Batch: 0.32444687671018685 Loss_Total: 12.884379\n",
      "TRAIN: Batch: 0.32444687671018685 Loss_Seg: 10.868197\n",
      "accuracy = 0.944634\n",
      "mean IU  = 0.738763\n",
      "    class # 0 capture rate = 0.944117 \n",
      "    class # 1 capture rate = 0.951794 \n",
      "TRAIN: Batch: 0.3283558752247674 Loss_Total: 12.17408\n",
      "TRAIN: Batch: 0.3283558752247674 Loss_Seg: 7.3178234\n",
      "accuracy = 0.961711\n",
      "mean IU  = 0.755271\n",
      "    class # 0 capture rate = 0.962044 \n",
      "    class # 1 capture rate = 0.955268 \n",
      "TRAIN: Batch: 0.332264873739348 Loss_Total: 12.890879\n",
      "TRAIN: Batch: 0.332264873739348 Loss_Seg: 17.68062\n",
      "accuracy = 0.914261\n",
      "mean IU  = 0.692776\n",
      "    class # 0 capture rate = 0.912597 \n",
      "    class # 1 capture rate = 0.932311 \n",
      "TRAIN: Batch: 0.33617387225392853 Loss_Total: 12.324219\n",
      "TRAIN: Batch: 0.33617387225392853 Loss_Seg: 9.360169\n",
      "accuracy = 0.949506\n",
      "mean IU  = 0.729641\n",
      "    class # 0 capture rate = 0.949170 \n",
      "    class # 1 capture rate = 0.955204 \n",
      "TRAIN: Batch: 0.3400828707685091 Loss_Total: 15.106307\n",
      "TRAIN: Batch: 0.3400828707685091 Loss_Seg: 13.5792885\n",
      "accuracy = 0.946017\n",
      "mean IU  = 0.738053\n",
      "    class # 0 capture rate = 0.947046 \n",
      "    class # 1 capture rate = 0.931517 \n",
      "TRAIN: Batch: 0.34399186928308967 Loss_Total: 13.521893\n",
      "TRAIN: Batch: 0.34399186928308967 Loss_Seg: 16.305779\n",
      "accuracy = 0.940744\n",
      "mean IU  = 0.702511\n",
      "    class # 0 capture rate = 0.945405 \n",
      "    class # 1 capture rate = 0.867671 \n",
      "TRAIN: Batch: 0.3479008677976702 Loss_Total: 11.150132\n",
      "TRAIN: Batch: 0.3479008677976702 Loss_Seg: 10.459957\n",
      "accuracy = 0.949424\n",
      "mean IU  = 0.720528\n",
      "    class # 0 capture rate = 0.951487 \n",
      "    class # 1 capture rate = 0.913357 \n",
      "TRAIN: Batch: 0.3518098663122508 Loss_Total: 9.985936\n",
      "TRAIN: Batch: 0.3518098663122508 Loss_Seg: 6.9666715\n",
      "accuracy = 0.962789\n",
      "mean IU  = 0.792756\n",
      "    class # 0 capture rate = 0.961879 \n",
      "    class # 1 capture rate = 0.976190 \n",
      "TRAIN: Batch: 0.35571886482683135 Loss_Total: 8.317243\n",
      "TRAIN: Batch: 0.35571886482683135 Loss_Seg: 7.3509502\n",
      "accuracy = 0.958221\n",
      "mean IU  = 0.749521\n",
      "    class # 0 capture rate = 0.957515 \n",
      "    class # 1 capture rate = 0.971333 \n",
      "TRAIN: Batch: 0.35962786334141195 Loss_Total: 10.922131\n",
      "TRAIN: Batch: 0.35962786334141195 Loss_Seg: 10.43092\n",
      "accuracy = 0.948186\n",
      "mean IU  = 0.724468\n",
      "    class # 0 capture rate = 0.947998 \n",
      "    class # 1 capture rate = 0.951392 \n",
      "TRAIN: Batch: 0.3635368618559925 Loss_Total: 11.528812\n",
      "TRAIN: Batch: 0.3635368618559925 Loss_Seg: 10.329867\n",
      "accuracy = 0.952454\n",
      "mean IU  = 0.766995\n",
      "    class # 0 capture rate = 0.952580 \n",
      "    class # 1 capture rate = 0.950797 \n",
      "TRAIN: Batch: 0.3674458603705731 Loss_Total: 9.155677\n",
      "TRAIN: Batch: 0.3674458603705731 Loss_Seg: 8.44184\n",
      "accuracy = 0.954270\n",
      "mean IU  = 0.721870\n",
      "    class # 0 capture rate = 0.953885 \n",
      "    class # 1 capture rate = 0.962274 \n",
      "TRAIN: Batch: 0.3713548588851536 Loss_Total: 10.869348\n",
      "TRAIN: Batch: 0.3713548588851536 Loss_Seg: 9.171729\n",
      "accuracy = 0.951479\n",
      "mean IU  = 0.745187\n",
      "    class # 0 capture rate = 0.951161 \n",
      "    class # 1 capture rate = 0.956451 \n",
      "TRAIN: Batch: 0.37526385739973417 Loss_Total: 12.7056675\n",
      "TRAIN: Batch: 0.37526385739973417 Loss_Seg: 12.373242\n",
      "accuracy = 0.945178\n",
      "mean IU  = 0.720834\n",
      "    class # 0 capture rate = 0.947068 \n",
      "    class # 1 capture rate = 0.915476 \n",
      "TRAIN: Batch: 0.37917285591431477 Loss_Total: 13.315901\n",
      "TRAIN: Batch: 0.37917285591431477 Loss_Seg: 12.357373\n",
      "accuracy = 0.927917\n",
      "mean IU  = 0.661055\n",
      "    class # 0 capture rate = 0.927142 \n",
      "    class # 1 capture rate = 0.942484 \n",
      "TRAIN: Batch: 0.3830818544288953 Loss_Total: 12.112177\n",
      "TRAIN: Batch: 0.3830818544288953 Loss_Seg: 13.247866\n",
      "accuracy = 0.931556\n",
      "mean IU  = 0.700145\n",
      "    class # 0 capture rate = 0.931142 \n",
      "    class # 1 capture rate = 0.937453 \n",
      "TRAIN: Batch: 0.3869908529434759 Loss_Total: 14.230566\n",
      "TRAIN: Batch: 0.3869908529434759 Loss_Seg: 17.555252\n",
      "accuracy = 0.920265\n",
      "mean IU  = 0.702790\n",
      "    class # 0 capture rate = 0.920707 \n",
      "    class # 1 capture rate = 0.915460 \n",
      "TRAIN: Batch: 0.39089985145805645 Loss_Total: 10.12088\n",
      "TRAIN: Batch: 0.39089985145805645 Loss_Seg: 8.329786\n",
      "accuracy = 0.952484\n",
      "mean IU  = 0.742591\n",
      "    class # 0 capture rate = 0.951747 \n",
      "    class # 1 capture rate = 0.964731 \n",
      "TRAIN: Batch: 0.394808849972637 Loss_Total: 13.772188\n",
      "TRAIN: Batch: 0.394808849972637 Loss_Seg: 14.303157\n",
      "accuracy = 0.935879\n",
      "mean IU  = 0.680514\n",
      "    class # 0 capture rate = 0.936703 \n",
      "    class # 1 capture rate = 0.920917 \n",
      "TRAIN: Batch: 0.3987178484872176 Loss_Total: 8.071515\n",
      "TRAIN: Batch: 0.3987178484872176 Loss_Seg: 8.502833\n",
      "accuracy = 0.959393\n",
      "mean IU  = 0.766073\n",
      "    class # 0 capture rate = 0.959461 \n",
      "    class # 1 capture rate = 0.958280 \n",
      "TRAIN: Batch: 0.4026268470017981 Loss_Total: 12.234745\n",
      "TRAIN: Batch: 0.4026268470017981 Loss_Seg: 9.635089\n",
      "accuracy = 0.948015\n",
      "mean IU  = 0.708404\n",
      "    class # 0 capture rate = 0.947332 \n",
      "    class # 1 capture rate = 0.961499 \n",
      "TRAIN: Batch: 0.4065358455163787 Loss_Total: 11.838598\n",
      "TRAIN: Batch: 0.4065358455163787 Loss_Seg: 10.55688\n",
      "accuracy = 0.947262\n",
      "mean IU  = 0.711172\n",
      "    class # 0 capture rate = 0.947042 \n",
      "    class # 1 capture rate = 0.951372 \n",
      "TRAIN: Batch: 0.41044484403095927 Loss_Total: 16.179554\n",
      "TRAIN: Batch: 0.41044484403095927 Loss_Seg: 13.925107\n",
      "accuracy = 0.933048\n",
      "mean IU  = 0.725961\n",
      "    class # 0 capture rate = 0.932411 \n",
      "    class # 1 capture rate = 0.940535 \n",
      "TRAIN: Batch: 0.4143538425455398 Loss_Total: 13.54026\n",
      "TRAIN: Batch: 0.4143538425455398 Loss_Seg: 10.729903\n",
      "accuracy = 0.951873\n",
      "mean IU  = 0.707378\n",
      "    class # 0 capture rate = 0.953197 \n",
      "    class # 1 capture rate = 0.923948 \n",
      "TRAIN: Batch: 0.4182628410601204 Loss_Total: 11.284304\n",
      "TRAIN: Batch: 0.4182628410601204 Loss_Seg: 11.599276\n",
      "accuracy = 0.938353\n",
      "mean IU  = 0.718939\n",
      "    class # 0 capture rate = 0.937170 \n",
      "    class # 1 capture rate = 0.955241 \n",
      "TRAIN: Batch: 0.42217183957470095 Loss_Total: 11.656901\n",
      "TRAIN: Batch: 0.42217183957470095 Loss_Seg: 9.461278\n",
      "accuracy = 0.955805\n",
      "mean IU  = 0.735215\n",
      "    class # 0 capture rate = 0.956431 \n",
      "    class # 1 capture rate = 0.943930 \n",
      "TRAIN: Batch: 0.42608083808928154 Loss_Total: 15.068875\n",
      "TRAIN: Batch: 0.42608083808928154 Loss_Seg: 9.041491\n",
      "accuracy = 0.937155\n",
      "mean IU  = 0.645535\n",
      "    class # 0 capture rate = 0.935862 \n",
      "    class # 1 capture rate = 0.972014 \n",
      "TRAIN: Batch: 0.4299898366038621 Loss_Total: 13.955915\n",
      "TRAIN: Batch: 0.4299898366038621 Loss_Seg: 12.943782\n",
      "accuracy = 0.941278\n",
      "mean IU  = 0.717107\n",
      "    class # 0 capture rate = 0.942775 \n",
      "    class # 1 capture rate = 0.919024 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.4338988351184426 Loss_Total: 17.050606\n",
      "TRAIN: Batch: 0.4338988351184426 Loss_Seg: 19.220177\n",
      "accuracy = 0.925308\n",
      "mean IU  = 0.688766\n",
      "    class # 0 capture rate = 0.930231 \n",
      "    class # 1 capture rate = 0.862739 \n",
      "TRAIN: Batch: 0.4378078336330232 Loss_Total: 11.802921\n",
      "TRAIN: Batch: 0.4378078336330232 Loss_Seg: 8.581156\n",
      "accuracy = 0.965276\n",
      "mean IU  = 0.787477\n",
      "    class # 0 capture rate = 0.966838 \n",
      "    class # 1 capture rate = 0.939992 \n",
      "TRAIN: Batch: 0.44171683214760377 Loss_Total: 10.884459\n",
      "TRAIN: Batch: 0.44171683214760377 Loss_Seg: 8.479679\n",
      "accuracy = 0.967989\n",
      "mean IU  = 0.809464\n",
      "    class # 0 capture rate = 0.968353 \n",
      "    class # 1 capture rate = 0.962544 \n",
      "TRAIN: Batch: 0.44562583066218436 Loss_Total: 10.440328\n",
      "TRAIN: Batch: 0.44562583066218436 Loss_Seg: 9.660358\n",
      "accuracy = 0.951996\n",
      "mean IU  = 0.746257\n",
      "    class # 0 capture rate = 0.951650 \n",
      "    class # 1 capture rate = 0.957447 \n",
      "TRAIN: Batch: 0.4495348291767649 Loss_Total: 9.632459\n",
      "TRAIN: Batch: 0.4495348291767649 Loss_Seg: 9.837998\n",
      "accuracy = 0.959104\n",
      "mean IU  = 0.752983\n",
      "    class # 0 capture rate = 0.960441 \n",
      "    class # 1 capture rate = 0.935321 \n",
      "TRAIN: Batch: 0.4534438276913455 Loss_Total: 11.72624\n",
      "TRAIN: Batch: 0.4534438276913455 Loss_Seg: 13.733608\n",
      "accuracy = 0.949407\n",
      "mean IU  = 0.743591\n",
      "    class # 0 capture rate = 0.951983 \n",
      "    class # 1 capture rate = 0.912556 \n",
      "TRAIN: Batch: 0.45735282620592604 Loss_Total: 10.979702\n",
      "TRAIN: Batch: 0.45735282620592604 Loss_Seg: 9.123995\n",
      "accuracy = 0.950776\n",
      "mean IU  = 0.722384\n",
      "    class # 0 capture rate = 0.950240 \n",
      "    class # 1 capture rate = 0.960851 \n",
      "TRAIN: Batch: 0.4612618247205066 Loss_Total: 15.3213005\n",
      "TRAIN: Batch: 0.4612618247205066 Loss_Seg: 14.3245325\n",
      "accuracy = 0.932755\n",
      "mean IU  = 0.720901\n",
      "    class # 0 capture rate = 0.933912 \n",
      "    class # 1 capture rate = 0.918979 \n",
      "TRAIN: Batch: 0.4651708232350872 Loss_Total: 9.716412\n",
      "TRAIN: Batch: 0.4651708232350872 Loss_Seg: 10.058927\n",
      "accuracy = 0.944800\n",
      "mean IU  = 0.680121\n",
      "    class # 0 capture rate = 0.944709 \n",
      "    class # 1 capture rate = 0.946877 \n",
      "TRAIN: Batch: 0.4690798217496677 Loss_Total: 10.768568\n",
      "TRAIN: Batch: 0.4690798217496677 Loss_Seg: 9.980665\n",
      "accuracy = 0.955980\n",
      "mean IU  = 0.746234\n",
      "    class # 0 capture rate = 0.957388 \n",
      "    class # 1 capture rate = 0.931889 \n",
      "TRAIN: Batch: 0.4729888202642483 Loss_Total: 13.718001\n",
      "TRAIN: Batch: 0.4729888202642483 Loss_Seg: 11.6684675\n",
      "accuracy = 0.941174\n",
      "mean IU  = 0.752296\n",
      "    class # 0 capture rate = 0.940066 \n",
      "    class # 1 capture rate = 0.953698 \n",
      "TRAIN: Batch: 0.47689781877882886 Loss_Total: 13.65189\n",
      "TRAIN: Batch: 0.47689781877882886 Loss_Seg: 16.976452\n",
      "accuracy = 0.938486\n",
      "mean IU  = 0.734686\n",
      "    class # 0 capture rate = 0.943210 \n",
      "    class # 1 capture rate = 0.884323 \n",
      "TRAIN: Batch: 0.4808068172934094 Loss_Total: 10.543381\n",
      "TRAIN: Batch: 0.4808068172934094 Loss_Seg: 9.860119\n",
      "accuracy = 0.947696\n",
      "mean IU  = 0.726039\n",
      "    class # 0 capture rate = 0.948488 \n",
      "    class # 1 capture rate = 0.934746 \n",
      "TRAIN: Batch: 0.48471581580799 Loss_Total: 11.80266\n",
      "TRAIN: Batch: 0.48471581580799 Loss_Seg: 12.64872\n",
      "accuracy = 0.945254\n",
      "mean IU  = 0.708246\n",
      "    class # 0 capture rate = 0.946790 \n",
      "    class # 1 capture rate = 0.918219 \n",
      "TRAIN: Batch: 0.48862481432257054 Loss_Total: 11.09352\n",
      "TRAIN: Batch: 0.48862481432257054 Loss_Seg: 12.210758\n",
      "accuracy = 0.948340\n",
      "mean IU  = 0.725190\n",
      "    class # 0 capture rate = 0.949652 \n",
      "    class # 1 capture rate = 0.926578 \n",
      "TRAIN: Batch: 0.49253381283715114 Loss_Total: 12.688127\n",
      "TRAIN: Batch: 0.49253381283715114 Loss_Seg: 16.439129\n",
      "accuracy = 0.928594\n",
      "mean IU  = 0.728235\n",
      "    class # 0 capture rate = 0.928149 \n",
      "    class # 1 capture rate = 0.933222 \n",
      "TRAIN: Batch: 0.4964428113517317 Loss_Total: 10.648434\n",
      "TRAIN: Batch: 0.4964428113517317 Loss_Seg: 7.8067436\n",
      "accuracy = 0.961294\n",
      "mean IU  = 0.726452\n",
      "    class # 0 capture rate = 0.962270 \n",
      "    class # 1 capture rate = 0.937956 \n",
      "TRAIN: Batch: 0.5003518098663122 Loss_Total: 10.356347\n",
      "TRAIN: Batch: 0.5003518098663122 Loss_Seg: 9.501742\n",
      "accuracy = 0.959203\n",
      "mean IU  = 0.773547\n",
      "    class # 0 capture rate = 0.960616 \n",
      "    class # 1 capture rate = 0.938084 \n",
      "TRAIN: Batch: 0.5042608083808928 Loss_Total: 8.302615\n",
      "TRAIN: Batch: 0.5042608083808928 Loss_Seg: 8.9305105\n",
      "accuracy = 0.957438\n",
      "mean IU  = 0.746504\n",
      "    class # 0 capture rate = 0.957582 \n",
      "    class # 1 capture rate = 0.954802 \n",
      "TRAIN: Batch: 0.5081698068954734 Loss_Total: 11.41613\n",
      "TRAIN: Batch: 0.5081698068954734 Loss_Seg: 11.727249\n",
      "accuracy = 0.938594\n",
      "mean IU  = 0.701186\n",
      "    class # 0 capture rate = 0.938927 \n",
      "    class # 1 capture rate = 0.933164 \n",
      "TRAIN: Batch: 0.5120788054100539 Loss_Total: 9.03554\n",
      "TRAIN: Batch: 0.5120788054100539 Loss_Seg: 8.079747\n",
      "accuracy = 0.961371\n",
      "mean IU  = 0.788518\n",
      "    class # 0 capture rate = 0.960545 \n",
      "    class # 1 capture rate = 0.973404 \n",
      "TRAIN: Batch: 0.5159878039246345 Loss_Total: 11.724102\n",
      "TRAIN: Batch: 0.5159878039246345 Loss_Seg: 11.188896\n",
      "accuracy = 0.945599\n",
      "mean IU  = 0.723102\n",
      "    class # 0 capture rate = 0.945228 \n",
      "    class # 1 capture rate = 0.951620 \n",
      "TRAIN: Batch: 0.5198968024392151 Loss_Total: 10.038832\n",
      "TRAIN: Batch: 0.5198968024392151 Loss_Seg: 8.672041\n",
      "accuracy = 0.951830\n",
      "mean IU  = 0.721198\n",
      "    class # 0 capture rate = 0.951731 \n",
      "    class # 1 capture rate = 0.953754 \n",
      "TRAIN: Batch: 0.5238058009537956 Loss_Total: 12.72397\n",
      "TRAIN: Batch: 0.5238058009537956 Loss_Seg: 9.445161\n",
      "accuracy = 0.955327\n",
      "mean IU  = 0.741390\n",
      "    class # 0 capture rate = 0.955589 \n",
      "    class # 1 capture rate = 0.950646 \n",
      "TRAIN: Batch: 0.5277147994683762 Loss_Total: 14.051315\n",
      "TRAIN: Batch: 0.5277147994683762 Loss_Seg: 12.381406\n",
      "accuracy = 0.944674\n",
      "mean IU  = 0.736200\n",
      "    class # 0 capture rate = 0.945576 \n",
      "    class # 1 capture rate = 0.932173 \n",
      "TRAIN: Batch: 0.5316237979829568 Loss_Total: 9.338876\n",
      "TRAIN: Batch: 0.5316237979829568 Loss_Seg: 7.9918747\n",
      "accuracy = 0.961419\n",
      "mean IU  = 0.754046\n",
      "    class # 0 capture rate = 0.962530 \n",
      "    class # 1 capture rate = 0.940255 \n",
      "TRAIN: Batch: 0.5355327964975374 Loss_Total: 12.477353\n",
      "TRAIN: Batch: 0.5355327964975374 Loss_Seg: 11.614218\n",
      "accuracy = 0.934808\n",
      "mean IU  = 0.717359\n",
      "    class # 0 capture rate = 0.932538 \n",
      "    class # 1 capture rate = 0.965554 \n",
      "TRAIN: Batch: 0.5394417950121179 Loss_Total: 11.33657\n",
      "TRAIN: Batch: 0.5394417950121179 Loss_Seg: 8.880181\n",
      "accuracy = 0.954341\n",
      "mean IU  = 0.750255\n",
      "    class # 0 capture rate = 0.954197 \n",
      "    class # 1 capture rate = 0.956686 \n",
      "TRAIN: Batch: 0.5433507935266985 Loss_Total: 12.63426\n",
      "TRAIN: Batch: 0.5433507935266985 Loss_Seg: 12.751577\n",
      "accuracy = 0.932117\n",
      "mean IU  = 0.691051\n",
      "    class # 0 capture rate = 0.932084 \n",
      "    class # 1 capture rate = 0.932634 \n",
      "TRAIN: Batch: 0.5472597920412791 Loss_Total: 11.565289\n",
      "TRAIN: Batch: 0.5472597920412791 Loss_Seg: 10.917161\n",
      "accuracy = 0.950878\n",
      "mean IU  = 0.755227\n",
      "    class # 0 capture rate = 0.950484 \n",
      "    class # 1 capture rate = 0.956441 \n",
      "TRAIN: Batch: 0.5511687905558595 Loss_Total: 11.624342\n",
      "TRAIN: Batch: 0.5511687905558595 Loss_Seg: 9.003612\n",
      "accuracy = 0.956492\n",
      "mean IU  = 0.744163\n",
      "    class # 0 capture rate = 0.956913 \n",
      "    class # 1 capture rate = 0.948908 \n",
      "TRAIN: Batch: 0.5550777890704401 Loss_Total: 11.806256\n",
      "TRAIN: Batch: 0.5550777890704401 Loss_Seg: 11.387447\n",
      "accuracy = 0.946159\n",
      "mean IU  = 0.726105\n",
      "    class # 0 capture rate = 0.945909 \n",
      "    class # 1 capture rate = 0.950166 \n",
      "TRAIN: Batch: 0.5589867875850207 Loss_Total: 13.121741\n",
      "TRAIN: Batch: 0.5589867875850207 Loss_Seg: 10.08239\n",
      "accuracy = 0.941248\n",
      "mean IU  = 0.715472\n",
      "    class # 0 capture rate = 0.939656 \n",
      "    class # 1 capture rate = 0.966570 \n",
      "TRAIN: Batch: 0.5628957860996013 Loss_Total: 13.59901\n",
      "TRAIN: Batch: 0.5628957860996013 Loss_Seg: 10.035345\n",
      "accuracy = 0.947140\n",
      "mean IU  = 0.726407\n",
      "    class # 0 capture rate = 0.946278 \n",
      "    class # 1 capture rate = 0.961407 \n",
      "TRAIN: Batch: 0.5668047846141818 Loss_Total: 12.326881\n",
      "TRAIN: Batch: 0.5668047846141818 Loss_Seg: 12.659276\n",
      "accuracy = 0.929714\n",
      "mean IU  = 0.687417\n",
      "    class # 0 capture rate = 0.929071 \n",
      "    class # 1 capture rate = 0.939600 \n",
      "TRAIN: Batch: 0.5707137831287624 Loss_Total: 11.08593\n",
      "TRAIN: Batch: 0.5707137831287624 Loss_Seg: 11.060203\n",
      "accuracy = 0.948360\n",
      "mean IU  = 0.735084\n",
      "    class # 0 capture rate = 0.948527 \n",
      "    class # 1 capture rate = 0.945771 \n",
      "TRAIN: Batch: 0.574622781643343 Loss_Total: 11.093637\n",
      "TRAIN: Batch: 0.574622781643343 Loss_Seg: 11.2990675\n",
      "accuracy = 0.957494\n",
      "mean IU  = 0.747524\n",
      "    class # 0 capture rate = 0.960223 \n",
      "    class # 1 capture rate = 0.910388 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.5785317801579235 Loss_Total: 10.453811\n",
      "TRAIN: Batch: 0.5785317801579235 Loss_Seg: 8.932524\n",
      "accuracy = 0.954952\n",
      "mean IU  = 0.752190\n",
      "    class # 0 capture rate = 0.954945 \n",
      "    class # 1 capture rate = 0.955061 \n",
      "TRAIN: Batch: 0.5824407786725041 Loss_Total: 13.647093\n",
      "TRAIN: Batch: 0.5824407786725041 Loss_Seg: 13.200556\n",
      "accuracy = 0.922867\n",
      "mean IU  = 0.682157\n",
      "    class # 0 capture rate = 0.920407 \n",
      "    class # 1 capture rate = 0.958271 \n",
      "TRAIN: Batch: 0.5863497771870847 Loss_Total: 10.579459\n",
      "TRAIN: Batch: 0.5863497771870847 Loss_Seg: 9.381157\n",
      "accuracy = 0.953114\n",
      "mean IU  = 0.722335\n",
      "    class # 0 capture rate = 0.952646 \n",
      "    class # 1 capture rate = 0.962487 \n",
      "TRAIN: Batch: 0.5902587757016652 Loss_Total: 12.772366\n",
      "TRAIN: Batch: 0.5902587757016652 Loss_Seg: 11.319069\n",
      "accuracy = 0.938359\n",
      "mean IU  = 0.709885\n",
      "    class # 0 capture rate = 0.937645 \n",
      "    class # 1 capture rate = 0.949322 \n",
      "TRAIN: Batch: 0.5941677742162458 Loss_Total: 10.276741\n",
      "TRAIN: Batch: 0.5941677742162458 Loss_Seg: 9.789205\n",
      "accuracy = 0.956561\n",
      "mean IU  = 0.757483\n",
      "    class # 0 capture rate = 0.956853 \n",
      "    class # 1 capture rate = 0.951843 \n",
      "TRAIN: Batch: 0.5980767727308264 Loss_Total: 11.70713\n",
      "TRAIN: Batch: 0.5980767727308264 Loss_Seg: 8.515713\n",
      "accuracy = 0.959492\n",
      "mean IU  = 0.753408\n",
      "    class # 0 capture rate = 0.959482 \n",
      "    class # 1 capture rate = 0.959677 \n",
      "TRAIN: Batch: 0.601985771245407 Loss_Total: 15.808058\n",
      "TRAIN: Batch: 0.601985771245407 Loss_Seg: 15.331435\n",
      "accuracy = 0.916174\n",
      "mean IU  = 0.675915\n",
      "    class # 0 capture rate = 0.914816 \n",
      "    class # 1 capture rate = 0.933953 \n",
      "TRAIN: Batch: 0.6058947697599875 Loss_Total: 12.356899\n",
      "TRAIN: Batch: 0.6058947697599875 Loss_Seg: 12.993974\n",
      "accuracy = 0.935957\n",
      "mean IU  = 0.708463\n",
      "    class # 0 capture rate = 0.936224 \n",
      "    class # 1 capture rate = 0.932101 \n",
      "TRAIN: Batch: 0.6098037682745681 Loss_Total: 11.579483\n",
      "TRAIN: Batch: 0.6098037682745681 Loss_Seg: 12.786995\n",
      "accuracy = 0.942696\n",
      "mean IU  = 0.709665\n",
      "    class # 0 capture rate = 0.944147 \n",
      "    class # 1 capture rate = 0.918930 \n",
      "TRAIN: Batch: 0.6137127667891487 Loss_Total: 13.319386\n",
      "TRAIN: Batch: 0.6137127667891487 Loss_Seg: 13.233194\n",
      "accuracy = 0.930683\n",
      "mean IU  = 0.709576\n",
      "    class # 0 capture rate = 0.929484 \n",
      "    class # 1 capture rate = 0.946288 \n",
      "TRAIN: Batch: 0.6176217653037291 Loss_Total: 12.410034\n",
      "TRAIN: Batch: 0.6176217653037291 Loss_Seg: 11.935845\n",
      "accuracy = 0.939875\n",
      "mean IU  = 0.691713\n",
      "    class # 0 capture rate = 0.942128 \n",
      "    class # 1 capture rate = 0.900317 \n",
      "TRAIN: Batch: 0.6215307638183097 Loss_Total: 12.191255\n",
      "TRAIN: Batch: 0.6215307638183097 Loss_Seg: 11.194901\n",
      "accuracy = 0.954290\n",
      "mean IU  = 0.752174\n",
      "    class # 0 capture rate = 0.955857 \n",
      "    class # 1 capture rate = 0.930064 \n",
      "TRAIN: Batch: 0.6254397623328903 Loss_Total: 17.901947\n",
      "TRAIN: Batch: 0.6254397623328903 Loss_Seg: 17.01059\n",
      "accuracy = 0.924601\n",
      "mean IU  = 0.684065\n",
      "    class # 0 capture rate = 0.927131 \n",
      "    class # 1 capture rate = 0.890387 \n",
      "TRAIN: Batch: 0.6293487608474708 Loss_Total: 8.241538\n",
      "TRAIN: Batch: 0.6293487608474708 Loss_Seg: 8.09585\n",
      "accuracy = 0.964599\n",
      "mean IU  = 0.767868\n",
      "    class # 0 capture rate = 0.965507 \n",
      "    class # 1 capture rate = 0.947394 \n",
      "TRAIN: Batch: 0.6332577593620514 Loss_Total: 9.885809\n",
      "TRAIN: Batch: 0.6332577593620514 Loss_Seg: 9.674249\n",
      "accuracy = 0.943135\n",
      "mean IU  = 0.719483\n",
      "    class # 0 capture rate = 0.942108 \n",
      "    class # 1 capture rate = 0.959504 \n",
      "TRAIN: Batch: 0.637166757876632 Loss_Total: 10.404778\n",
      "TRAIN: Batch: 0.637166757876632 Loss_Seg: 8.436407\n",
      "accuracy = 0.963133\n",
      "mean IU  = 0.800678\n",
      "    class # 0 capture rate = 0.963307 \n",
      "    class # 1 capture rate = 0.960770 \n",
      "TRAIN: Batch: 0.6410757563912126 Loss_Total: 9.839036\n",
      "TRAIN: Batch: 0.6410757563912126 Loss_Seg: 7.341468\n",
      "accuracy = 0.967625\n",
      "mean IU  = 0.797469\n",
      "    class # 0 capture rate = 0.967743 \n",
      "    class # 1 capture rate = 0.965665 \n",
      "TRAIN: Batch: 0.6449847549057931 Loss_Total: 9.872589\n",
      "TRAIN: Batch: 0.6449847549057931 Loss_Seg: 7.9086695\n",
      "accuracy = 0.958776\n",
      "mean IU  = 0.750763\n",
      "    class # 0 capture rate = 0.958902 \n",
      "    class # 1 capture rate = 0.956460 \n",
      "TRAIN: Batch: 0.6488937534203737 Loss_Total: 10.320824\n",
      "TRAIN: Batch: 0.6488937534203737 Loss_Seg: 11.309886\n",
      "accuracy = 0.947141\n",
      "mean IU  = 0.734539\n",
      "    class # 0 capture rate = 0.947026 \n",
      "    class # 1 capture rate = 0.948891 \n",
      "TRAIN: Batch: 0.6528027519349543 Loss_Total: 14.22542\n",
      "TRAIN: Batch: 0.6528027519349543 Loss_Seg: 14.154265\n",
      "accuracy = 0.937944\n",
      "mean IU  = 0.728818\n",
      "    class # 0 capture rate = 0.938680 \n",
      "    class # 1 capture rate = 0.928690 \n",
      "TRAIN: Batch: 0.6567117504495348 Loss_Total: 11.597293\n",
      "TRAIN: Batch: 0.6567117504495348 Loss_Seg: 7.6666846\n",
      "accuracy = 0.964740\n",
      "mean IU  = 0.783289\n",
      "    class # 0 capture rate = 0.964979 \n",
      "    class # 1 capture rate = 0.960716 \n",
      "TRAIN: Batch: 0.6606207489641154 Loss_Total: 14.421766\n",
      "TRAIN: Batch: 0.6606207489641154 Loss_Seg: 12.359081\n",
      "accuracy = 0.939457\n",
      "mean IU  = 0.726799\n",
      "    class # 0 capture rate = 0.939310 \n",
      "    class # 1 capture rate = 0.941426 \n",
      "TRAIN: Batch: 0.664529747478696 Loss_Total: 14.957927\n",
      "TRAIN: Batch: 0.664529747478696 Loss_Seg: 9.857159\n",
      "accuracy = 0.950508\n",
      "mean IU  = 0.742821\n",
      "    class # 0 capture rate = 0.949718 \n",
      "    class # 1 capture rate = 0.962903 \n",
      "TRAIN: Batch: 0.6684387459932766 Loss_Total: 13.307678\n",
      "TRAIN: Batch: 0.6684387459932766 Loss_Seg: 11.816944\n",
      "accuracy = 0.939101\n",
      "mean IU  = 0.720881\n",
      "    class # 0 capture rate = 0.938287 \n",
      "    class # 1 capture rate = 0.950649 \n",
      "TRAIN: Batch: 0.6723477445078571 Loss_Total: 16.905197\n",
      "TRAIN: Batch: 0.6723477445078571 Loss_Seg: 24.599577\n",
      "accuracy = 0.889220\n",
      "mean IU  = 0.679277\n",
      "    class # 0 capture rate = 0.884604 \n",
      "    class # 1 capture rate = 0.926064 \n",
      "TRAIN: Batch: 0.6762567430224377 Loss_Total: 13.495919\n",
      "TRAIN: Batch: 0.6762567430224377 Loss_Seg: 11.830756\n",
      "accuracy = 0.943944\n",
      "mean IU  = 0.716103\n",
      "    class # 0 capture rate = 0.944145 \n",
      "    class # 1 capture rate = 0.940653 \n",
      "TRAIN: Batch: 0.6801657415370183 Loss_Total: 10.76428\n",
      "TRAIN: Batch: 0.6801657415370183 Loss_Seg: 10.006358\n",
      "accuracy = 0.955342\n",
      "mean IU  = 0.764148\n",
      "    class # 0 capture rate = 0.955565 \n",
      "    class # 1 capture rate = 0.952071 \n",
      "TRAIN: Batch: 0.6840747400515987 Loss_Total: 12.290443\n",
      "TRAIN: Batch: 0.6840747400515987 Loss_Seg: 11.1018505\n",
      "accuracy = 0.934297\n",
      "mean IU  = 0.676633\n",
      "    class # 0 capture rate = 0.933544 \n",
      "    class # 1 capture rate = 0.948409 \n",
      "TRAIN: Batch: 0.6879837385661793 Loss_Total: 10.697294\n",
      "TRAIN: Batch: 0.6879837385661793 Loss_Seg: 10.802521\n",
      "accuracy = 0.943005\n",
      "mean IU  = 0.706651\n",
      "    class # 0 capture rate = 0.944791 \n",
      "    class # 1 capture rate = 0.912968 \n",
      "TRAIN: Batch: 0.6918927370807599 Loss_Total: 11.13729\n",
      "TRAIN: Batch: 0.6918927370807599 Loss_Seg: 10.901448\n",
      "accuracy = 0.947332\n",
      "mean IU  = 0.726199\n",
      "    class # 0 capture rate = 0.948023 \n",
      "    class # 1 capture rate = 0.936134 \n",
      "TRAIN: Batch: 0.6958017355953404 Loss_Total: 10.766865\n",
      "TRAIN: Batch: 0.6958017355953404 Loss_Seg: 7.488665\n",
      "accuracy = 0.957420\n",
      "mean IU  = 0.721492\n",
      "    class # 0 capture rate = 0.957402 \n",
      "    class # 1 capture rate = 0.957828 \n",
      "TRAIN: Batch: 0.699710734109921 Loss_Total: 10.564427\n",
      "TRAIN: Batch: 0.699710734109921 Loss_Seg: 8.907659\n",
      "accuracy = 0.961469\n",
      "mean IU  = 0.777934\n",
      "    class # 0 capture rate = 0.962704 \n",
      "    class # 1 capture rate = 0.942292 \n",
      "TRAIN: Batch: 0.7036197326245016 Loss_Total: 8.283497\n",
      "TRAIN: Batch: 0.7036197326245016 Loss_Seg: 7.289885\n",
      "accuracy = 0.961422\n",
      "mean IU  = 0.774173\n",
      "    class # 0 capture rate = 0.961125 \n",
      "    class # 1 capture rate = 0.966311 \n",
      "TRAIN: Batch: 0.7075287311390822 Loss_Total: 10.969129\n",
      "TRAIN: Batch: 0.7075287311390822 Loss_Seg: 9.430826\n",
      "accuracy = 0.945017\n",
      "mean IU  = 0.727824\n",
      "    class # 0 capture rate = 0.943677 \n",
      "    class # 1 capture rate = 0.965937 \n",
      "TRAIN: Batch: 0.7114377296536627 Loss_Total: 13.782094\n",
      "TRAIN: Batch: 0.7114377296536627 Loss_Seg: 13.535012\n",
      "accuracy = 0.943768\n",
      "mean IU  = 0.725444\n",
      "    class # 0 capture rate = 0.945758 \n",
      "    class # 1 capture rate = 0.914732 \n",
      "TRAIN: Batch: 0.7153467281682433 Loss_Total: 13.400761\n",
      "TRAIN: Batch: 0.7153467281682433 Loss_Seg: 13.4815035\n",
      "accuracy = 0.940066\n",
      "mean IU  = 0.704015\n",
      "    class # 0 capture rate = 0.943548 \n",
      "    class # 1 capture rate = 0.885830 \n",
      "TRAIN: Batch: 0.7192557266828239 Loss_Total: 14.21209\n",
      "TRAIN: Batch: 0.7192557266828239 Loss_Seg: 14.96698\n",
      "accuracy = 0.934076\n",
      "mean IU  = 0.708855\n",
      "    class # 0 capture rate = 0.937077 \n",
      "    class # 1 capture rate = 0.894371 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.7231647251974044 Loss_Total: 11.171795\n",
      "TRAIN: Batch: 0.7231647251974044 Loss_Seg: 11.25366\n",
      "accuracy = 0.944255\n",
      "mean IU  = 0.710007\n",
      "    class # 0 capture rate = 0.945113 \n",
      "    class # 1 capture rate = 0.929521 \n",
      "TRAIN: Batch: 0.727073723711985 Loss_Total: 9.951239\n",
      "TRAIN: Batch: 0.727073723711985 Loss_Seg: 10.1734085\n",
      "accuracy = 0.943915\n",
      "mean IU  = 0.703729\n",
      "    class # 0 capture rate = 0.943543 \n",
      "    class # 1 capture rate = 0.950758 \n",
      "TRAIN: Batch: 0.7309827222265656 Loss_Total: 11.130217\n",
      "TRAIN: Batch: 0.7309827222265656 Loss_Seg: 10.069621\n",
      "accuracy = 0.947065\n",
      "mean IU  = 0.710045\n",
      "    class # 0 capture rate = 0.947237 \n",
      "    class # 1 capture rate = 0.943858 \n",
      "TRAIN: Batch: 0.7348917207411462 Loss_Total: 11.444239\n",
      "TRAIN: Batch: 0.7348917207411462 Loss_Seg: 9.958191\n",
      "accuracy = 0.942476\n",
      "mean IU  = 0.695031\n",
      "    class # 0 capture rate = 0.941560 \n",
      "    class # 1 capture rate = 0.960219 \n",
      "TRAIN: Batch: 0.7388007192557267 Loss_Total: 10.883622\n",
      "TRAIN: Batch: 0.7388007192557267 Loss_Seg: 7.170366\n",
      "accuracy = 0.965058\n",
      "mean IU  = 0.781257\n",
      "    class # 0 capture rate = 0.964721 \n",
      "    class # 1 capture rate = 0.970975 \n",
      "TRAIN: Batch: 0.7427097177703073 Loss_Total: 15.038674\n",
      "TRAIN: Batch: 0.7427097177703073 Loss_Seg: 18.060928\n",
      "accuracy = 0.918728\n",
      "mean IU  = 0.697754\n",
      "    class # 0 capture rate = 0.921413 \n",
      "    class # 1 capture rate = 0.890000 \n",
      "TRAIN: Batch: 0.7466187162848879 Loss_Total: 12.913187\n",
      "TRAIN: Batch: 0.7466187162848879 Loss_Seg: 15.940219\n",
      "accuracy = 0.923676\n",
      "mean IU  = 0.671197\n",
      "    class # 0 capture rate = 0.924167 \n",
      "    class # 1 capture rate = 0.916134 \n",
      "TRAIN: Batch: 0.7505277147994683 Loss_Total: 10.918607\n",
      "TRAIN: Batch: 0.7505277147994683 Loss_Seg: 10.513171\n",
      "accuracy = 0.949701\n",
      "mean IU  = 0.745814\n",
      "    class # 0 capture rate = 0.950301 \n",
      "    class # 1 capture rate = 0.940930 \n",
      "TRAIN: Batch: 0.7544367133140489 Loss_Total: 12.433162\n",
      "TRAIN: Batch: 0.7544367133140489 Loss_Seg: 12.009109\n",
      "accuracy = 0.931434\n",
      "mean IU  = 0.663378\n",
      "    class # 0 capture rate = 0.930717 \n",
      "    class # 1 capture rate = 0.945630 \n",
      "TRAIN: Batch: 0.7583457118286295 Loss_Total: 7.75002\n",
      "TRAIN: Batch: 0.7583457118286295 Loss_Seg: 7.111999\n",
      "accuracy = 0.961398\n",
      "mean IU  = 0.759630\n",
      "    class # 0 capture rate = 0.961255 \n",
      "    class # 1 capture rate = 0.964046 \n",
      "TRAIN: Batch: 0.76225471034321 Loss_Total: 10.771553\n",
      "TRAIN: Batch: 0.76225471034321 Loss_Seg: 9.378262\n",
      "accuracy = 0.953704\n",
      "mean IU  = 0.748851\n",
      "    class # 0 capture rate = 0.953382 \n",
      "    class # 1 capture rate = 0.958910 \n",
      "TRAIN: Batch: 0.7661637088577906 Loss_Total: 11.826535\n",
      "TRAIN: Batch: 0.7661637088577906 Loss_Seg: 8.721135\n",
      "accuracy = 0.959786\n",
      "mean IU  = 0.756443\n",
      "    class # 0 capture rate = 0.960178 \n",
      "    class # 1 capture rate = 0.952734 \n",
      "TRAIN: Batch: 0.7700727073723712 Loss_Total: 12.628979\n",
      "TRAIN: Batch: 0.7700727073723712 Loss_Seg: 11.973412\n",
      "accuracy = 0.943264\n",
      "mean IU  = 0.766869\n",
      "    class # 0 capture rate = 0.942334 \n",
      "    class # 1 capture rate = 0.952938 \n",
      "TRAIN: Batch: 0.7739817058869518 Loss_Total: 9.990727\n",
      "TRAIN: Batch: 0.7739817058869518 Loss_Seg: 10.325421\n",
      "accuracy = 0.949268\n",
      "mean IU  = 0.753945\n",
      "    class # 0 capture rate = 0.948085 \n",
      "    class # 1 capture rate = 0.965617 \n",
      "TRAIN: Batch: 0.7778907044015323 Loss_Total: 10.2751045\n",
      "TRAIN: Batch: 0.7778907044015323 Loss_Seg: 7.705639\n",
      "accuracy = 0.955144\n",
      "mean IU  = 0.725367\n",
      "    class # 0 capture rate = 0.954399 \n",
      "    class # 1 capture rate = 0.970667 \n",
      "TRAIN: Batch: 0.7817997029161129 Loss_Total: 13.77656\n",
      "TRAIN: Batch: 0.7817997029161129 Loss_Seg: 15.348911\n",
      "accuracy = 0.930387\n",
      "mean IU  = 0.710296\n",
      "    class # 0 capture rate = 0.932886 \n",
      "    class # 1 capture rate = 0.899968 \n",
      "TRAIN: Batch: 0.7857087014306935 Loss_Total: 11.690802\n",
      "TRAIN: Batch: 0.7857087014306935 Loss_Seg: 7.985111\n",
      "accuracy = 0.961419\n",
      "mean IU  = 0.781803\n",
      "    class # 0 capture rate = 0.961470 \n",
      "    class # 1 capture rate = 0.960636 \n",
      "TRAIN: Batch: 0.789617699945274 Loss_Total: 12.309126\n",
      "TRAIN: Batch: 0.789617699945274 Loss_Seg: 11.503724\n",
      "accuracy = 0.949526\n",
      "mean IU  = 0.733839\n",
      "    class # 0 capture rate = 0.950473 \n",
      "    class # 1 capture rate = 0.934358 \n",
      "TRAIN: Batch: 0.7935266984598546 Loss_Total: 12.298559\n",
      "TRAIN: Batch: 0.7935266984598546 Loss_Seg: 14.727185\n",
      "accuracy = 0.937118\n",
      "mean IU  = 0.710840\n",
      "    class # 0 capture rate = 0.940257 \n",
      "    class # 1 capture rate = 0.893571 \n",
      "TRAIN: Batch: 0.7974356969744352 Loss_Total: 11.639756\n",
      "TRAIN: Batch: 0.7974356969744352 Loss_Seg: 11.930369\n",
      "accuracy = 0.952583\n",
      "mean IU  = 0.780483\n",
      "    class # 0 capture rate = 0.952719 \n",
      "    class # 1 capture rate = 0.950993 \n",
      "TRAIN: Batch: 0.8013446954890158 Loss_Total: 9.900508\n",
      "TRAIN: Batch: 0.8013446954890158 Loss_Seg: 7.880633\n",
      "accuracy = 0.963842\n",
      "mean IU  = 0.769292\n",
      "    class # 0 capture rate = 0.965291 \n",
      "    class # 1 capture rate = 0.937703 \n",
      "TRAIN: Batch: 0.8052536940035963 Loss_Total: 11.162982\n",
      "TRAIN: Batch: 0.8052536940035963 Loss_Seg: 8.898149\n",
      "accuracy = 0.952727\n",
      "mean IU  = 0.743906\n",
      "    class # 0 capture rate = 0.952856 \n",
      "    class # 1 capture rate = 0.950633 \n",
      "TRAIN: Batch: 0.8091626925181769 Loss_Total: 9.693373\n",
      "TRAIN: Batch: 0.8091626925181769 Loss_Seg: 11.796038\n",
      "accuracy = 0.945311\n",
      "mean IU  = 0.743417\n",
      "    class # 0 capture rate = 0.945126 \n",
      "    class # 1 capture rate = 0.947795 \n",
      "TRAIN: Batch: 0.8130716910327574 Loss_Total: 14.273113\n",
      "TRAIN: Batch: 0.8130716910327574 Loss_Seg: 14.031331\n",
      "accuracy = 0.938867\n",
      "mean IU  = 0.714914\n",
      "    class # 0 capture rate = 0.941156 \n",
      "    class # 1 capture rate = 0.906504 \n",
      "TRAIN: Batch: 0.8169806895473379 Loss_Total: 12.364125\n",
      "TRAIN: Batch: 0.8169806895473379 Loss_Seg: 11.303088\n",
      "accuracy = 0.939173\n",
      "mean IU  = 0.711183\n",
      "    class # 0 capture rate = 0.938535 \n",
      "    class # 1 capture rate = 0.949016 \n",
      "TRAIN: Batch: 0.8208896880619185 Loss_Total: 10.093011\n",
      "TRAIN: Batch: 0.8208896880619185 Loss_Seg: 11.099692\n",
      "accuracy = 0.935882\n",
      "mean IU  = 0.692715\n",
      "    class # 0 capture rate = 0.934598 \n",
      "    class # 1 capture rate = 0.957746 \n",
      "TRAIN: Batch: 0.8247986865764991 Loss_Total: 12.272799\n",
      "TRAIN: Batch: 0.8247986865764991 Loss_Seg: 12.112244\n",
      "accuracy = 0.938078\n",
      "mean IU  = 0.709916\n",
      "    class # 0 capture rate = 0.938200 \n",
      "    class # 1 capture rate = 0.936253 \n",
      "TRAIN: Batch: 0.8287076850910796 Loss_Total: 12.969015\n",
      "TRAIN: Batch: 0.8287076850910796 Loss_Seg: 8.555723\n",
      "accuracy = 0.957295\n",
      "mean IU  = 0.742800\n",
      "    class # 0 capture rate = 0.957340 \n",
      "    class # 1 capture rate = 0.956438 \n",
      "TRAIN: Batch: 0.8326166836056602 Loss_Total: 8.261715\n",
      "TRAIN: Batch: 0.8326166836056602 Loss_Seg: 6.150524\n",
      "accuracy = 0.963276\n",
      "mean IU  = 0.758532\n",
      "    class # 0 capture rate = 0.962519 \n",
      "    class # 1 capture rate = 0.978657 \n",
      "TRAIN: Batch: 0.8365256821202408 Loss_Total: 11.919076\n",
      "TRAIN: Batch: 0.8365256821202408 Loss_Seg: 9.827188\n",
      "accuracy = 0.948355\n",
      "mean IU  = 0.728531\n",
      "    class # 0 capture rate = 0.947456 \n",
      "    class # 1 capture rate = 0.963478 \n",
      "TRAIN: Batch: 0.8404346806348214 Loss_Total: 9.367083\n",
      "TRAIN: Batch: 0.8404346806348214 Loss_Seg: 9.877104\n",
      "accuracy = 0.950095\n",
      "mean IU  = 0.750016\n",
      "    class # 0 capture rate = 0.949650 \n",
      "    class # 1 capture rate = 0.956538 \n",
      "TRAIN: Batch: 0.8443436791494019 Loss_Total: 13.401995\n",
      "TRAIN: Batch: 0.8443436791494019 Loss_Seg: 15.685456\n",
      "accuracy = 0.932256\n",
      "mean IU  = 0.718464\n",
      "    class # 0 capture rate = 0.932067 \n",
      "    class # 1 capture rate = 0.934564 \n",
      "TRAIN: Batch: 0.8482526776639825 Loss_Total: 10.792816\n",
      "TRAIN: Batch: 0.8482526776639825 Loss_Seg: 8.891651\n",
      "accuracy = 0.949559\n",
      "mean IU  = 0.671871\n",
      "    class # 0 capture rate = 0.949729 \n",
      "    class # 1 capture rate = 0.944871 \n",
      "TRAIN: Batch: 0.8521616761785631 Loss_Total: 11.655422\n",
      "TRAIN: Batch: 0.8521616761785631 Loss_Seg: 13.529017\n",
      "accuracy = 0.943774\n",
      "mean IU  = 0.688860\n",
      "    class # 0 capture rate = 0.946505 \n",
      "    class # 1 capture rate = 0.890664 \n",
      "TRAIN: Batch: 0.8560706746931436 Loss_Total: 11.966818\n",
      "TRAIN: Batch: 0.8560706746931436 Loss_Seg: 11.789461\n",
      "accuracy = 0.943845\n",
      "mean IU  = 0.708983\n",
      "    class # 0 capture rate = 0.946168 \n",
      "    class # 1 capture rate = 0.905132 \n",
      "TRAIN: Batch: 0.8599796732077242 Loss_Total: 12.431667\n",
      "TRAIN: Batch: 0.8599796732077242 Loss_Seg: 11.016471\n",
      "accuracy = 0.944846\n",
      "mean IU  = 0.717157\n",
      "    class # 0 capture rate = 0.945213 \n",
      "    class # 1 capture rate = 0.938784 \n",
      "TRAIN: Batch: 0.8638886717223048 Loss_Total: 9.83494\n",
      "TRAIN: Batch: 0.8638886717223048 Loss_Seg: 8.529319\n",
      "accuracy = 0.965246\n",
      "mean IU  = 0.780405\n",
      "    class # 0 capture rate = 0.966267 \n",
      "    class # 1 capture rate = 0.947510 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Batch: 0.8677976702368853 Loss_Total: 9.772565\n",
      "TRAIN: Batch: 0.8677976702368853 Loss_Seg: 8.59499\n",
      "accuracy = 0.962034\n",
      "mean IU  = 0.763151\n",
      "    class # 0 capture rate = 0.962552 \n",
      "    class # 1 capture rate = 0.952604 \n",
      "TRAIN: Batch: 0.8717066687514659 Loss_Total: 11.225641\n",
      "TRAIN: Batch: 0.8717066687514659 Loss_Seg: 14.305492\n",
      "accuracy = 0.927352\n",
      "mean IU  = 0.723807\n",
      "    class # 0 capture rate = 0.926428 \n",
      "    class # 1 capture rate = 0.937146 \n",
      "TRAIN: Batch: 0.8756156672660464 Loss_Total: 13.937675\n",
      "TRAIN: Batch: 0.8756156672660464 Loss_Seg: 11.594869\n",
      "accuracy = 0.945452\n",
      "mean IU  = 0.737764\n",
      "    class # 0 capture rate = 0.945662 \n",
      "    class # 1 capture rate = 0.942499 \n",
      "TRAIN: Batch: 0.879524665780627 Loss_Total: 16.07704\n",
      "TRAIN: Batch: 0.879524665780627 Loss_Seg: 18.043686\n",
      "accuracy = 0.939412\n",
      "mean IU  = 0.731444\n",
      "    class # 0 capture rate = 0.946339 \n",
      "    class # 1 capture rate = 0.858558 \n",
      "TRAIN: Batch: 0.8834336642952075 Loss_Total: 8.252621\n",
      "TRAIN: Batch: 0.8834336642952075 Loss_Seg: 9.23921\n",
      "accuracy = 0.954903\n",
      "mean IU  = 0.767003\n",
      "    class # 0 capture rate = 0.955215 \n",
      "    class # 1 capture rate = 0.950499 \n",
      "TRAIN: Batch: 0.8873426628097881 Loss_Total: 10.886532\n",
      "TRAIN: Batch: 0.8873426628097881 Loss_Seg: 10.074407\n",
      "accuracy = 0.950778\n",
      "mean IU  = 0.735796\n",
      "    class # 0 capture rate = 0.950834 \n",
      "    class # 1 capture rate = 0.949850 \n",
      "TRAIN: Batch: 0.8912516613243687 Loss_Total: 10.06192\n",
      "TRAIN: Batch: 0.8912516613243687 Loss_Seg: 8.9931965\n",
      "accuracy = 0.958126\n",
      "mean IU  = 0.761524\n",
      "    class # 0 capture rate = 0.958690 \n",
      "    class # 1 capture rate = 0.948945 \n",
      "TRAIN: Batch: 0.8951606598389492 Loss_Total: 12.678375\n",
      "TRAIN: Batch: 0.8951606598389492 Loss_Seg: 9.148544\n",
      "accuracy = 0.951012\n",
      "mean IU  = 0.745877\n",
      "    class # 0 capture rate = 0.950242 \n",
      "    class # 1 capture rate = 0.962948 \n",
      "TRAIN: Batch: 0.8990696583535298 Loss_Total: 14.216906\n",
      "TRAIN: Batch: 0.8990696583535298 Loss_Seg: 14.066687\n",
      "accuracy = 0.930633\n",
      "mean IU  = 0.710604\n",
      "    class # 0 capture rate = 0.929797 \n",
      "    class # 1 capture rate = 0.941335 \n",
      "TRAIN: Batch: 0.9029786568681104 Loss_Total: 13.956144\n",
      "TRAIN: Batch: 0.9029786568681104 Loss_Seg: 9.200839\n",
      "accuracy = 0.958100\n",
      "mean IU  = 0.771715\n",
      "    class # 0 capture rate = 0.958872 \n",
      "    class # 1 capture rate = 0.946656 \n",
      "TRAIN: Batch: 0.906887655382691 Loss_Total: 18.857197\n",
      "TRAIN: Batch: 0.906887655382691 Loss_Seg: 10.748555\n",
      "accuracy = 0.940647\n",
      "mean IU  = 0.710830\n",
      "    class # 0 capture rate = 0.940081 \n",
      "    class # 1 capture rate = 0.949709 \n",
      "TRAIN: Batch: 0.9107966538972715 Loss_Total: 13.849276\n",
      "TRAIN: Batch: 0.9107966538972715 Loss_Seg: 11.570689\n",
      "accuracy = 0.945772\n",
      "mean IU  = 0.716978\n",
      "    class # 0 capture rate = 0.946728 \n",
      "    class # 1 capture rate = 0.929748 \n",
      "TRAIN: Batch: 0.9147056524118521 Loss_Total: 12.036599\n",
      "TRAIN: Batch: 0.9147056524118521 Loss_Seg: 12.611914\n",
      "accuracy = 0.936148\n",
      "mean IU  = 0.717295\n",
      "    class # 0 capture rate = 0.936236 \n",
      "    class # 1 capture rate = 0.934959 \n",
      "TRAIN: Batch: 0.9186146509264327 Loss_Total: 15.145365\n",
      "TRAIN: Batch: 0.9186146509264327 Loss_Seg: 12.461548\n",
      "accuracy = 0.935142\n",
      "mean IU  = 0.685722\n",
      "    class # 0 capture rate = 0.935055 \n",
      "    class # 1 capture rate = 0.936658 \n",
      "TRAIN: Batch: 0.9225236494410132 Loss_Total: 11.654188\n",
      "TRAIN: Batch: 0.9225236494410132 Loss_Seg: 12.173168\n",
      "accuracy = 0.945627\n",
      "mean IU  = 0.753600\n",
      "    class # 0 capture rate = 0.945233 \n",
      "    class # 1 capture rate = 0.950524 \n",
      "TRAIN: Batch: 0.9264326479555938 Loss_Total: 11.547442\n",
      "TRAIN: Batch: 0.9264326479555938 Loss_Seg: 13.989297\n",
      "accuracy = 0.946011\n",
      "mean IU  = 0.726653\n",
      "    class # 0 capture rate = 0.948805 \n",
      "    class # 1 capture rate = 0.903959 \n",
      "TRAIN: Batch: 0.9303416464701744 Loss_Total: 9.852295\n",
      "TRAIN: Batch: 0.9303416464701744 Loss_Seg: 8.050915\n",
      "accuracy = 0.953727\n",
      "mean IU  = 0.739436\n",
      "    class # 0 capture rate = 0.952333 \n",
      "    class # 1 capture rate = 0.978733 \n",
      "TRAIN: Batch: 0.9342506449847549 Loss_Total: 11.904192\n",
      "TRAIN: Batch: 0.9342506449847549 Loss_Seg: 12.644748\n",
      "accuracy = 0.940702\n",
      "mean IU  = 0.723784\n",
      "    class # 0 capture rate = 0.941495 \n",
      "    class # 1 capture rate = 0.929593 \n",
      "TRAIN: Batch: 0.9381596434993354 Loss_Total: 11.981589\n",
      "TRAIN: Batch: 0.9381596434993354 Loss_Seg: 8.641508\n",
      "accuracy = 0.960471\n",
      "mean IU  = 0.742149\n",
      "    class # 0 capture rate = 0.961163 \n",
      "    class # 1 capture rate = 0.946203 \n",
      "TRAIN: Batch: 0.942068642013916 Loss_Total: 20.597641\n",
      "TRAIN: Batch: 0.942068642013916 Loss_Seg: 21.47917\n",
      "accuracy = 0.907646\n",
      "mean IU  = 0.675034\n",
      "    class # 0 capture rate = 0.910658 \n",
      "    class # 1 capture rate = 0.875743 \n",
      "TRAIN: Batch: 0.9459776405284966 Loss_Total: 10.681785\n",
      "TRAIN: Batch: 0.9459776405284966 Loss_Seg: 9.177277\n",
      "accuracy = 0.963134\n",
      "mean IU  = 0.812631\n",
      "    class # 0 capture rate = 0.963420 \n",
      "    class # 1 capture rate = 0.959667 \n",
      "TRAIN: Batch: 0.9498866390430771 Loss_Total: 11.761212\n",
      "TRAIN: Batch: 0.9498866390430771 Loss_Seg: 10.018468\n",
      "accuracy = 0.945279\n",
      "mean IU  = 0.739794\n",
      "    class # 0 capture rate = 0.944288 \n",
      "    class # 1 capture rate = 0.959206 \n",
      "TRAIN: Batch: 0.9537956375576577 Loss_Total: 12.353821\n",
      "TRAIN: Batch: 0.9537956375576577 Loss_Seg: 9.94943\n",
      "accuracy = 0.946014\n",
      "mean IU  = 0.740542\n",
      "    class # 0 capture rate = 0.944178 \n",
      "    class # 1 capture rate = 0.972505 \n",
      "TRAIN: Batch: 0.9577046360722383 Loss_Total: 14.997662\n",
      "TRAIN: Batch: 0.9577046360722383 Loss_Seg: 15.572806\n",
      "accuracy = 0.922126\n",
      "mean IU  = 0.697315\n",
      "    class # 0 capture rate = 0.920808 \n",
      "    class # 1 capture rate = 0.938121 \n",
      "TRAIN: Batch: 0.9616136345868188 Loss_Total: 10.460145\n",
      "TRAIN: Batch: 0.9616136345868188 Loss_Seg: 11.673226\n",
      "accuracy = 0.951850\n",
      "mean IU  = 0.741966\n",
      "    class # 0 capture rate = 0.952449 \n",
      "    class # 1 capture rate = 0.942252 \n",
      "TRAIN: Batch: 0.9655226331013994 Loss_Total: 12.327219\n",
      "TRAIN: Batch: 0.9655226331013994 Loss_Seg: 10.74974\n",
      "accuracy = 0.955680\n",
      "mean IU  = 0.734933\n",
      "    class # 0 capture rate = 0.957848 \n",
      "    class # 1 capture rate = 0.915879 \n",
      "TRAIN: Batch: 0.96943163161598 Loss_Total: 13.613495\n",
      "TRAIN: Batch: 0.96943163161598 Loss_Seg: 13.995468\n",
      "accuracy = 0.933636\n",
      "mean IU  = 0.723895\n",
      "    class # 0 capture rate = 0.933051 \n",
      "    class # 1 capture rate = 0.940724 \n",
      "TRAIN: Batch: 0.9733406301305606 Loss_Total: 13.148247\n",
      "TRAIN: Batch: 0.9733406301305606 Loss_Seg: 11.665655\n",
      "accuracy = 0.925136\n",
      "mean IU  = 0.657511\n",
      "    class # 0 capture rate = 0.922921 \n",
      "    class # 1 capture rate = 0.966974 \n",
      "TRAIN: Batch: 0.9772496286451411 Loss_Total: 10.809548\n",
      "TRAIN: Batch: 0.9772496286451411 Loss_Seg: 8.447915\n",
      "accuracy = 0.952746\n",
      "mean IU  = 0.716594\n",
      "    class # 0 capture rate = 0.952660 \n",
      "    class # 1 capture rate = 0.954521 \n",
      "TRAIN: Batch: 0.9811586271597217 Loss_Total: 11.912935\n",
      "TRAIN: Batch: 0.9811586271597217 Loss_Seg: 10.161957\n",
      "accuracy = 0.944815\n",
      "mean IU  = 0.703373\n",
      "    class # 0 capture rate = 0.944800 \n",
      "    class # 1 capture rate = 0.945087 \n",
      "TRAIN: Batch: 0.9850676256743023 Loss_Total: 11.497276\n",
      "TRAIN: Batch: 0.9850676256743023 Loss_Seg: 10.551669\n",
      "accuracy = 0.938492\n",
      "mean IU  = 0.695428\n",
      "    class # 0 capture rate = 0.937663 \n",
      "    class # 1 capture rate = 0.953005 \n",
      "TRAIN: Batch: 0.9889766241888828 Loss_Total: 10.266901\n",
      "TRAIN: Batch: 0.9889766241888828 Loss_Seg: 7.259023\n",
      "accuracy = 0.964964\n",
      "mean IU  = 0.776261\n",
      "    class # 0 capture rate = 0.965890 \n",
      "    class # 1 capture rate = 0.948435 \n",
      "TRAIN: Batch: 0.9928856227034634 Loss_Total: 11.210649\n",
      "TRAIN: Batch: 0.9928856227034634 Loss_Seg: 8.976628\n",
      "accuracy = 0.952979\n",
      "mean IU  = 0.719540\n",
      "    class # 0 capture rate = 0.953304 \n",
      "    class # 1 capture rate = 0.946447 \n",
      "TRAIN: Batch: 0.996794621218044 Loss_Total: 10.025221\n",
      "TRAIN: Batch: 0.996794621218044 Loss_Seg: 9.759785\n",
      "accuracy = 0.951874\n",
      "mean IU  = 0.734945\n",
      "    class # 0 capture rate = 0.952532 \n",
      "    class # 1 capture rate = 0.940685 \n",
      "Validating NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \"\"\"\n",
      "Process Process-24:\n",
      "Process Process-23:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-76742371c67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#model = Model(args, experiment, loss_weight=weight, mustRestore=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckptpath_recg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'charList.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_beta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoderType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecoderType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeamSearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmustRestore_seg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmustRestore_recg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidateloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6809828a6d02>\u001b[0m in \u001b[0;36mtrainSeg\u001b[0;34m(self, loader, validateloader, testloader)\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;31m# validate:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidateloader\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mavg_batch_loss_seg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_batch_loss_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidateSeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidateloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mavg_batch_loss_seg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_batch_loss_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidateSeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6809828a6d02>\u001b[0m in \u001b[0;36mvalidateSeg\u001b[0;34m(self, loader, epoch, is_testing)\u001b[0m\n\u001b[1;32m    886\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseqLen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxTextLen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbt_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#self.batchsize_recg, #changed!!!!!!!!!!!!!!!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m              self.is_training:False})  # self.loss,val_loss,\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mtotal_val_loss_seg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval_loss_seg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "checkArgs()\n",
    "if args.train:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Lambda(lambda img: cv2.resize(img, (args.image_w, args.image_h), interpolation=cv2.INTER_CUBIC)),\n",
    "        transforms.Lambda(lambda img: np.expand_dims(img, 3)),\n",
    "        # transforms.Lambda(lambda img: add_artifacts(img,args)),\n",
    "        # transforms.Lambda(lambda img: cv2.transpose(img))\n",
    "    ])\n",
    "    # arprint=ArtPrint(args.data_root, transform=transform_train)\n",
    "    arprint = ArtPrintNoIntsectBinary(args.data_root, transform=transform_train)\n",
    "    concat = arprint\n",
    "    idxTrain = int(len(arprint) * 0.9)\n",
    "    trainset, testset = random_split(concat, [idxTrain, len(concat) - idxTrain])\n",
    "    trainloader = DataLoader(trainset, batch_size=args.batch_size_seg, shuffle=True, drop_last=True, num_workers=4)\n",
    "    testloader = DataLoader(testset, batch_size=args.batch_size_seg, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "    # weight gen\n",
    "    ##pos_perc = sum(map(lambda x: np.sum(cv2.imread(x[1], cv2.IMREAD_GRAYSCALE)), trainset.dataset.samples)) / (\n",
    "    ##            args.image_h * args.image_w * len(trainset.dataset.samples))\n",
    "    ##neg_perc = 1 - pos_perc\n",
    "    ##weight = np.array([pos_perc, neg_perc])  # just reverse\n",
    "    weight=np.array([0.1,0.9])\n",
    "    print(weight)\n",
    "    #model = Model(args, experiment, loss_weight=weight, mustRestore=False)\n",
    "    model = Model(args, charList=open(join(args.ckptpath_recg, 'charList.txt')).read(), loss_beta=0.5,loss_weight=weight, decoderType=DecoderType.BeamSearch,experiment=experiment,mustRestore_seg=False,mustRestore_recg=True,joint=True)\n",
    "    model.trainSeg(loader=trainloader, validateloader=testloader)\n",
    "\n",
    "else:\n",
    "    pass  # for no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
